10/19 02:52:33:  train data num: 2100  dev data num: 727
10/19 02:52:33:  train data num: 2100  dev data num: 727
10/19 05:09:46:  New best model, new acc 36.1761 % >= previous acc -inf %
10/19 05:09:47:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 05:09:47:  Step:10000, Best: 36.1761 %, Curr: 36.1761 %
10/19 05:09:52:  New best model, new acc 36.1761 % >= previous acc -inf %
10/19 05:09:52:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 05:09:52:  Step:10000, Best: 36.1761 %, Curr: 36.1761 %
10/19 07:26:03:  New best model, new acc 39.8900 % >= previous acc 36.1761 %
10/19 07:26:03:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 07:26:03:  Step:20000, Best: 39.8900 %, Curr: 39.8900 %
10/19 07:26:18:  New best model, new acc 39.8900 % >= previous acc 36.1761 %
10/19 07:26:18:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 07:26:18:  Step:20000, Best: 39.8900 %, Curr: 39.8900 %
10/19 09:41:22:  New best model, new acc 43.4663 % >= previous acc 39.8900 %
10/19 09:41:22:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 09:41:22:  Step:30000, Best: 43.4663 %, Curr: 43.4663 %
10/19 09:41:34:  New best model, new acc 43.4663 % >= previous acc 39.8900 %
10/19 09:41:34:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 09:41:34:  Step:30000, Best: 43.4663 %, Curr: 43.4663 %
10/19 11:56:38:  New best model, new acc 43.4663 % >= previous acc 43.4663 %
10/19 11:56:38:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 11:56:38:  Step:40000, Best: 43.4663 %, Curr: 43.4663 %
10/19 11:56:51:  New best model, new acc 43.4663 % >= previous acc 43.4663 %
10/19 11:56:51:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 11:56:51:  Step:40000, Best: 43.4663 %, Curr: 43.4663 %
10/19 14:11:46:  New best model, new acc 44.9794 % >= previous acc 43.4663 %
10/19 14:11:46:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 14:11:46:  Step:50000, Best: 44.9794 %, Curr: 44.9794 %
10/19 14:11:52:  New best model, new acc 44.9794 % >= previous acc 43.4663 %
10/19 14:11:52:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 14:11:52:  Step:50000, Best: 44.9794 %, Curr: 44.9794 %
10/19 16:26:41:  New best model, new acc 46.0798 % >= previous acc 44.9794 %
10/19 16:26:41:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 16:26:41:  Step:60000, Best: 46.0798 %, Curr: 46.0798 %
10/19 16:26:53:  New best model, new acc 46.0798 % >= previous acc 44.9794 %
10/19 16:26:53:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 16:26:53:  Step:60000, Best: 46.0798 %, Curr: 46.0798 %
10/19 18:41:43:  do not save, best acc: 46.0798
10/19 18:41:43:  Step:70000, Best: 46.0798 %, Curr: 45.3920 %
10/19 18:41:47:  do not save, best acc: 46.0798
10/19 18:41:47:  Step:70000, Best: 46.0798 %, Curr: 45.3920 %
10/19 20:56:35:  New best model, new acc 48.9684 % >= previous acc 46.0798 %
10/19 20:56:35:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 20:56:35:  Step:80000, Best: 48.9684 %, Curr: 48.9684 %
10/19 20:56:48:  New best model, new acc 48.9684 % >= previous acc 46.0798 %
10/19 20:56:48:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 20:56:48:  Step:80000, Best: 48.9684 %, Curr: 48.9684 %
10/19 23:11:25:  New best model, new acc 48.9684 % >= previous acc 48.9684 %
10/19 23:11:25:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 23:11:25:  Step:90000, Best: 48.9684 %, Curr: 48.9684 %
10/19 23:11:33:  New best model, new acc 48.9684 % >= previous acc 48.9684 %
10/19 23:11:33:  Save to ./checkpoint/llama_linear_1token_5examples.pkl
10/19 23:11:33:  Step:90000, Best: 48.9684 %, Curr: 48.9684 %
10/20 01:26:12:  do not save, best acc: 48.9684
10/20 01:26:12:  Step:100000, Best: 48.9684 %, Curr: 48.4182 %
10/20 01:26:24:  do not save, best acc: 48.9684
10/20 01:26:24:  Step:100000, Best: 48.9684 %, Curr: 48.4182 %
10/20 02:42:04:  do not save, best acc: 48.9684
10/20 02:42:04:  Step:105000, Best: 48.9684 %, Curr: 48.1431 %
10/20 02:42:13:  do not save, best acc: 48.9684
10/20 02:42:13:  Step:105000, Best: 48.9684 %, Curr: 48.1431 %
10/20 07:59:51:  train data num: 2100  dev data num: 727
10/20 07:59:52:  train data num: 2100  dev data num: 727
10/20 08:55:38:  New best model, new acc 24.8968 % >= previous acc -inf %
10/20 08:55:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 08:55:38:  Step:10000, Best: 24.8968 %, Curr: 24.8968 %
10/20 08:55:39:  New best model, new acc 24.8968 % >= previous acc -inf %
10/20 08:55:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 08:55:39:  Step:10000, Best: 24.8968 %, Curr: 24.8968 %
10/20 09:00:11:  train data num: 2100  dev data num: 727
10/20 09:00:11:  train data num: 2100  dev data num: 727
10/20 09:55:29:  New best model, new acc 0.2751 % >= previous acc -inf %
10/20 09:55:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 09:55:29:  Step:10000, Best: 0.2751 %, Curr: 0.2751 %
10/20 09:55:34:  New best model, new acc 0.2751 % >= previous acc -inf %
10/20 09:55:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 09:55:34:  Step:10000, Best: 0.2751 %, Curr: 0.2751 %
10/20 10:49:34:  New best model, new acc 1.6506 % >= previous acc 0.2751 %
10/20 10:49:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 10:49:34:  Step:20000, Best: 1.6506 %, Curr: 1.6506 %
10/20 10:49:39:  New best model, new acc 1.6506 % >= previous acc 0.2751 %
10/20 10:49:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 10:49:39:  Step:20000, Best: 1.6506 %, Curr: 1.6506 %
10/20 11:43:30:  New best model, new acc 24.6217 % >= previous acc 1.6506 %
10/20 11:43:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 11:43:30:  Step:30000, Best: 24.6217 %, Curr: 24.6217 %
10/20 11:43:46:  New best model, new acc 24.6217 % >= previous acc 1.6506 %
10/20 11:43:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 11:43:46:  Step:30000, Best: 24.6217 %, Curr: 24.6217 %
10/20 12:37:51:  New best model, new acc 35.0757 % >= previous acc 24.6217 %
10/20 12:37:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 12:37:51:  Step:40000, Best: 35.0757 %, Curr: 35.0757 %
10/20 12:37:53:  New best model, new acc 35.0757 % >= previous acc 24.6217 %
10/20 12:37:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 12:37:53:  Step:40000, Best: 35.0757 %, Curr: 35.0757 %
10/20 13:31:46:  New best model, new acc 40.3026 % >= previous acc 35.0757 %
10/20 13:31:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 13:31:46:  Step:50000, Best: 40.3026 %, Curr: 40.3026 %
10/20 13:32:03:  New best model, new acc 40.3026 % >= previous acc 35.0757 %
10/20 13:32:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 13:32:03:  Step:50000, Best: 40.3026 %, Curr: 40.3026 %
10/20 14:25:51:  New best model, new acc 44.5667 % >= previous acc 40.3026 %
10/20 14:25:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 14:25:51:  Step:60000, Best: 44.5667 %, Curr: 44.5667 %
10/20 14:26:07:  New best model, new acc 44.5667 % >= previous acc 40.3026 %
10/20 14:26:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 14:26:07:  Step:60000, Best: 44.5667 %, Curr: 44.5667 %
10/20 15:20:05:  New best model, new acc 47.0426 % >= previous acc 44.5667 %
10/20 15:20:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 15:20:05:  Step:70000, Best: 47.0426 %, Curr: 47.0426 %
10/20 15:20:08:  New best model, new acc 47.0426 % >= previous acc 44.5667 %
10/20 15:20:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 15:20:08:  Step:70000, Best: 47.0426 %, Curr: 47.0426 %
10/20 16:14:02:  New best model, new acc 50.3439 % >= previous acc 47.0426 %
10/20 16:14:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 16:14:02:  Step:80000, Best: 50.3439 %, Curr: 50.3439 %
10/20 16:14:18:  New best model, new acc 50.3439 % >= previous acc 47.0426 %
10/20 16:14:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 16:14:18:  Step:80000, Best: 50.3439 %, Curr: 50.3439 %
10/20 17:08:13:  New best model, new acc 53.7827 % >= previous acc 50.3439 %
10/20 17:08:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 17:08:13:  Step:90000, Best: 53.7827 %, Curr: 53.7827 %
10/20 17:08:16:  New best model, new acc 53.7827 % >= previous acc 50.3439 %
10/20 17:08:16:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 17:08:16:  Step:90000, Best: 53.7827 %, Curr: 53.7827 %
10/20 18:02:05:  New best model, new acc 54.3329 % >= previous acc 53.7827 %
10/20 18:02:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 18:02:05:  Step:100000, Best: 54.3329 %, Curr: 54.3329 %
10/20 18:02:08:  New best model, new acc 54.3329 % >= previous acc 53.7827 %
10/20 18:02:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 18:02:08:  Step:100000, Best: 54.3329 %, Curr: 54.3329 %
10/20 18:35:25:  New best model, new acc 55.7084 % >= previous acc 54.3329 %
10/20 18:35:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 18:35:25:  Step:105000, Best: 55.7084 %, Curr: 55.7084 %
10/20 18:35:40:  New best model, new acc 55.7084 % >= previous acc 54.3329 %
10/20 18:35:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/20 18:35:41:  Step:105000, Best: 55.7084 %, Curr: 55.7084 %
10/21 02:01:47:  train data num: 2100  dev data num: 727
10/21 02:01:47:  train data num: 2100  dev data num: 727
10/21 02:03:43:  train data num: 2100  dev data num: 727
10/21 02:03:43:  train data num: 2100  dev data num: 727
10/21 02:05:01:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 251, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 235, in _main
    _train(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 178, in _train
    _eval2save(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 121, in _eval2save
    acc = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 90, in _eval4sa
    print(batch_targets)
UnboundLocalError: local variable 'batch_targets' referenced before assignment
10/21 02:05:01:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 251, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 235, in _main
    _train(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 178, in _train
    _eval2save(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 121, in _eval2save
    acc = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 90, in _eval4sa
    print(batch_targets)
UnboundLocalError: local variable 'batch_targets' referenced before assignment
10/21 02:08:47:  train data num: 2100  dev data num: 727
10/21 02:08:47:  train data num: 2100  dev data num: 727
10/21 02:24:47:  train data num: 2100  dev data num: 727
10/21 02:24:47:  train data num: 2100  dev data num: 727
10/21 02:29:48:  train data num: 2100  dev data num: 727
10/21 02:29:48:  train data num: 2100  dev data num: 727
10/21 02:33:51:  train data num: 2100  dev data num: 727
10/21 02:33:51:  train data num: 2100  dev data num: 727
10/21 03:29:13:  New best model, new acc 0.1376 % >= previous acc -inf %
10/21 03:29:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 03:29:13:  Step:10000, Best: 0.1376 %, Curr: 0.1376 %
10/21 03:29:17:  New best model, new acc 0.1376 % >= previous acc -inf %
10/21 03:29:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 03:29:17:  Step:10000, Best: 0.1376 %, Curr: 0.1376 %
10/21 04:23:17:  New best model, new acc 1.6506 % >= previous acc 0.1376 %
10/21 04:23:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 04:23:17:  Step:20000, Best: 1.6506 %, Curr: 1.6506 %
10/21 04:23:31:  New best model, new acc 1.6506 % >= previous acc 0.1376 %
10/21 04:23:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 04:23:31:  Step:20000, Best: 1.6506 %, Curr: 1.6506 %
10/21 05:17:31:  New best model, new acc 23.5213 % >= previous acc 1.6506 %
10/21 05:17:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 05:17:31:  Step:30000, Best: 23.5213 %, Curr: 23.5213 %
10/21 05:17:44:  New best model, new acc 23.5213 % >= previous acc 1.6506 %
10/21 05:17:44:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 05:17:44:  Step:30000, Best: 23.5213 %, Curr: 23.5213 %
10/21 06:11:47:  New best model, new acc 33.0124 % >= previous acc 23.5213 %
10/21 06:11:47:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 06:11:47:  Step:40000, Best: 33.0124 %, Curr: 33.0124 %
10/21 06:12:01:  New best model, new acc 33.0124 % >= previous acc 23.5213 %
10/21 06:12:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 06:12:01:  Step:40000, Best: 33.0124 %, Curr: 33.0124 %
10/21 07:06:05:  New best model, new acc 38.6520 % >= previous acc 33.0124 %
10/21 07:06:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 07:06:05:  Step:50000, Best: 38.6520 %, Curr: 38.6520 %
10/21 07:06:18:  New best model, new acc 38.6520 % >= previous acc 33.0124 %
10/21 07:06:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 07:06:18:  Step:50000, Best: 38.6520 %, Curr: 38.6520 %
10/21 08:00:21:  New best model, new acc 43.6039 % >= previous acc 38.6520 %
10/21 08:00:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 08:00:21:  Step:60000, Best: 43.6039 %, Curr: 43.6039 %
10/21 08:00:26:  New best model, new acc 43.6039 % >= previous acc 38.6520 %
10/21 08:00:26:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 08:00:26:  Step:60000, Best: 43.6039 %, Curr: 43.6039 %
10/21 08:54:32:  New best model, new acc 47.5928 % >= previous acc 43.6039 %
10/21 08:54:32:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 08:54:32:  Step:70000, Best: 47.5928 %, Curr: 47.5928 %
10/21 08:54:36:  New best model, new acc 47.5928 % >= previous acc 43.6039 %
10/21 08:54:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 08:54:36:  Step:70000, Best: 47.5928 %, Curr: 47.5928 %
10/21 09:48:38:  New best model, new acc 50.8941 % >= previous acc 47.5928 %
10/21 09:48:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 09:48:38:  Step:80000, Best: 50.8941 %, Curr: 50.8941 %
10/21 09:48:42:  New best model, new acc 50.8941 % >= previous acc 47.5928 %
10/21 09:48:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 09:48:42:  Step:80000, Best: 50.8941 %, Curr: 50.8941 %
10/21 10:42:45:  New best model, new acc 51.8569 % >= previous acc 50.8941 %
10/21 10:42:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 10:42:45:  Step:90000, Best: 51.8569 %, Curr: 51.8569 %
10/21 10:42:51:  New best model, new acc 51.8569 % >= previous acc 50.8941 %
10/21 10:42:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 10:42:51:  Step:90000, Best: 51.8569 %, Curr: 51.8569 %
10/21 11:36:41:  do not save, best acc: 51.8569
10/21 11:36:41:  Step:100000, Best: 51.8569 %, Curr: 51.4443 %
10/21 11:36:54:  do not save, best acc: 51.8569
10/21 11:36:54:  Step:100000, Best: 51.8569 %, Curr: 51.4443 %
10/21 12:10:11:  New best model, new acc 54.1953 % >= previous acc 51.8569 %
10/21 12:10:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 12:10:11:  Step:105000, Best: 54.1953 %, Curr: 54.1953 %
10/21 12:10:24:  New best model, new acc 54.1953 % >= previous acc 51.8569 %
10/21 12:10:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 12:10:24:  Step:105000, Best: 54.1953 %, Curr: 54.1953 %
10/21 12:16:44:  train data num: 2100  dev data num: 727
10/21 12:16:44:  train data num: 2100  dev data num: 727
10/21 13:11:53:  New best model, new acc 0.1376 % >= previous acc -inf %
10/21 13:11:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 13:11:53:  Step:10000, Best: 0.1376 %, Curr: 0.1376 %
10/21 13:12:11:  New best model, new acc 0.1376 % >= previous acc -inf %
10/21 13:12:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 13:12:11:  Step:10000, Best: 0.1376 %, Curr: 0.1376 %
10/21 14:06:12:  New best model, new acc 0.2751 % >= previous acc 0.1376 %
10/21 14:06:12:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 14:06:12:  Step:20000, Best: 0.2751 %, Curr: 0.2751 %
10/21 14:06:14:  New best model, new acc 0.2751 % >= previous acc 0.1376 %
10/21 14:06:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 14:06:14:  Step:20000, Best: 0.2751 %, Curr: 0.2751 %
10/21 15:00:14:  New best model, new acc 2.0633 % >= previous acc 0.2751 %
10/21 15:00:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 15:00:14:  Step:30000, Best: 2.0633 %, Curr: 2.0633 %
10/21 15:00:15:  New best model, new acc 2.0633 % >= previous acc 0.2751 %
10/21 15:00:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 15:00:15:  Step:30000, Best: 2.0633 %, Curr: 2.0633 %
10/21 15:54:15:  New best model, new acc 18.9821 % >= previous acc 2.0633 %
10/21 15:54:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 15:54:15:  Step:40000, Best: 18.9821 %, Curr: 18.9821 %
10/21 15:54:29:  New best model, new acc 18.9821 % >= previous acc 2.0633 %
10/21 15:54:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 15:54:29:  Step:40000, Best: 18.9821 %, Curr: 18.9821 %
10/21 16:48:33:  New best model, new acc 28.6107 % >= previous acc 18.9821 %
10/21 16:48:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 16:48:33:  Step:50000, Best: 28.6107 %, Curr: 28.6107 %
10/21 16:48:33:  New best model, new acc 28.6107 % >= previous acc 18.9821 %
10/21 16:48:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 16:48:33:  Step:50000, Best: 28.6107 %, Curr: 28.6107 %
10/21 17:42:25:  New best model, new acc 34.1128 % >= previous acc 28.6107 %
10/21 17:42:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 17:42:25:  Step:60000, Best: 34.1128 %, Curr: 34.1128 %
10/21 17:42:44:  New best model, new acc 34.1128 % >= previous acc 28.6107 %
10/21 17:42:44:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 17:42:44:  Step:60000, Best: 34.1128 %, Curr: 34.1128 %
10/21 18:36:43:  New best model, new acc 39.3398 % >= previous acc 34.1128 %
10/21 18:36:43:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 18:36:43:  Step:70000, Best: 39.3398 %, Curr: 39.3398 %
10/21 18:36:46:  New best model, new acc 39.3398 % >= previous acc 34.1128 %
10/21 18:36:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 18:36:46:  Step:70000, Best: 39.3398 %, Curr: 39.3398 %
10/21 19:30:36:  New best model, new acc 44.1541 % >= previous acc 39.3398 %
10/21 19:30:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 19:30:36:  Step:80000, Best: 44.1541 %, Curr: 44.1541 %
10/21 19:30:53:  New best model, new acc 44.1541 % >= previous acc 39.3398 %
10/21 19:30:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 19:30:53:  Step:80000, Best: 44.1541 %, Curr: 44.1541 %
10/21 20:24:51:  New best model, new acc 45.1169 % >= previous acc 44.1541 %
10/21 20:24:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 20:24:51:  Step:90000, Best: 45.1169 %, Curr: 45.1169 %
10/21 20:24:51:  New best model, new acc 45.1169 % >= previous acc 44.1541 %
10/21 20:24:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 20:24:51:  Step:90000, Best: 45.1169 %, Curr: 45.1169 %
10/21 21:18:32:  New best model, new acc 47.3177 % >= previous acc 45.1169 %
10/21 21:18:32:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 21:18:32:  Step:100000, Best: 47.3177 %, Curr: 47.3177 %
10/21 21:18:49:  New best model, new acc 47.3177 % >= previous acc 45.1169 %
10/21 21:18:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 21:18:49:  Step:100000, Best: 47.3177 %, Curr: 47.3177 %
10/21 22:12:47:  New best model, new acc 48.8308 % >= previous acc 47.3177 %
10/21 22:12:47:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 22:12:47:  Step:110000, Best: 48.8308 %, Curr: 48.8308 %
10/21 22:12:49:  New best model, new acc 48.8308 % >= previous acc 47.3177 %
10/21 22:12:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 22:12:50:  Step:110000, Best: 48.8308 %, Curr: 48.8308 %
10/21 23:06:49:  New best model, new acc 51.0316 % >= previous acc 48.8308 %
10/21 23:06:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 23:06:49:  Step:120000, Best: 51.0316 %, Curr: 51.0316 %
10/21 23:06:50:  New best model, new acc 51.0316 % >= previous acc 48.8308 %
10/21 23:06:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/21 23:06:50:  Step:120000, Best: 51.0316 %, Curr: 51.0316 %
10/22 00:00:46:  do not save, best acc: 51.0316
10/22 00:00:46:  Step:130000, Best: 51.0316 %, Curr: 50.6190 %
10/22 00:00:48:  do not save, best acc: 51.0316
10/22 00:00:48:  Step:130000, Best: 51.0316 %, Curr: 50.6190 %
10/22 00:54:31:  New best model, new acc 53.2325 % >= previous acc 51.0316 %
10/22 00:54:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 00:54:31:  Step:140000, Best: 53.2325 %, Curr: 53.2325 %
10/22 00:54:48:  New best model, new acc 53.2325 % >= previous acc 51.0316 %
10/22 00:54:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 00:54:48:  Step:140000, Best: 53.2325 %, Curr: 53.2325 %
10/22 01:48:40:  New best model, new acc 53.9202 % >= previous acc 53.2325 %
10/22 01:48:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 01:48:40:  Step:150000, Best: 53.9202 %, Curr: 53.9202 %
10/22 01:48:57:  New best model, new acc 53.9202 % >= previous acc 53.2325 %
10/22 01:48:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 01:48:57:  Step:150000, Best: 53.9202 %, Curr: 53.9202 %
10/22 02:42:45:  do not save, best acc: 53.9202
10/22 02:42:45:  Step:160000, Best: 53.9202 %, Curr: 53.7827 %
10/22 02:43:03:  do not save, best acc: 53.9202
10/22 02:43:03:  Step:160000, Best: 53.9202 %, Curr: 53.7827 %
10/22 03:36:54:  do not save, best acc: 53.9202
10/22 03:36:54:  Step:170000, Best: 53.9202 %, Curr: 52.8198 %
10/22 03:37:09:  do not save, best acc: 53.9202
10/22 03:37:09:  Step:170000, Best: 53.9202 %, Curr: 52.8198 %
10/22 04:30:59:  do not save, best acc: 53.9202
10/22 04:30:59:  Step:180000, Best: 53.9202 %, Curr: 53.6451 %
10/22 04:31:19:  do not save, best acc: 53.9202
10/22 04:31:19:  Step:180000, Best: 53.9202 %, Curr: 53.6451 %
10/22 05:38:57:  do not save, best acc: 53.9202
10/22 05:38:57:  do not save, best acc: 53.9202
10/22 05:38:57:  Step:190000, Best: 53.9202 %, Curr: 51.9945 %
10/22 05:38:57:  Step:190000, Best: 53.9202 %, Curr: 51.9945 %
10/22 10:37:28:  train data num: 2100  dev data num: 727
10/22 10:37:28:  train data num: 2100  dev data num: 727
10/22 11:32:26:  New best model, new acc 0.1376 % >= previous acc -inf %
10/22 11:32:26:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 11:32:26:  Step:10000, Best: 0.1376 %, Curr: 0.1376 %
10/22 11:32:35:  New best model, new acc 0.1376 % >= previous acc -inf %
10/22 11:32:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 11:32:35:  Step:10000, Best: 0.1376 %, Curr: 0.1376 %
10/22 12:26:23:  New best model, new acc 0.2751 % >= previous acc 0.1376 %
10/22 12:26:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 12:26:23:  Step:20000, Best: 0.2751 %, Curr: 0.2751 %
10/22 12:26:29:  New best model, new acc 0.2751 % >= previous acc 0.1376 %
10/22 12:26:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 12:26:29:  Step:20000, Best: 0.2751 %, Curr: 0.2751 %
10/22 13:20:15:  New best model, new acc 2.0633 % >= previous acc 0.2751 %
10/22 13:20:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 13:20:15:  Step:30000, Best: 2.0633 %, Curr: 2.0633 %
10/22 13:20:22:  New best model, new acc 2.0633 % >= previous acc 0.2751 %
10/22 13:20:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 13:20:22:  Step:30000, Best: 2.0633 %, Curr: 2.0633 %
10/22 14:14:07:  New best model, new acc 18.9821 % >= previous acc 2.0633 %
10/22 14:14:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 14:14:07:  Step:40000, Best: 18.9821 %, Curr: 18.9821 %
10/22 14:14:18:  New best model, new acc 18.9821 % >= previous acc 2.0633 %
10/22 14:14:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 14:14:18:  Step:40000, Best: 18.9821 %, Curr: 18.9821 %
10/22 15:08:00:  New best model, new acc 28.6107 % >= previous acc 18.9821 %
10/22 15:08:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 15:08:00:  Step:50000, Best: 28.6107 %, Curr: 28.6107 %
10/22 15:08:12:  New best model, new acc 28.6107 % >= previous acc 18.9821 %
10/22 15:08:12:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 15:08:12:  Step:50000, Best: 28.6107 %, Curr: 28.6107 %
10/22 16:01:50:  New best model, new acc 34.1128 % >= previous acc 28.6107 %
10/22 16:01:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 16:01:50:  Step:60000, Best: 34.1128 %, Curr: 34.1128 %
10/22 16:01:57:  New best model, new acc 34.1128 % >= previous acc 28.6107 %
10/22 16:01:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 16:01:57:  Step:60000, Best: 34.1128 %, Curr: 34.1128 %
10/22 16:55:38:  New best model, new acc 39.3398 % >= previous acc 34.1128 %
10/22 16:55:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 16:55:38:  Step:70000, Best: 39.3398 %, Curr: 39.3398 %
10/22 16:55:48:  New best model, new acc 39.3398 % >= previous acc 34.1128 %
10/22 16:55:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 16:55:48:  Step:70000, Best: 39.3398 %, Curr: 39.3398 %
10/22 17:49:27:  New best model, new acc 44.1541 % >= previous acc 39.3398 %
10/22 17:49:27:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 17:49:27:  Step:80000, Best: 44.1541 %, Curr: 44.1541 %
10/22 17:49:36:  New best model, new acc 44.1541 % >= previous acc 39.3398 %
10/22 17:49:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 17:49:36:  Step:80000, Best: 44.1541 %, Curr: 44.1541 %
10/22 18:43:15:  New best model, new acc 45.1169 % >= previous acc 44.1541 %
10/22 18:43:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 18:43:15:  Step:90000, Best: 45.1169 %, Curr: 45.1169 %
10/22 18:43:23:  New best model, new acc 45.1169 % >= previous acc 44.1541 %
10/22 18:43:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 18:43:23:  Step:90000, Best: 45.1169 %, Curr: 45.1169 %
10/22 19:36:55:  New best model, new acc 47.3177 % >= previous acc 45.1169 %
10/22 19:36:55:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 19:36:55:  Step:100000, Best: 47.3177 %, Curr: 47.3177 %
10/22 19:37:05:  New best model, new acc 47.3177 % >= previous acc 45.1169 %
10/22 19:37:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 19:37:05:  Step:100000, Best: 47.3177 %, Curr: 47.3177 %
10/22 20:30:45:  New best model, new acc 48.8308 % >= previous acc 47.3177 %
10/22 20:30:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 20:30:45:  Step:110000, Best: 48.8308 %, Curr: 48.8308 %
10/22 20:30:54:  New best model, new acc 48.8308 % >= previous acc 47.3177 %
10/22 20:30:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 20:30:54:  Step:110000, Best: 48.8308 %, Curr: 48.8308 %
10/22 21:24:32:  New best model, new acc 51.0316 % >= previous acc 48.8308 %
10/22 21:24:32:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 21:24:32:  Step:120000, Best: 51.0316 %, Curr: 51.0316 %
10/22 21:24:45:  New best model, new acc 51.0316 % >= previous acc 48.8308 %
10/22 21:24:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 21:24:45:  Step:120000, Best: 51.0316 %, Curr: 51.0316 %
10/22 22:18:24:  do not save, best acc: 51.0316
10/22 22:18:24:  Step:130000, Best: 51.0316 %, Curr: 50.6190 %
10/22 22:18:32:  do not save, best acc: 51.0316
10/22 22:18:32:  Step:130000, Best: 51.0316 %, Curr: 50.6190 %
10/22 23:12:02:  New best model, new acc 53.2325 % >= previous acc 51.0316 %
10/22 23:12:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 23:12:02:  Step:140000, Best: 53.2325 %, Curr: 53.2325 %
10/22 23:12:14:  New best model, new acc 53.2325 % >= previous acc 51.0316 %
10/22 23:12:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/22 23:12:14:  Step:140000, Best: 53.2325 %, Curr: 53.2325 %
10/23 00:05:52:  New best model, new acc 53.9202 % >= previous acc 53.2325 %
10/23 00:05:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/23 00:05:52:  Step:150000, Best: 53.9202 %, Curr: 53.9202 %
10/23 00:06:01:  New best model, new acc 53.9202 % >= previous acc 53.2325 %
10/23 00:06:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
10/23 00:06:01:  Step:150000, Best: 53.9202 %, Curr: 53.9202 %
10/23 00:59:37:  do not save, best acc: 53.9202
10/23 00:59:37:  Step:160000, Best: 53.9202 %, Curr: 53.7827 %
10/23 00:59:45:  do not save, best acc: 53.9202
10/23 00:59:45:  Step:160000, Best: 53.9202 %, Curr: 53.7827 %
10/23 01:53:25:  do not save, best acc: 53.9202
10/23 01:53:25:  Step:170000, Best: 53.9202 %, Curr: 52.8198 %
10/23 01:53:28:  do not save, best acc: 53.9202
10/23 01:53:28:  Step:170000, Best: 53.9202 %, Curr: 52.8198 %
10/23 02:47:07:  do not save, best acc: 53.9202
10/23 02:47:07:  Step:180000, Best: 53.9202 %, Curr: 53.6451 %
10/23 02:47:13:  do not save, best acc: 53.9202
10/23 02:47:13:  Step:180000, Best: 53.9202 %, Curr: 53.6451 %
10/23 03:40:54:  do not save, best acc: 53.9202
10/23 03:40:54:  Step:190000, Best: 53.9202 %, Curr: 51.9945 %
10/23 03:41:05:  do not save, best acc: 53.9202
10/23 03:41:05:  Step:190000, Best: 53.9202 %, Curr: 51.9945 %
10/23 04:34:49:  do not save, best acc: 53.9202
10/23 04:34:49:  Step:200000, Best: 53.9202 %, Curr: 50.0688 %
10/23 04:34:57:  do not save, best acc: 53.9202
10/23 04:34:57:  Step:200000, Best: 53.9202 %, Curr: 50.0688 %
10/23 05:28:38:  do not save, best acc: 53.9202
10/23 05:28:38:  Step:210000, Best: 53.9202 %, Curr: 48.4182 %
10/23 05:28:47:  do not save, best acc: 53.9202
10/23 05:28:47:  Step:210000, Best: 53.9202 %, Curr: 48.4182 %
10/23 05:41:10:  do not save, best acc: 53.9202
10/23 05:41:10:  Step:210000, Best: 53.9202 %, Curr: 48.4182 %
10/23 05:41:28:  do not save, best acc: 53.9202
10/23 05:41:28:  Step:210000, Best: 53.9202 %, Curr: 48.4182 %
10/26 02:41:34:  train data num: 2100  dev data num: 727
10/26 02:41:34:  train data num: 2100  dev data num: 727
10/26 02:43:48:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 206, in _main
    train_ds = SADataset(args.data_file['train'], tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 27, in __init__
    self._generate_image_feature()
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 212, in _generate_image_feature
    image_file = h5py.File(os.path.join(self.args.dataset_dir, "image_feature.h5"), 'w')
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 237, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 126, in h5py.h5f.create
BlockingIOError: [Errno 11] Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
10/26 02:49:13:  train data num: 1745  dev data num: 577
10/26 02:49:13:  train data num: 1745  dev data num: 577
10/26 02:50:28:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 233, in _main
    _train(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 146, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 142, in collate_fn
    batch_pairs.append(self._get_pairs(item))
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 177, in _get_pairs
    text, image, example = item['sentence'], item['image'], item['examples'],
KeyError: 'image'
10/26 02:50:28:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 233, in _main
    _train(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 146, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 142, in collate_fn
    batch_pairs.append(self._get_pairs(item))
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 177, in _get_pairs
    text, image, example = item['sentence'], item['image'], item['examples'],
KeyError: 'image'
10/26 02:52:18:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 206, in _main
    train_ds = SADataset(args.data_file['train'], tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 27, in __init__
    self._generate_image_feature()
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 211, in _generate_image_feature
    image_file = h5py.File(os.path.join(self.args.dataset_dir, "image_feature.h5"), 'w')
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 237, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 126, in h5py.h5f.create
BlockingIOError: [Errno 11] Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
11/07 03:33:10:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 206, in _main
    train_ds = SADataset(args.data_file['train'], tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 27, in __init__
    self._generate_image_feature()
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 211, in _generate_image_feature
    image_file = h5py.File(os.path.join(self.args.dataset_dir, "image_feature.h5"), 'w')
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 237, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 126, in h5py.h5f.create
BlockingIOError: [Errno 11] Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
11/07 03:37:05:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 207, in _main
    dev_ds = SADataset(args.data_file['dev'], tokenizer=True, args=args, **args.kwargs_ds)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 27, in __init__
    self._generate_image_feature()
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 211, in _generate_image_feature
    image_file = h5py.File(os.path.join(self.args.dataset_dir, "image_feature.h5"), 'w')
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 237, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 126, in h5py.h5f.create
BlockingIOError: [Errno 11] Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
11/07 03:39:03:  train data num: 2100  dev data num: 727
11/07 03:47:02:  train data num: 2100  dev data num: 727
11/07 03:47:02:  train data num: 2100  dev data num: 727
11/07 03:52:16:  train data num: 2100  dev data num: 727
11/07 03:52:16:  train data num: 2100  dev data num: 727
11/07 03:58:49:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 206, in _main
    train_ds = SADataset(args.data_file['train'], tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 27, in __init__
    self._generate_image_feature()
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 213, in _generate_image_feature
    image_file = h5py.File(os.path.join(self.args.dataset_dir, "image_feature.h5"), 'w')
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 237, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 126, in h5py.h5f.create
BlockingIOError: [Errno 11] Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
11/07 03:59:24:  train data num: 2100  dev data num: 727
11/07 03:59:24:  train data num: 2100  dev data num: 727
11/07 04:00:39:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 233, in _main
    _train(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 146, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 142, in collate_fn
    batch_pairs.append(self._get_pairs(item))
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 179, in _get_pairs
    text, image, example = item['sentence'], item['image'], item['examples'],
KeyError: 'image'
11/07 04:00:39:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 233, in _main
    _train(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 146, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 142, in collate_fn
    batch_pairs.append(self._get_pairs(item))
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 179, in _get_pairs
    text, image, example = item['sentence'], item['image'], item['examples'],
KeyError: 'image'
11/07 04:01:28:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 206, in _main
    train_ds = SADataset(args.data_file['train'], tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 27, in __init__
    self._generate_image_feature()
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/dataset_sa.py", line 213, in _generate_image_feature
    image_file = h5py.File(os.path.join(self.args.dataset_dir, "image_feature.h5"), 'w')
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py", line 237, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 126, in h5py.h5f.create
BlockingIOError: [Errno 11] Unable to create file (unable to lock file, errno = 11, error message = 'Resource temporarily unavailable')
11/07 04:03:42:  train data num: 2100  dev data num: 727
11/07 04:33:42:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 249, in <module>
    _main(args)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/main.py", line 218, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/WikiMEL_LLaMA_2/utils.py", line 135, in wrap_with_peft
    accelerator = Accelerator()
  File "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py", line 369, in __init__
    self.state = AcceleratorState(
  File "/usr/local/lib/python3.10/dist-packages/accelerate/state.py", line 732, in __init__
    PartialState(cpu, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/accelerate/state.py", line 202, in __init__
    torch.distributed.init_process_group(backend=self.backend, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 932, in init_process_group
    _store_based_barrier(rank, store, timeout)
  File "/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py", line 469, in _store_based_barrier
    raise RuntimeError(
RuntimeError: Timed out initializing process group in store based barrier on rank: 1, for key: store_based_barrier_key:1 (world_size=2, worker_count=1, timeout=0:30:00)
11/14 09:03:05:  train data num: 2100  dev data num: 727
11/14 09:03:05:  train data num: 2100  dev data num: 727
11/14 09:09:17:  train data num: 2100  dev data num: 727
11/14 09:09:17:  train data num: 2100  dev data num: 727
11/14 09:42:16:  train data num: 2100  dev data num: 727
11/14 09:42:16:  train data num: 2100  dev data num: 727
11/14 09:48:18:  train data num: 2100  dev data num: 727
11/14 09:48:18:  train data num: 2100  dev data num: 727
11/14 09:49:37:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in <module>
    try:
  File "/workspace/GEMEL/twitter/code/main.py", line 128, in _main
    # 5.train
  File "/workspace/GEMEL/twitter/code/main.py", line 71, in _train
    if args.do_eval and not args.global_steps % args.do_eval_steps:
NameError: name '_eval2save' is not defined
11/14 09:49:37:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in <module>
    try:
  File "/workspace/GEMEL/twitter/code/main.py", line 128, in _main
    # 5.train
  File "/workspace/GEMEL/twitter/code/main.py", line 71, in _train
    if args.do_eval and not args.global_steps % args.do_eval_steps:
NameError: name '_eval2save' is not defined
11/14 09:50:23:  train data num: 2100  dev data num: 727
11/14 09:50:23:  train data num: 2100  dev data num: 727
11/14 10:04:29:  New best model, new acc 0.1376 % >= previous acc -inf %
11/14 10:04:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 10:04:29:  Step:1, Best: 0.1376 %, Curr: 0.1376 %
11/14 10:04:35:  New best model, new acc 0.1376 % >= previous acc -inf %
11/14 10:04:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 10:04:35:  Step:1, Best: 0.1376 %, Curr: 0.1376 %
11/14 10:17:15:  New best model, new acc 0.1376 % >= previous acc 0.1376 %
11/14 10:17:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 10:17:15:  Step:2, Best: 0.1376 %, Curr: 0.1376 %
11/14 10:17:40:  New best model, new acc 0.1376 % >= previous acc 0.1376 %
11/14 10:17:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 10:17:40:  Step:2, Best: 0.1376 %, Curr: 0.1376 %
11/14 11:30:39:  train data num: 2100  dev data num: 727
11/14 11:30:39:  train data num: 2100  dev data num: 727
11/14 11:38:36:  train data num: 2100  dev data num: 727
11/14 11:38:36:  train data num: 2100  dev data num: 727
11/14 12:47:28:  train data num: 2100  dev data num: 727
11/14 12:47:28:  train data num: 2100  dev data num: 727
11/14 12:48:05:  train data num: 2100  dev data num: 727
11/14 12:48:05:  train data num: 2100  dev data num: 727
11/14 13:03:05:  train data num: 2100  dev data num: 727
11/14 13:03:05:  train data num: 2100  dev data num: 727
11/14 13:16:56:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 145, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 129, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 72, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 147, in _eval2save
    args.writer.add_scalar('eval_acc', f1, args.global_steps)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py", line 388, in add_scalar
    summary = scalar(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/summary.py", line 280, in scalar
    tensor = make_np(tensor).squeeze()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_convert_np.py", line 24, in make_np
    raise NotImplementedError(
NotImplementedError: Got <class 'tuple'>, but numpy array, torch tensor, or caffe2 blob name are expected.
11/14 13:17:15:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 145, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 129, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 72, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 147, in _eval2save
    args.writer.add_scalar('eval_acc', f1, args.global_steps)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py", line 388, in add_scalar
    summary = scalar(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/summary.py", line 280, in scalar
    tensor = make_np(tensor).squeeze()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_convert_np.py", line 24, in make_np
    raise NotImplementedError(
NotImplementedError: Got <class 'tuple'>, but numpy array, torch tensor, or caffe2 blob name are expected.
11/14 13:19:46:  train data num: 2100  dev data num: 727
11/14 13:19:46:  train data num: 2100  dev data num: 727
11/14 13:33:40:  New best model, new f1 0.2753 % >= previous f1 0.0000 %
11/14 13:33:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 13:33:40:  Step:1, Best: f10.275, p0.275,r0.275, Curr: f10.2753, p0.275,r0.275 
11/14 13:33:58:  New best model, new f1 0.2753 % >= previous f1 0.0000 %
11/14 13:33:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 13:33:58:  Step:1, Best: f10.275, p0.275,r0.275, Curr: f10.2753, p0.275,r0.275 
11/14 13:46:36:  New best model, new f1 0.2753 % >= previous f1 0.0000 %
11/14 13:46:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 13:46:36:  Step:2, Best: f10.275, p0.275,r0.275, Curr: f10.2753, p0.275,r0.275 
11/14 13:46:54:  New best model, new f1 0.2753 % >= previous f1 0.0000 %
11/14 13:46:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 13:46:54:  Step:2, Best: f10.275, p0.275,r0.275, Curr: f10.2753, p0.275,r0.275 
11/14 13:52:45:  train data num: 2100  dev data num: 727
11/14 13:52:45:  train data num: 2100  dev data num: 727
11/14 14:47:58:  New best model, new f1 0.2753 % >= previous f1 0.0000 %
11/14 14:47:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 14:47:58:  Step:10000, Best: f1:0.275, p:0.275,r:0.275, Curr: f1:0.2753, p:0.275,r:0.275 
11/14 14:48:08:  New best model, new f1 0.2753 % >= previous f1 0.0000 %
11/14 14:48:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 14:48:08:  Step:10000, Best: f1:0.275, p:0.275,r:0.275, Curr: f1:0.2753, p:0.275,r:0.275 
11/14 15:41:59:  New best model, new f1 0.5506 % >= previous f1 0.0000 %
11/14 15:41:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 15:41:59:  Step:20000, Best: f1:0.551, p:0.551,r:0.550, Curr: f1:0.5506, p:0.551,r:0.550 
11/14 15:42:19:  New best model, new f1 0.5506 % >= previous f1 0.0000 %
11/14 15:42:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 15:42:19:  Step:20000, Best: f1:0.551, p:0.551,r:0.550, Curr: f1:0.5506, p:0.551,r:0.550 
11/14 16:36:16:  New best model, new f1 2.3400 % >= previous f1 0.0000 %
11/14 16:36:16:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 16:36:16:  Step:30000, Best: f1:2.340, p:2.342,r:2.338, Curr: f1:2.3400, p:2.342,r:2.338 
11/14 16:36:36:  New best model, new f1 2.3400 % >= previous f1 0.0000 %
11/14 16:36:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 16:36:36:  Step:30000, Best: f1:2.340, p:2.342,r:2.338, Curr: f1:2.3400, p:2.342,r:2.338 
11/14 17:30:30:  New best model, new f1 19.0214 % >= previous f1 0.0000 %
11/14 17:30:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 17:30:30:  Step:40000, Best: f1:19.021, p:19.061,r:18.982, Curr: f1:19.0214, p:19.061,r:18.982 
11/14 17:30:50:  New best model, new f1 19.0214 % >= previous f1 0.0000 %
11/14 17:30:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 17:30:50:  Step:40000, Best: f1:19.021, p:19.061,r:18.982, Curr: f1:19.0214, p:19.061,r:18.982 
11/14 18:24:41:  New best model, new f1 28.7483 % >= previous f1 0.0000 %
11/14 18:24:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 18:24:41:  Step:50000, Best: f1:28.748, p:28.748,r:28.748, Curr: f1:28.7483, p:28.748,r:28.748 
11/14 18:25:03:  New best model, new f1 28.7483 % >= previous f1 0.0000 %
11/14 18:25:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 18:25:03:  Step:50000, Best: f1:28.748, p:28.748,r:28.748, Curr: f1:28.7483, p:28.748,r:28.748 
11/14 19:18:59:  New best model, new f1 34.2503 % >= previous f1 0.0000 %
11/14 19:18:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 19:18:59:  Step:60000, Best: f1:34.250, p:34.250,r:34.250, Curr: f1:34.2503, p:34.250,r:34.250 
11/14 19:19:01:  New best model, new f1 34.2503 % >= previous f1 0.0000 %
11/14 19:19:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 19:19:01:  Step:60000, Best: f1:34.250, p:34.250,r:34.250, Curr: f1:34.2503, p:34.250,r:34.250 
11/14 20:13:02:  New best model, new f1 39.3398 % >= previous f1 0.0000 %
11/14 20:13:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 20:13:02:  Step:70000, Best: f1:39.340, p:39.340,r:39.340, Curr: f1:39.3398, p:39.340,r:39.340 
11/14 20:13:05:  New best model, new f1 39.3398 % >= previous f1 0.0000 %
11/14 20:13:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 20:13:05:  Step:70000, Best: f1:39.340, p:39.340,r:39.340, Curr: f1:39.3398, p:39.340,r:39.340 
11/14 21:06:57:  New best model, new f1 44.1541 % >= previous f1 0.0000 %
11/14 21:06:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 21:06:57:  Step:80000, Best: f1:44.154, p:44.154,r:44.154, Curr: f1:44.1541, p:44.154,r:44.154 
11/14 21:07:16:  New best model, new f1 44.1541 % >= previous f1 0.0000 %
11/14 21:07:16:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 21:07:16:  Step:80000, Best: f1:44.154, p:44.154,r:44.154, Curr: f1:44.1541, p:44.154,r:44.154 
11/14 22:01:18:  New best model, new f1 45.1169 % >= previous f1 0.0000 %
11/14 22:01:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 22:01:18:  Step:90000, Best: f1:45.117, p:45.117,r:45.117, Curr: f1:45.1169, p:45.117,r:45.117 
11/14 22:01:18:  New best model, new f1 45.1169 % >= previous f1 0.0000 %
11/14 22:01:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 22:01:18:  Step:90000, Best: f1:45.117, p:45.117,r:45.117, Curr: f1:45.1169, p:45.117,r:45.117 
11/14 22:55:10:  New best model, new f1 47.3177 % >= previous f1 0.0000 %
11/14 22:55:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 22:55:10:  Step:100000, Best: f1:47.318, p:47.318,r:47.318, Curr: f1:47.3177, p:47.318,r:47.318 
11/14 22:55:12:  New best model, new f1 47.3177 % >= previous f1 0.0000 %
11/14 22:55:12:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 22:55:12:  Step:100000, Best: f1:47.318, p:47.318,r:47.318, Curr: f1:47.3177, p:47.318,r:47.318 
11/14 23:49:06:  New best model, new f1 48.8308 % >= previous f1 0.0000 %
11/14 23:49:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 23:49:06:  Step:110000, Best: f1:48.831, p:48.831,r:48.831, Curr: f1:48.8308, p:48.831,r:48.831 
11/14 23:49:25:  New best model, new f1 48.8308 % >= previous f1 0.0000 %
11/14 23:49:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/14 23:49:25:  Step:110000, Best: f1:48.831, p:48.831,r:48.831, Curr: f1:48.8308, p:48.831,r:48.831 
11/15 00:43:18:  New best model, new f1 51.0316 % >= previous f1 0.0000 %
11/15 00:43:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 00:43:19:  Step:120000, Best: f1:51.032, p:51.032,r:51.032, Curr: f1:51.0316, p:51.032,r:51.032 
11/15 00:43:39:  New best model, new f1 51.0316 % >= previous f1 0.0000 %
11/15 00:43:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 00:43:39:  Step:120000, Best: f1:51.032, p:51.032,r:51.032, Curr: f1:51.0316, p:51.032,r:51.032 
11/15 01:37:33:  New best model, new f1 50.6190 % >= previous f1 0.0000 %
11/15 01:37:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 01:37:33:  Step:130000, Best: f1:50.619, p:50.619,r:50.619, Curr: f1:50.6190, p:50.619,r:50.619 
11/15 01:37:52:  New best model, new f1 50.6190 % >= previous f1 0.0000 %
11/15 01:37:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 01:37:52:  Step:130000, Best: f1:50.619, p:50.619,r:50.619, Curr: f1:50.6190, p:50.619,r:50.619 
11/15 02:24:27:  train data num: 2100  dev data num: 727
11/15 02:24:27:  train data num: 2100  dev data num: 727
11/15 02:25:42:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 145, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 126, in _main
    args.best_f1, args.best_precision, args.best_recall = _eval2save(args) if args.eval_before_train else float('-inf')
TypeError: cannot unpack non-iterable float object
11/15 02:25:42:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 145, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 126, in _main
    args.best_f1, args.best_precision, args.best_recall = _eval2save(args) if args.eval_before_train else float('-inf')
TypeError: cannot unpack non-iterable float object
11/15 02:27:43:  train data num: 2100  dev data num: 727
11/15 02:27:43:  train data num: 2100  dev data num: 727
11/15 02:30:05:  train data num: 2100  dev data num: 727
11/15 02:30:05:  train data num: 2100  dev data num: 727
11/15 03:17:36:  train data num: 2100  dev data num: 727
11/15 03:17:36:  train data num: 2100  dev data num: 727
11/15 03:18:56:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:18:56:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:18:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:18:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:18:56:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:18:56:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:18:58:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:18:58:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:18:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:18:58:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:18:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:18:58:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:00:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:00:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:00:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:00:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:03:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:03:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:05:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:05:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:08:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:08:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:10:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:10:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:10:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:10:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:12:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:12:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:12:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:12:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:12:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:12:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:15:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:15:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:15:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:15:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:17:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:17:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:19:  Step:11, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:19:  Step:11, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:22:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:22:  Step:12, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:19:22:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:19:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:19:22:  Step:12, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:20:03:  train data num: 2100  dev data num: 727
11/15 03:20:03:  train data num: 2100  dev data num: 727
11/15 03:21:25:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:25:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:25:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:25:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:25:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:25:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:30:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:30:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:30:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:30:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:30:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:30:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:35:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:35:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:35:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:35:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:35:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:35:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:40:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:40:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:40:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:40:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:44:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:44:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:44:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:44:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:44:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:44:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:49:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:49:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:49:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:49:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:49:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:49:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:54:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:54:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:54:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:54:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:59:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:59:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:59:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:21:59:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:21:59:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:21:59:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:22:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:22:03:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:22:03:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:22:03:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:03:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:22:08:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:22:08:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:22:08:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:22:08:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:12:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:22:12:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:22:12:  Step:11, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:12:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:22:13:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:22:13:  Step:11, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:22:17:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:22:17:  Step:12, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:22:17:  Save to ./checkpoint/llama_linear_1token_10examples.pkl
11/15 03:22:17:  Step:12, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:22:49:  train data num: 2100  dev data num: 727
11/15 03:22:49:  train data num: 2100  dev data num: 727
11/15 03:24:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:24:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:24:17:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:24:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:24:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:24:17:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:24:29:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:24:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:24:29:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:24:29:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:24:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:24:29:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:24:41:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:24:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:24:41:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:24:41:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:24:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:24:41:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:24:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:24:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:24:52:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:24:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:24:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:24:53:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:04:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:05:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:17:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:17:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:28:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:29:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:29:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:29:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:40:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:40:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:52:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:25:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:25:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:25:52:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:04:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:04:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:16:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:16:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:16:  Step:11, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:16:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:16:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:16:  Step:11, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:28:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:28:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:28:  Step:12, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:28:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:28:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:28:  Step:12, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:40:  Step:13, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:40:  Step:13, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:52:  Step:14, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:26:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:26:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:26:52:  Step:14, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:27:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:27:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:27:04:  Step:15, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:27:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/15 03:27:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:27:04:  Step:15, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/15 03:27:40:  train data num: 2100  dev data num: 727
11/15 03:27:40:  train data num: 2100  dev data num: 727
11/15 03:28:35:  train data num: 2100  dev data num: 727
11/15 03:28:35:  train data num: 2100  dev data num: 727
11/15 03:30:40:  New best model, new f1 1.5267 % >= previous f1 0.0000 %
11/15 03:30:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:30:40:  Step:1, Best: f1:1.527, p:1.961,r:1.250, Curr: f1:1.5267, p:1.961,r:1.250 
11/15 03:30:41:  New best model, new f1 1.5267 % >= previous f1 0.0000 %
11/15 03:30:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 03:30:41:  Step:1, Best: f1:1.527, p:1.961,r:1.250, Curr: f1:1.5267, p:1.961,r:1.250 
11/15 03:32:30:  train data num: 2100  dev data num: 727
11/15 03:32:30:  train data num: 2100  dev data num: 727
11/15 04:29:56:  New best model, new f1 0.2165 % >= previous f1 0.0000 %
11/15 04:29:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 04:29:56:  Step:10000, Best: f1:0.216, p:0.275,r:0.178, Curr: f1:0.2165, p:0.275,r:0.178 
11/15 04:30:12:  New best model, new f1 0.2165 % >= previous f1 0.0000 %
11/15 04:30:12:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 04:30:12:  Step:10000, Best: f1:0.216, p:0.275,r:0.178, Curr: f1:0.2165, p:0.275,r:0.178 
11/15 05:26:14:  New best model, new f1 0.8658 % >= previous f1 0.2165 %
11/15 05:26:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 05:26:14:  Step:20000, Best: f1:0.866, p:1.102,r:0.713, Curr: f1:0.8658, p:1.102,r:0.713 
11/15 05:26:26:  New best model, new f1 0.8658 % >= previous f1 0.2165 %
11/15 05:26:27:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 05:26:27:  Step:20000, Best: f1:0.866, p:1.102,r:0.713, Curr: f1:0.8658, p:1.102,r:0.713 
11/15 06:22:27:  New best model, new f1 3.6797 % >= previous f1 0.8658 %
11/15 06:22:27:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 06:22:27:  Step:30000, Best: f1:3.680, p:4.683,r:3.030, Curr: f1:3.6797, p:4.683,r:3.030 
11/15 06:22:42:  New best model, new f1 3.6797 % >= previous f1 0.8658 %
11/15 06:22:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 06:22:42:  Step:30000, Best: f1:3.680, p:4.683,r:3.030, Curr: f1:3.6797, p:4.683,r:3.030 
11/15 07:18:51:  New best model, new f1 20.5850 % >= previous f1 3.6797 %
11/15 07:18:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 07:18:51:  Step:40000, Best: f1:20.585, p:26.243,r:16.934, Curr: f1:20.5850, p:26.243,r:16.934 
11/15 07:19:05:  New best model, new f1 20.5850 % >= previous f1 3.6797 %
11/15 07:19:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 07:19:05:  Step:40000, Best: f1:20.585, p:26.243,r:16.934, Curr: f1:20.5850, p:26.243,r:16.934 
11/15 08:15:09:  New best model, new f1 31.8794 % >= previous f1 20.5850 %
11/15 08:15:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 08:15:09:  Step:50000, Best: f1:31.879, p:40.272,r:26.381, Curr: f1:31.8794, p:40.272,r:26.381 
11/15 08:15:26:  New best model, new f1 31.8794 % >= previous f1 20.5850 %
11/15 08:15:26:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 08:15:26:  Step:50000, Best: f1:31.879, p:40.272,r:26.381, Curr: f1:31.8794, p:40.272,r:26.381 
11/15 09:11:30:  New best model, new f1 34.3532 % >= previous f1 31.8794 %
11/15 09:11:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 09:11:30:  Step:60000, Best: f1:34.353, p:43.185,r:28.520, Curr: f1:34.3532, p:43.185,r:28.520 
11/15 09:11:45:  New best model, new f1 34.3532 % >= previous f1 31.8794 %
11/15 09:11:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 09:11:45:  Step:60000, Best: f1:34.353, p:43.185,r:28.520, Curr: f1:34.3532, p:43.185,r:28.520 
11/15 10:07:48:  New best model, new f1 37.4866 % >= previous f1 34.3532 %
11/15 10:07:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 10:07:48:  Step:70000, Best: f1:37.487, p:47.162,r:31.105, Curr: f1:37.4866, p:47.162,r:31.105 
11/15 10:08:04:  New best model, new f1 37.4866 % >= previous f1 34.3532 %
11/15 10:08:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 10:08:04:  Step:70000, Best: f1:37.487, p:47.162,r:31.105, Curr: f1:37.4866, p:47.162,r:31.105 
11/15 11:04:11:  New best model, new f1 39.7867 % >= previous f1 37.4866 %
11/15 11:04:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 11:04:11:  Step:80000, Best: f1:39.787, p:49.535,r:33.244, Curr: f1:39.7867, p:49.535,r:33.244 
11/15 11:04:16:  New best model, new f1 39.7867 % >= previous f1 37.4866 %
11/15 11:04:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 11:04:17:  Step:80000, Best: f1:39.787, p:49.535,r:33.244, Curr: f1:39.7867, p:49.535,r:33.244 
11/15 12:00:23:  New best model, new f1 42.9180 % >= previous f1 39.7867 %
11/15 12:00:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 12:00:23:  Step:90000, Best: f1:42.918, p:53.307,r:35.918, Curr: f1:42.9180, p:53.307,r:35.918 
11/15 12:00:28:  New best model, new f1 42.9180 % >= previous f1 39.7867 %
11/15 12:00:28:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 12:00:28:  Step:90000, Best: f1:42.918, p:53.307,r:35.918, Curr: f1:42.9180, p:53.307,r:35.918 
11/15 12:56:28:  New best model, new f1 45.2026 % >= previous f1 42.9180 %
11/15 12:56:28:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 12:56:28:  Step:100000, Best: f1:45.203, p:56.233,r:37.790, Curr: f1:45.2026, p:56.233,r:37.790 
11/15 12:56:35:  New best model, new f1 45.2026 % >= previous f1 42.9180 %
11/15 12:56:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 12:56:35:  Step:100000, Best: f1:45.203, p:56.233,r:37.790, Curr: f1:45.2026, p:56.233,r:37.790 
11/15 13:52:49:  New best model, new f1 46.5315 % >= previous f1 45.2026 %
11/15 13:52:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 13:52:49:  Step:110000, Best: f1:46.531, p:57.979,r:38.859, Curr: f1:46.5315, p:57.979,r:38.859 
11/15 13:52:56:  New best model, new f1 46.5315 % >= previous f1 45.2026 %
11/15 13:52:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 13:52:56:  Step:110000, Best: f1:46.531, p:57.979,r:38.859, Curr: f1:46.5315, p:57.979,r:38.859 
11/15 14:49:01:  New best model, new f1 48.5302 % >= previous f1 46.5315 %
11/15 14:49:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 14:49:01:  Step:120000, Best: f1:48.530, p:60.614,r:40.463, Curr: f1:48.5302, p:60.614,r:40.463 
11/15 14:49:15:  New best model, new f1 48.5302 % >= previous f1 46.5315 %
11/15 14:49:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 14:49:15:  Step:120000, Best: f1:48.530, p:60.614,r:40.463, Curr: f1:48.5302, p:60.614,r:40.463 
11/15 15:45:25:  do not save, best f1: 48.5302
11/15 15:45:25:  Step:130000, Best: f1:48.530, p:60.614,r:40.463, Curr: f1:48.0554, p:59.735,r:40.196 
11/15 15:45:28:  do not save, best f1: 48.5302
11/15 15:45:28:  Step:130000, Best: f1:48.530, p:60.614,r:40.463, Curr: f1:48.0554, p:59.735,r:40.196 
11/15 16:41:30:  do not save, best f1: 48.5302
11/15 16:41:30:  Step:140000, Best: f1:48.530, p:60.614,r:40.463, Curr: f1:48.2171, p:59.841,r:40.374 
11/15 16:41:36:  do not save, best f1: 48.5302
11/15 16:41:36:  Step:140000, Best: f1:48.530, p:60.614,r:40.463, Curr: f1:48.2171, p:59.841,r:40.374 
11/15 17:37:45:  New best model, new f1 49.0967 % >= previous f1 48.5302 %
11/15 17:37:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 17:37:45:  Step:150000, Best: f1:49.097, p:60.789,r:41.176, Curr: f1:49.0967, p:60.789,r:41.176 
11/15 17:37:48:  New best model, new f1 49.0967 % >= previous f1 48.5302 %
11/15 17:37:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 17:37:48:  Step:150000, Best: f1:49.097, p:60.789,r:41.176, Curr: f1:49.0967, p:60.789,r:41.176 
11/15 18:33:47:  do not save, best f1: 49.0967
11/15 18:33:47:  Step:160000, Best: f1:49.097, p:60.789,r:41.176, Curr: f1:48.9622, p:60.766,r:40.998 
11/15 18:33:55:  do not save, best f1: 49.0967
11/15 18:33:55:  Step:160000, Best: f1:49.097, p:60.789,r:41.176, Curr: f1:48.9622, p:60.766,r:40.998 
11/15 19:29:59:  New best model, new f1 49.5218 % >= previous f1 49.0967 %
11/15 19:29:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 19:29:59:  Step:170000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:49.5218, p:61.316,r:41.533 
11/15 19:30:03:  New best model, new f1 49.5218 % >= previous f1 49.0967 %
11/15 19:30:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/15 19:30:03:  Step:170000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:49.5218, p:61.316,r:41.533 
11/15 20:26:05:  do not save, best f1: 49.5218
11/15 20:26:05:  Step:180000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:48.4076, p:59.843,r:40.642 
11/15 20:26:11:  do not save, best f1: 49.5218
11/15 20:26:11:  Step:180000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:48.4076, p:59.843,r:40.642 
11/15 21:22:10:  do not save, best f1: 49.5218
11/15 21:22:10:  Step:190000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:47.8560, p:58.931,r:40.285 
11/15 21:22:27:  do not save, best f1: 49.5218
11/15 21:22:27:  Step:190000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:47.8560, p:58.931,r:40.285 
11/15 22:18:33:  do not save, best f1: 49.5218
11/15 22:18:33:  Step:200000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:47.9365, p:58.984,r:40.374 
11/15 22:18:38:  do not save, best f1: 49.5218
11/15 22:18:38:  Step:200000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:47.9365, p:58.984,r:40.374 
11/15 23:14:37:  do not save, best f1: 49.5218
11/15 23:14:37:  Step:210000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:46.0805, p:56.789,r:38.770 
11/15 23:14:53:  do not save, best f1: 49.5218
11/15 23:14:53:  Step:210000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:46.0805, p:56.789,r:38.770 
11/15 23:27:15:  do not save, best f1: 49.5218
11/15 23:27:15:  Step:210000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:46.0805, p:56.789,r:38.770 
11/15 23:27:46:  do not save, best f1: 49.5218
11/15 23:27:46:  Step:210000, Best: f1:49.522, p:61.316,r:41.533, Curr: f1:46.0805, p:56.789,r:38.770 
11/16 08:57:37:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 151, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _main
    aspect_predictor = aspect_predictor(args.data_file['train'], args=args)
UnboundLocalError: local variable 'aspect_predictor' referenced before assignment
11/16 08:57:37:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 151, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _main
    aspect_predictor = aspect_predictor(args.data_file['train'], args=args)
UnboundLocalError: local variable 'aspect_predictor' referenced before assignment
11/16 09:59:03:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 151, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _main
    aspect_predictor = aspect_predict(args.data_file['train'], args=args)
  File "/workspace/GEMEL/twitter/code/aspect.py", line 23, in __init__
    pretrain_path = os.path.joint(args.weight_dir, "pretrain")
AttributeError: module 'posixpath' has no attribute 'joint'
11/16 09:59:03:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 151, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _main
    aspect_predictor = aspect_predict(args.data_file['train'], args=args)
  File "/workspace/GEMEL/twitter/code/aspect.py", line 23, in __init__
    pretrain_path = os.path.joint(args.weight_dir, "pretrain")
AttributeError: module 'posixpath' has no attribute 'joint'
11/16 09:59:35:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 151, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _main
    aspect_predictor = aspect_predict(args.data_file['train'], args=args)
  File "/workspace/GEMEL/twitter/code/aspect.py", line 24, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(os.path.join(pretrain_path, "deberta-base"), add_prefix_space=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py", line 686, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py", line 519, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../../_llm_weight/pretrain/deberta-base'. Use `repo_type` argument if needed.
11/16 09:59:35:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 151, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _main
    aspect_predictor = aspect_predict(args.data_file['train'], args=args)
  File "/workspace/GEMEL/twitter/code/aspect.py", line 24, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(os.path.join(pretrain_path, "deberta-base"), add_prefix_space=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py", line 686, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py", line 519, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py", line 429, in cached_file
    resolved_file = hf_hub_download(
  File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../../_llm_weight/pretrain/deberta-base'. Use `repo_type` argument if needed.
11/16 15:40:15:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 148, in predict
    raw_data = self.process_data(tokenized_inputs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 134, in process_data
    inputs_dir = os.path.join(self.dataset_dir, file_name)
AttributeError: 'aspect_predict' object has no attribute 'dataset_dir'
11/16 15:40:15:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 148, in predict
    raw_data = self.process_data(tokenized_inputs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 134, in process_data
    inputs_dir = os.path.join(self.dataset_dir, file_name)
AttributeError: 'aspect_predict' object has no attribute 'dataset_dir'
11/16 15:42:24:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 150, in predict
    raw_data = self.process_data(tokenized_inputs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 138, in process_data
    data = torch.load(inputs_dir)
  File "/usr/local/lib/python3.10/dist-packages/torch/serialization.py", line 815, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/usr/local/lib/python3.10/dist-packages/torch/serialization.py", line 1033, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
EOFError: Ran out of input
11/17 08:13:35:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 93, in _main
    aspect_predictor = aspect_method(args.data_file['train'], args=args)
TypeError: aspect_method.__init__() got multiple values for argument 'args'
11/17 08:13:35:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 93, in _main
    aspect_predictor = aspect_method(args.data_file['train'], args=args)
TypeError: aspect_method.__init__() got multiple values for argument 'args'
11/17 08:14:05:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 237, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 69, in __init__
    tokenized_inputs = self.tokenize_data( self._get_data(self.file))
TypeError: aspect_dataset.tokenize_data() missing 5 required positional arguments: 'image_l', 'label_l', 'pair_l', 'senti_l', and 'allabel_l'
11/17 08:14:05:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 237, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 69, in __init__
    tokenized_inputs = self.tokenize_data( self._get_data(self.file))
TypeError: aspect_dataset.tokenize_data() missing 5 required positional arguments: 'image_l', 'label_l', 'pair_l', 'senti_l', and 'allabel_l'
11/17 08:15:51:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 243, in predict
    text_config, image_config, text_pretrained_dict, image_pretrained_dict = self.model_select("deberta")
AttributeError: 'aspect_method' object has no attribute 'model_select'
11/17 08:15:59:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 243, in predict
    text_config, image_config, text_pretrained_dict, image_pretrained_dict = self.model_select("deberta")
AttributeError: 'aspect_method' object has no attribute 'model_select'
11/17 08:17:30:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 237, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 65, in __init__
    tokenized_inputs = self.tokenize_data(sentence_l, image_l, label_l, pair_l, senti_l, allabel_l)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 142, in tokenize_data
    processor = AutoProcessor.from_pretrained(self.image_model_path)
AttributeError: 'aspect_dataset' object has no attribute 'image_model_path'
11/17 08:17:30:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 237, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 65, in __init__
    tokenized_inputs = self.tokenize_data(sentence_l, image_l, label_l, pair_l, senti_l, allabel_l)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 142, in tokenize_data
    processor = AutoProcessor.from_pretrained(self.image_model_path)
AttributeError: 'aspect_dataset' object has no attribute 'image_model_path'
11/17 08:19:53:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 252, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 77, in __getitem__
    for key in self.inputs.keys():
AttributeError: 'aspect_dataset' object has no attribute 'inputs'
11/17 08:19:56:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 252, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 77, in __getitem__
    for key in self.inputs.keys():
AttributeError: 'aspect_dataset' object has no attribute 'inputs'
11/17 08:48:09:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 263, in predict
    t_total = len(train_dataloader) * self.args.epochs
AttributeError: 'Namespace' object has no attribute 'epochs'
11/17 08:48:09:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 263, in predict
    t_total = len(train_dataloader) * self.args.epochs
AttributeError: 'Namespace' object has no attribute 'epochs'
11/17 08:49:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 280, in predict
    aspect_outputs = model(**batch)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
TypeError: ASPModel.forward() got an unexpected keyword argument 'token_type_ids'
11/17 08:49:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 280, in predict
    aspect_outputs = model(**batch)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
TypeError: ASPModel.forward() got an unexpected keyword argument 'token_type_ids'
11/17 09:01:50:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 296, in predict
    global_step += 1
UnboundLocalError: local variable 'global_step' referenced before assignment
11/17 09:01:50:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 296, in predict
    global_step += 1
UnboundLocalError: local variable 'global_step' referenced before assignment
11/17 10:33:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 392, in predict
    results, _ = self.evaluate(self.args, model, dev_dataloader, dev_data, dev_data["pairs"])
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 130, in __getitem__
    d[key] = self.raw_data[key][index]
IndexError: too many indices for tensor of dimension 2
11/17 10:33:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 392, in predict
    results, _ = self.evaluate(self.args, model, dev_dataloader, dev_data, dev_data["pairs"])
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 130, in __getitem__
    d[key] = self.raw_data[key][index]
IndexError: too many indices for tensor of dimension 2
11/17 10:38:01:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 337, in predict
    dev_data = aspect_dataset(self.args.data_file['test'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 122, in __init__
    self.raw_data = self.process_data(tokenized_inputs, refresh_data=False)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 253, in process_data
    data = torch.load(inputs_dir)
  File "/usr/local/lib/python3.10/dist-packages/torch/serialization.py", line 815, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/usr/local/lib/python3.10/dist-packages/torch/serialization.py", line 1033, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
EOFError: Ran out of input
11/17 10:38:46:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 394, in predict
    results, _ = self.evaluate(self.args, model, dev_dataloader, dev_data, dev_data["pairs"])
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 132, in __getitem__
    d[key] = self.raw_data[key][index]
IndexError: too many indices for tensor of dimension 2
11/17 10:39:49:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 337, in predict
    dev_data = aspect_dataset(self.args.data_file['test'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 122, in __init__
    self.raw_data = self.process_data(tokenized_inputs, refresh_data=False)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 253, in process_data
    data = torch.load(inputs_dir)
  File "/usr/local/lib/python3.10/dist-packages/torch/serialization.py", line 797, in load
    with _open_zipfile_reader(opened_file) as opened_zipfile:
  File "/usr/local/lib/python3.10/dist-packages/torch/serialization.py", line 283, in __init__
    super().__init__(torch._C.PyTorchFileReader(name_or_buffer))
RuntimeError: PytorchStreamReader failed reading zip archive: failed finding central directory
11/17 10:42:17:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 394, in predict
    if results["aspect_f1"] >= best_result["aspect_f1"]:
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 132, in __getitem__
IndexError: too many indices for tensor of dimension 2
11/17 10:42:17:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 394, in predict
    if results["aspect_f1"] >= best_result["aspect_f1"]:
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 132, in __getitem__
IndexError: too many indices for tensor of dimension 2
11/17 10:44:56:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 394, in predict
    results, _ = self.evaluate(self.args, model, dev_dataloader, dev_data, dev_data["pairs"])
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 128, in __getitem__
    d[key] = self.raw_data[key][index]
IndexError: too many indices for tensor of dimension 2
11/17 10:44:56:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 394, in predict
    results, _ = self.evaluate(self.args, model, dev_dataloader, dev_data, dev_data["pairs"])
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 128, in __getitem__
    d[key] = self.raw_data[key][index]
IndexError: too many indices for tensor of dimension 2
11/17 10:47:19:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 372, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 138, in collate
    raise RuntimeError('each element in list of batch should be of equal size')
RuntimeError: each element in list of batch should be of equal size
11/17 10:47:19:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 372, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 138, in collate
    raise RuntimeError('each element in list of batch should be of equal size')
RuntimeError: each element in list of batch should be of equal size
11/17 10:50:18:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 372, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 138, in collate
    raise RuntimeError('each element in list of batch should be of equal size')
RuntimeError: each element in list of batch should be of equal size
11/17 10:50:25:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 372, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 138, in collate
    raise RuntimeError('each element in list of batch should be of equal size')
RuntimeError: each element in list of batch should be of equal size
11/17 10:55:15:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 339, in predict
    train_pairs = train_data["pairs"]
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 128, in __getitem__
    d[key] = self.raw_data[key][index]
IndexError: too many indices for tensor of dimension 2
11/17 10:55:15:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 339, in predict
    train_pairs = train_data["pairs"]
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 128, in __getitem__
    d[key] = self.raw_data[key][index]
IndexError: too many indices for tensor of dimension 2
11/17 12:11:32:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 375, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 138, in collate
    raise RuntimeError('each element in list of batch should be of equal size')
RuntimeError: each element in list of batch should be of equal size
11/17 12:11:32:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 375, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 138, in collate
    raise RuntimeError('each element in list of batch should be of equal size')
RuntimeError: each element in list of batch should be of equal size
11/17 12:13:31:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 375, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 138, in collate
    raise RuntimeError('each element in list of batch should be of equal size')
RuntimeError: each element in list of batch should be of equal size
11/17 12:13:31:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 375, in predict
    for step, batch in tqdm(enumerate(train_dataloader), desc="Train", ncols=50, total=len(train_dataloader)):
  File "/usr/local/lib/python3.10/dist-packages/tqdm/std.py", line 1178, in __iter__
    for obj in iterable:
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 265, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in collate
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 127, in <dictcomp>
    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py", line 138, in collate
    raise RuntimeError('each element in list of batch should be of equal size')
RuntimeError: each element in list of batch should be of equal size
11/17 12:34:33:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 340, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 120, in __init__
    self.raw_data, self.pairs = self.process_data(refresh_data=args.refresh_aspect_data)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 263, in process_data
    print(k.size())
AttributeError: 'list' object has no attribute 'size'
11/17 12:34:33:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 340, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 120, in __init__
    self.raw_data, self.pairs = self.process_data(refresh_data=args.refresh_aspect_data)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 263, in process_data
    print(k.size())
AttributeError: 'list' object has no attribute 'size'
11/17 12:35:48:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 341, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 120, in __init__
    self.raw_data, self.pairs = self.process_data(refresh_data=args.refresh_aspect_data)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 264, in process_data
    print(v.size())
AttributeError: 'list' object has no attribute 'size'
11/17 12:35:48:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 341, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 120, in __init__
    self.raw_data, self.pairs = self.process_data(refresh_data=args.refresh_aspect_data)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 264, in process_data
    print(v.size())
AttributeError: 'list' object has no attribute 'size'
11/17 12:39:04:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 341, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 120, in __init__
    self.raw_data, self.pairs = self.process_data(refresh_data=args.refresh_aspect_data)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 264, in process_data
    print(v.size())
AttributeError: 'list' object has no attribute 'size'
11/17 12:39:10:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 341, in predict
    train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 120, in __init__
    self.raw_data, self.pairs = self.process_data(refresh_data=args.refresh_aspect_data)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 264, in process_data
    print(v.size())
AttributeError: 'list' object has no attribute 'size'
11/17 12:42:35:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 397, in predict
    results, _ = self.evaluate(self.args, model, dev_dataloader, dev_data, dev_pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 313, in evaluate
    aspect_span = logits2span(p_pred_labels=aspect_logits, text_inputs=text_inputs, p_pairs=pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 25, in logits2span
    word_ids = text_inputs.word_ids(batch_index=i)
AttributeError: 'aspect_dataset' object has no attribute 'word_ids'
11/17 12:42:35:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 152, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 397, in predict
    results, _ = self.evaluate(self.args, model, dev_dataloader, dev_data, dev_pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 313, in evaluate
    aspect_span = logits2span(p_pred_labels=aspect_logits, text_inputs=text_inputs, p_pairs=pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 25, in logits2span
    word_ids = text_inputs.word_ids(batch_index=i)
AttributeError: 'aspect_dataset' object has no attribute 'word_ids'
11/21 03:41:32:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 161, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 343, in predict
    text_config, image_config, text_pretrained_dict, image_pretrained_dict = self.model_select("deberta")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 284, in model_select
    model_path1 = os.path.join(self.pretrain_path, 'deberta')
AttributeError: 'str' object has no attribute 'pretrain_path'
11/21 03:41:32:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 161, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 94, in _main
    aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 343, in predict
    text_config, image_config, text_pretrained_dict, image_pretrained_dict = self.model_select("deberta")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 284, in model_select
    model_path1 = os.path.join(self.pretrain_path, 'deberta')
AttributeError: 'str' object has no attribute 'pretrain_path'
11/21 03:55:28:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 161, in <module>
    except Exception as e:
  File "/workspace/GEMEL/twitter/code/main.py", line 96, in _main
    text_config, image_config, text_pretrained_dict, image_pretrained_dict = aspect_predictor.model_select("deberta")
NameError: name 'self' is not defined
11/21 03:55:29:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 161, in <module>
    except Exception as e:
  File "/workspace/GEMEL/twitter/code/main.py", line 96, in _main
    text_config, image_config, text_pretrained_dict, image_pretrained_dict = aspect_predictor.model_select("deberta")
NameError: name 'self' is not defined
11/21 03:57:43:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 161, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 98, in _main
    apsect_predict_model = ASPModel(text_config, image_config, text_num_labels=3, alpha=args.alpha, beta=args.beta)
NameError: name 'ASPModel' is not defined
11/21 03:57:43:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 161, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 98, in _main
    apsect_predict_model = ASPModel(text_config, image_config, text_num_labels=3, alpha=args.alpha, beta=args.beta)
NameError: name 'ASPModel' is not defined
11/21 03:58:21:  train data num: 2100  dev data num: 727
11/21 03:58:21:  train data num: 2100  dev data num: 727
11/21 04:55:43:  New best model, new f1 0.2165 % >= previous f1 0.0000 %
11/21 04:55:43:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/21 04:55:43:  Step:10000, Best: f1:0.216, p:0.275,r:0.178, Curr: f1:0.2165, p:0.275,r:0.178 
11/21 04:55:53:  New best model, new f1 0.2165 % >= previous f1 0.0000 %
11/21 04:55:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/21 04:55:53:  Step:10000, Best: f1:0.216, p:0.275,r:0.178, Curr: f1:0.2165, p:0.275,r:0.178 
11/21 05:52:00:  New best model, new f1 0.8658 % >= previous f1 0.2165 %
11/21 05:52:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/21 05:52:00:  Step:20000, Best: f1:0.866, p:1.102,r:0.713, Curr: f1:0.8658, p:1.102,r:0.713 
11/21 05:52:10:  New best model, new f1 0.8658 % >= previous f1 0.2165 %
11/21 05:52:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/21 05:52:10:  Step:20000, Best: f1:0.866, p:1.102,r:0.713, Curr: f1:0.8658, p:1.102,r:0.713 
11/21 06:48:20:  New best model, new f1 4.0043 % >= previous f1 0.8658 %
11/21 06:48:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/21 06:48:21:  Step:30000, Best: f1:4.004, p:5.096,r:3.298, Curr: f1:4.0043, p:5.096,r:3.298 
11/21 06:48:31:  New best model, new f1 4.0043 % >= previous f1 0.8658 %
11/21 06:48:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/21 06:48:31:  Step:30000, Best: f1:4.004, p:5.096,r:3.298, Curr: f1:4.0043, p:5.096,r:3.298 
11/21 07:44:44:  New best model, new f1 20.4656 % >= previous f1 4.0043 %
11/21 07:44:44:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/21 07:44:44:  Step:40000, Best: f1:20.466, p:26.069,r:16.845, Curr: f1:20.4656, p:26.069,r:16.845 
11/21 07:44:49:  New best model, new f1 20.4656 % >= previous f1 4.0043 %
11/21 07:44:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/21 07:44:49:  Step:40000, Best: f1:20.466, p:26.069,r:16.845, Curr: f1:20.4656, p:26.069,r:16.845 
11/21 09:44:44:  train data num: 2100  dev data num: 727
11/21 09:44:44:  train data num: 2100  dev data num: 727
11/21 10:14:54:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    aspect = aspect_predictor.predict()
TypeError: aspect_method.predict() missing 1 required positional argument: 'args'
11/21 10:14:54:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    aspect = aspect_predictor.predict()
TypeError: aspect_method.predict() missing 1 required positional argument: 'args'
11/21 10:19:40:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    aspect = aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 422, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dev_dataloader, self.dev_data.raw_data, self.dev_data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 330, in evaluate
    span_pred_sum = np.hstack(span_list)  # predict span
  File "<__array_function__ internals>", line 200, in hstack
  File "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py", line 363, in hstack
    arrs = atleast_1d(*tup)
  File "<__array_function__ internals>", line 200, in atleast_1d
  File "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py", line 65, in atleast_1d
    ary = asanyarray(ary)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.
11/21 10:19:40:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    aspect = aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 422, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dev_dataloader, self.dev_data.raw_data, self.dev_data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 330, in evaluate
    span_pred_sum = np.hstack(span_list)  # predict span
  File "<__array_function__ internals>", line 200, in hstack
  File "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py", line 363, in hstack
    arrs = atleast_1d(*tup)
  File "<__array_function__ internals>", line 200, in atleast_1d
  File "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py", line 65, in atleast_1d
    ary = asanyarray(ary)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.
11/21 10:24:44:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    aspect = aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 422, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dev_dataloader, self.dev_data.raw_data, self.dev_data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 330, in evaluate
    span_pred_sum = np.vstack(span_list)  # predict span
  File "<__array_function__ internals>", line 200, in vstack
  File "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py", line 293, in vstack
    arrs = atleast_2d(*tup)
  File "<__array_function__ internals>", line 200, in atleast_2d
  File "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py", line 121, in atleast_2d
    ary = asanyarray(ary)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.
11/21 10:24:44:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    aspect = aspect_predictor.predict()
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 422, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dev_dataloader, self.dev_data.raw_data, self.dev_data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 330, in evaluate
    span_pred_sum = np.vstack(span_list)  # predict span
  File "<__array_function__ internals>", line 200, in vstack
  File "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py", line 293, in vstack
    arrs = atleast_2d(*tup)
  File "<__array_function__ internals>", line 200, in atleast_2d
  File "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py", line 121, in atleast_2d
    ary = asanyarray(ary)
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (16,) + inhomogeneous part.
11/21 11:51:36:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 159, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 115, in _main
    train_ds = SADataset(args.data_file['train'], aspect=aspect, tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 18, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 113, in _get_data
    print(len(self.aspect))
AttributeError: 'SADataset' object has no attribute 'aspect'
11/21 11:51:36:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 159, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 115, in _main
    train_ds = SADataset(args.data_file['train'], aspect=aspect, tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 18, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 113, in _get_data
    print(len(self.aspect))
AttributeError: 'SADataset' object has no attribute 'aspect'
11/21 12:03:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 116, in _main
    train_ds = SADataset(args.data_file['train'], aspect=train_aspect, tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 23, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 98, in _get_data
    assert len(sentence_l) == len(aspect)
AssertionError
11/21 12:03:42:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 116, in _main
    train_ds = SADataset(args.data_file['train'], aspect=train_aspect, tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 23, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 98, in _get_data
    assert len(sentence_l) == len(aspect)
AssertionError
11/21 12:20:08:  train data num: 2100  dev data num: 727
11/21 12:20:08:  train data num: 2100  dev data num: 727
11/21 12:24:37:  train data num: 2100  dev data num: 727
11/21 12:24:37:  train data num: 2100  dev data num: 727
11/21 13:11:05:  train data num: 2100  dev data num: 727
11/21 13:11:12:  train data num: 2100  dev data num: 727
11/21 13:12:27:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 170, in _get_query
    print(text, aspect, item['pairs'])
KeyError: 'pairs'
11/21 13:12:27:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 170, in _get_query
    print(text, aspect, item['pairs'])
KeyError: 'pairs'
11/21 13:27:44:  train data num: 2100  dev data num: 727
11/21 13:27:52:  train data num: 2100  dev data num: 727
11/21 13:37:38:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    train_aspect = aspect_predictor.predict("train")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 454, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dataloader, data.raw_data, data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 347, in evaluate
    aspect_span = logits2span(p_pred_labels=aspect_logits, text_inputs=text_inputs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 83, in logits2span
    predict_num += len(list(pred_pair))
UnboundLocalError: local variable 'predict_num' referenced before assignment
11/21 13:37:38:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    train_aspect = aspect_predictor.predict("train")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 454, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dataloader, data.raw_data, data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 347, in evaluate
    aspect_span = logits2span(p_pred_labels=aspect_logits, text_inputs=text_inputs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 83, in logits2span
    predict_num += len(list(pred_pair))
UnboundLocalError: local variable 'predict_num' referenced before assignment
11/21 13:41:37:  train data num: 2100  dev data num: 727
11/21 13:41:37:  train data num: 2100  dev data num: 727
11/21 13:58:13:  train data num: 2100  dev data num: 727
11/21 13:58:19:  train data num: 2100  dev data num: 727
11/21 14:07:44:  train data num: 2100  dev data num: 727
11/21 14:07:44:  train data num: 2100  dev data num: 727
11/21 14:14:54:  train data num: 2100  dev data num: 727
11/21 14:14:54:  train data num: 2100  dev data num: 727
11/21 14:20:10:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    train_aspect = aspect_predictor.predict("train")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 463, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dataloader, data.raw_data, data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 368, in evaluate
    aspect_precision, aspect_recall, aspect_f1, predict_span = cal_f1(aspect_pred_sum, text_inputs, pairs, is_result=True)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 126, in cal_f1
    pred_pair.add((start_pos, end_pos))
AttributeError: 'tuple' object has no attribute 'add'
11/21 14:20:10:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    train_aspect = aspect_predictor.predict("train")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 463, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dataloader, data.raw_data, data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 368, in evaluate
    aspect_precision, aspect_recall, aspect_f1, predict_span = cal_f1(aspect_pred_sum, text_inputs, pairs, is_result=True)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 126, in cal_f1
    pred_pair.add((start_pos, end_pos))
AttributeError: 'tuple' object has no attribute 'add'
11/21 14:28:22:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    train_aspect = aspect_predictor.predict("train")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 463, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dataloader, data.raw_data, data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 368, in evaluate
    aspect_precision, aspect_recall, aspect_f1, predict_span = cal_f1(aspect_pred_sum, text_inputs, pairs, is_result=True)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 126, in cal_f1
    pred_pair.add((start_pos, end_pos))
AttributeError: 'list' object has no attribute 'add'
11/21 14:28:22:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    train_aspect = aspect_predictor.predict("train")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 463, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dataloader, data.raw_data, data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 368, in evaluate
    aspect_precision, aspect_recall, aspect_f1, predict_span = cal_f1(aspect_pred_sum, text_inputs, pairs, is_result=True)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 126, in cal_f1
    pred_pair.add((start_pos, end_pos))
AttributeError: 'list' object has no attribute 'add'
11/21 14:29:28:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    train_aspect = aspect_predictor.predict("train")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 463, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dataloader, data.raw_data, data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 368, in evaluate
    aspect_precision, aspect_recall, aspect_f1, predict_span = cal_f1(aspect_pred_sum, text_inputs, pairs, is_result=True)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 132, in cal_f1
    correct_num += len(true_pair & pred_pair)
TypeError: unsupported operand type(s) for &: 'set' and 'list'
11/21 14:29:28:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 95, in _main
    train_aspect = aspect_predictor.predict("train")
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 463, in predict
    _, aspect = self.evaluate(self.args, apsect_predict_model, dataloader, data.raw_data, data.pairs)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 368, in evaluate
    aspect_precision, aspect_recall, aspect_f1, predict_span = cal_f1(aspect_pred_sum, text_inputs, pairs, is_result=True)
  File "/workspace/GEMEL/twitter/code/aspect/aspect_method.py", line 132, in cal_f1
    correct_num += len(true_pair & pred_pair)
TypeError: unsupported operand type(s) for &: 'set' and 'list'
11/21 14:32:49:  train data num: 2100  dev data num: 727
11/21 14:32:49:  train data num: 2100  dev data num: 727
11/21 14:34:04:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 173, in _get_query
    at = text[a[0], a[1]]
TypeError: string indices must be integers
11/21 14:34:04:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 173, in _get_query
    at = text[a[0], a[1]]
TypeError: string indices must be integers
11/21 14:37:12:  train data num: 2100  dev data num: 727
11/21 14:37:12:  train data num: 2100  dev data num: 727
11/21 14:38:27:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 175, in _get_query
    at = text[a[0], a[1]]
TypeError: string indices must be integers
11/21 14:38:27:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 175, in _get_query
    at = text[a[0], a[1]]
TypeError: string indices must be integers
11/21 14:44:59:  train data num: 2100  dev data num: 727
11/21 14:44:59:  train data num: 2100  dev data num: 727
11/21 14:46:14:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 176, in _get_query
    at = text[int(a[0]), int(a[1])]
TypeError: string indices must be integers
11/21 14:46:14:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 176, in _get_query
    at = text[int(a[0]), int(a[1])]
TypeError: string indices must be integers
11/21 14:48:40:  train data num: 2100  dev data num: 727
11/21 14:48:40:  train data num: 2100  dev data num: 727
11/21 14:53:44:  train data num: 2100  dev data num: 727
11/21 14:53:44:  train data num: 2100  dev data num: 727
11/21 14:55:00:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 147, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 180, in _get_query
    aspect_text = " ".join(aspect_text)
TypeError: sequence item 0: expected str instance, list found
11/21 14:55:00:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 147, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 180, in _get_query
    aspect_text = " ".join(aspect_text)
TypeError: sequence item 0: expected str instance, list found
11/21 14:58:06:  train data num: 2100  dev data num: 727
11/21 14:58:06:  train data num: 2100  dev data num: 727
11/21 14:59:21:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 147, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 182, in _get_query
    aspect_text = " ".join(aspect_text)
TypeError: sequence item 0: expected str instance, list found
11/21 14:59:21:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 44, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 147, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 182, in _get_query
    aspect_text = " ".join(aspect_text)
TypeError: sequence item 0: expected str instance, list found
11/21 15:16:27:  train data num: 2100  dev data num: 727
11/21 15:16:27:  train data num: 2100  dev data num: 727
11/21 15:22:40:  train data num: 2100  dev data num: 727
11/21 15:22:40:  train data num: 2100  dev data num: 727
11/21 16:08:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 74, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 143, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 113, in _eval4sa
    batch_pairs, batch_targets, _ = batch_data
ValueError: not enough values to unpack (expected 3, got 2)
11/21 16:08:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 160, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 144, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 74, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 143, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 113, in _eval4sa
    batch_pairs, batch_targets, _ = batch_data
ValueError: not enough values to unpack (expected 3, got 2)
11/23 02:47:07:  train data num: 2100  dev data num: 727
11/23 02:47:07:  train data num: 2100  dev data num: 727
11/23 03:45:38:  New best model, new f1 18.1030 % >= previous f1 0.0000 %
11/23 03:45:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 03:45:38:  Step:10000, Best: f1:18.103, p:23.098,r:14.884, Curr: f1:18.1030, p:23.098,r:14.884 
11/23 03:45:51:  New best model, new f1 18.1030 % >= previous f1 0.0000 %
11/23 03:45:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 03:45:52:  Step:10000, Best: f1:18.103, p:23.098,r:14.884, Curr: f1:18.1030, p:23.098,r:14.884 
11/23 04:43:07:  New best model, new f1 24.5840 % >= previous f1 18.1030 %
11/23 04:43:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 04:43:07:  Step:20000, Best: f1:24.584, p:30.904,r:20.410, Curr: f1:24.5840, p:30.904,r:20.410 
11/23 04:43:17:  New best model, new f1 24.5840 % >= previous f1 18.1030 %
11/23 04:43:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 04:43:17:  Step:20000, Best: f1:24.584, p:30.904,r:20.410, Curr: f1:24.5840, p:30.904,r:20.410 
11/23 05:40:29:  New best model, new f1 30.9664 % >= previous f1 24.5840 %
11/23 05:40:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 05:40:29:  Step:30000, Best: f1:30.966, p:38.615,r:25.847, Curr: f1:30.9664, p:38.615,r:25.847 
11/23 05:40:39:  New best model, new f1 30.9664 % >= previous f1 24.5840 %
11/23 05:40:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 05:40:39:  Step:30000, Best: f1:30.966, p:38.615,r:25.847, Curr: f1:30.9664, p:38.615,r:25.847 
11/23 06:37:57:  New best model, new f1 35.7406 % >= previous f1 30.9664 %
11/23 06:37:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 06:37:57:  Step:40000, Best: f1:35.741, p:43.742,r:30.214, Curr: f1:35.7406, p:43.742,r:30.214 
11/23 06:38:04:  New best model, new f1 35.7406 % >= previous f1 30.9664 %
11/23 06:38:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 06:38:04:  Step:40000, Best: f1:35.741, p:43.742,r:30.214, Curr: f1:35.7406, p:43.742,r:30.214 
11/23 07:35:18:  New best model, new f1 38.5311 % >= previous f1 35.7406 %
11/23 07:35:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 07:35:18:  Step:50000, Best: f1:38.531, p:47.820,r:32.264, Curr: f1:38.5311, p:47.820,r:32.264 
11/23 07:35:29:  New best model, new f1 38.5311 % >= previous f1 35.7406 %
11/23 07:35:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 07:35:29:  Step:50000, Best: f1:38.531, p:47.820,r:32.264, Curr: f1:38.5311, p:47.820,r:32.264 
11/23 08:32:33:  New best model, new f1 41.3574 % >= previous f1 38.5311 %
11/23 08:32:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 08:32:33:  Step:60000, Best: f1:41.357, p:51.047,r:34.759, Curr: f1:41.3574, p:51.047,r:34.759 
11/23 08:32:48:  New best model, new f1 41.3574 % >= previous f1 38.5311 %
11/23 08:32:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 08:32:48:  Step:60000, Best: f1:41.357, p:51.047,r:34.759, Curr: f1:41.3574, p:51.047,r:34.759 
11/23 09:30:03:  New best model, new f1 41.3757 % >= previous f1 41.3574 %
11/23 09:30:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 09:30:04:  Step:70000, Best: f1:41.376, p:50.911,r:34.848, Curr: f1:41.3757, p:50.911,r:34.848 
11/23 09:30:15:  New best model, new f1 41.3757 % >= previous f1 41.3574 %
11/23 09:30:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 09:30:15:  Step:70000, Best: f1:41.376, p:50.911,r:34.848, Curr: f1:41.3757, p:50.911,r:34.848 
11/23 10:27:23:  New best model, new f1 43.5518 % >= previous f1 41.3757 %
11/23 10:27:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 10:27:23:  Step:80000, Best: f1:43.552, p:53.506,r:36.720, Curr: f1:43.5518, p:53.506,r:36.720 
11/23 10:27:34:  New best model, new f1 43.5518 % >= previous f1 41.3757 %
11/23 10:27:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 10:27:34:  Step:80000, Best: f1:43.552, p:53.506,r:36.720, Curr: f1:43.5518, p:53.506,r:36.720 
11/23 11:24:42:  New best model, new f1 44.9260 % >= previous f1 43.5518 %
11/23 11:24:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 11:24:42:  Step:90000, Best: f1:44.926, p:55.195,r:37.879, Curr: f1:44.9260, p:55.195,r:37.879 
11/23 11:24:52:  New best model, new f1 44.9260 % >= previous f1 43.5518 %
11/23 11:24:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 11:24:52:  Step:90000, Best: f1:44.926, p:55.195,r:37.879, Curr: f1:44.9260, p:55.195,r:37.879 
11/23 12:21:59:  New best model, new f1 45.2910 % >= previous f1 44.9260 %
11/23 12:21:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 12:21:59:  Step:100000, Best: f1:45.291, p:55.729,r:38.146, Curr: f1:45.2910, p:55.729,r:38.146 
11/23 12:22:09:  New best model, new f1 45.2910 % >= previous f1 44.9260 %
11/23 12:22:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 12:22:10:  Step:100000, Best: f1:45.291, p:55.729,r:38.146, Curr: f1:45.2910, p:55.729,r:38.146 
11/23 13:19:19:  New best model, new f1 46.2513 % >= previous f1 45.2910 %
11/23 13:19:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 13:19:19:  Step:110000, Best: f1:46.251, p:56.736,r:39.037, Curr: f1:46.2513, p:56.736,r:39.037 
11/23 13:19:28:  New best model, new f1 46.2513 % >= previous f1 45.2910 %
11/23 13:19:28:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 13:19:28:  Step:110000, Best: f1:46.251, p:56.736,r:39.037, Curr: f1:46.2513, p:56.736,r:39.037 
11/23 14:16:32:  do not save, best f1: 46.2513
11/23 14:16:32:  Step:120000, Best: f1:46.251, p:56.736,r:39.037, Curr: f1:45.8619, p:56.129,r:38.770 
11/23 14:16:43:  do not save, best f1: 46.2513
11/23 14:16:43:  Step:120000, Best: f1:46.251, p:56.736,r:39.037, Curr: f1:45.8619, p:56.129,r:38.770 
11/23 15:13:50:  do not save, best f1: 46.2513
11/23 15:13:50:  Step:130000, Best: f1:46.251, p:56.736,r:39.037, Curr: f1:46.1053, p:56.298,r:39.037 
11/23 15:13:57:  do not save, best f1: 46.2513
11/23 15:13:57:  Step:130000, Best: f1:46.251, p:56.736,r:39.037, Curr: f1:46.1053, p:56.298,r:39.037 
11/23 16:11:05:  New best model, new f1 46.6316 % >= previous f1 46.2513 %
11/23 16:11:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 16:11:05:  Step:140000, Best: f1:46.632, p:56.941,r:39.483, Curr: f1:46.6316, p:56.941,r:39.483 
11/23 16:11:14:  New best model, new f1 46.6316 % >= previous f1 46.2513 %
11/23 16:11:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 16:11:14:  Step:140000, Best: f1:46.632, p:56.941,r:39.483, Curr: f1:46.6316, p:56.941,r:39.483 
11/23 17:08:22:  New best model, new f1 47.0774 % >= previous f1 46.6316 %
11/23 17:08:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 17:08:22:  Step:150000, Best: f1:47.077, p:57.529,r:39.840, Curr: f1:47.0774, p:57.529,r:39.840 
11/23 17:08:29:  New best model, new f1 47.0774 % >= previous f1 46.6316 %
11/23 17:08:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 17:08:29:  Step:150000, Best: f1:47.077, p:57.529,r:39.840, Curr: f1:47.0774, p:57.529,r:39.840 
11/23 18:05:31:  do not save, best f1: 47.0774
11/23 18:05:31:  Step:160000, Best: f1:47.077, p:57.529,r:39.840, Curr: f1:45.2055, p:55.284,r:38.235 
11/23 18:05:43:  do not save, best f1: 47.0774
11/23 18:05:43:  Step:160000, Best: f1:47.077, p:57.529,r:39.840, Curr: f1:45.2055, p:55.284,r:38.235 
11/23 19:02:44:  New best model, new f1 47.2574 % >= previous f1 47.0774 %
11/23 19:02:44:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 19:02:44:  Step:170000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:47.2574, p:57.881,r:39.929 
11/23 19:02:52:  New best model, new f1 47.2574 % >= previous f1 47.0774 %
11/23 19:02:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/23 19:02:52:  Step:170000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:47.2574, p:57.881,r:39.929 
11/23 19:59:53:  do not save, best f1: 47.2574
11/23 19:59:53:  Step:180000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:46.5753, p:56.959,r:39.394 
11/23 20:00:01:  do not save, best f1: 47.2574
11/23 20:00:01:  Step:180000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:46.5753, p:56.959,r:39.394 
11/23 20:56:57:  do not save, best f1: 47.2574
11/23 20:56:57:  Step:190000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:45.6029, p:55.727,r:38.592 
11/23 20:57:08:  do not save, best f1: 47.2574
11/23 20:57:08:  Step:190000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:45.6029, p:55.727,r:38.592 
11/23 21:54:08:  do not save, best f1: 47.2574
11/23 21:54:08:  Step:200000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:45.4162, p:55.541,r:38.414 
11/23 21:54:19:  do not save, best f1: 47.2574
11/23 21:54:19:  Step:200000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:45.4162, p:55.541,r:38.414 
11/23 22:51:17:  do not save, best f1: 47.2574
11/23 22:51:17:  Step:210000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:45.3586, p:55.556,r:38.324 
11/23 22:51:23:  do not save, best f1: 47.2574
11/23 22:51:23:  Step:210000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:45.3586, p:55.556,r:38.324 
11/23 23:03:43:  do not save, best f1: 47.2574
11/23 23:03:43:  Step:210000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:45.3586, p:55.556,r:38.324 
11/23 23:03:57:  do not save, best f1: 47.2574
11/23 23:03:57:  Step:210000, Best: f1:47.257, p:57.881,r:39.929, Curr: f1:45.3586, p:55.556,r:38.324 
11/24 07:56:15:  train data num: 2100  dev data num: 727
11/24 07:56:15:  train data num: 2100  dev data num: 727
11/24 08:09:54:  train data num: 2100  dev data num: 727
11/24 08:09:54:  train data num: 2100  dev data num: 727
11/24 08:17:03:  train data num: 2100  dev data num: 727
11/24 08:17:03:  train data num: 2100  dev data num: 727
11/24 08:29:10:  train data num: 2100  dev data num: 727
11/24 08:29:10:  train data num: 2100  dev data num: 727
11/24 08:37:07:  train data num: 2100  dev data num: 727
11/24 08:37:07:  train data num: 2100  dev data num: 727
11/24 09:32:59:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/24 09:32:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 09:32:59:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/24 09:33:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/24 09:33:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 09:33:07:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/24 10:27:32:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/24 10:27:32:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 10:27:32:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/24 10:27:45:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/24 10:27:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 10:27:45:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/24 11:22:16:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/24 11:22:16:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 11:22:16:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/24 11:22:28:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/24 11:22:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 11:22:29:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/24 12:16:53:  New best model, new f1 30.6972 % >= previous f1 0.0000 %
11/24 12:16:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 12:16:53:  Step:40000, Best: f1:30.697, p:36.875,r:26.292, Curr: f1:30.6972, p:36.875,r:26.292 
11/24 12:17:04:  New best model, new f1 30.6972 % >= previous f1 0.0000 %
11/24 12:17:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 12:17:05:  Step:40000, Best: f1:30.697, p:36.875,r:26.292, Curr: f1:30.6972, p:36.875,r:26.292 
11/24 13:11:44:  New best model, new f1 36.7655 % >= previous f1 30.6972 %
11/24 13:11:44:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 13:11:44:  Step:50000, Best: f1:36.765, p:46.521,r:30.392, Curr: f1:36.7655, p:46.521,r:30.392 
11/24 13:11:51:  New best model, new f1 36.7655 % >= previous f1 30.6972 %
11/24 13:11:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 13:11:51:  Step:50000, Best: f1:36.765, p:46.521,r:30.392, Curr: f1:36.7655, p:46.521,r:30.392 
11/24 14:06:18:  New best model, new f1 37.7358 % >= previous f1 36.7655 %
11/24 14:06:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 14:06:18:  Step:60000, Best: f1:37.736, p:47.749,r:31.194, Curr: f1:37.7358, p:47.749,r:31.194 
11/24 14:06:26:  New best model, new f1 37.7358 % >= previous f1 36.7655 %
11/24 14:06:26:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 14:06:26:  Step:60000, Best: f1:37.736, p:47.749,r:31.194, Curr: f1:37.7358, p:47.749,r:31.194 
11/24 15:00:56:  New best model, new f1 41.5094 % >= previous f1 37.7358 %
11/24 15:00:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 15:00:56:  Step:70000, Best: f1:41.509, p:52.524,r:34.314, Curr: f1:41.5094, p:52.524,r:34.314 
11/24 15:01:08:  New best model, new f1 41.5094 % >= previous f1 37.7358 %
11/24 15:01:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 15:01:08:  Step:70000, Best: f1:41.509, p:52.524,r:34.314, Curr: f1:41.5094, p:52.524,r:34.314 
11/24 15:55:42:  New best model, new f1 43.1034 % >= previous f1 41.5094 %
11/24 15:55:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 15:55:42:  Step:80000, Best: f1:43.103, p:54.496,r:35.651, Curr: f1:43.1034, p:54.496,r:35.651 
11/24 15:55:46:  New best model, new f1 43.1034 % >= previous f1 41.5094 %
11/24 15:55:47:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 15:55:47:  Step:80000, Best: f1:43.103, p:54.496,r:35.651, Curr: f1:43.1034, p:54.496,r:35.651 
11/24 16:50:13:  New best model, new f1 45.2586 % >= previous f1 43.1034 %
11/24 16:50:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 16:50:13:  Step:90000, Best: f1:45.259, p:57.221,r:37.433, Curr: f1:45.2586, p:57.221,r:37.433 
11/24 16:50:24:  New best model, new f1 45.2586 % >= previous f1 43.1034 %
11/24 16:50:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 16:50:24:  Step:90000, Best: f1:45.259, p:57.221,r:37.433, Curr: f1:45.2586, p:57.221,r:37.433 
11/24 17:44:46:  New best model, new f1 45.9052 % >= previous f1 45.2586 %
11/24 17:44:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 17:44:46:  Step:100000, Best: f1:45.905, p:58.038,r:37.968, Curr: f1:45.9052, p:58.038,r:37.968 
11/24 17:44:54:  New best model, new f1 45.9052 % >= previous f1 45.2586 %
11/24 17:44:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 17:44:54:  Step:100000, Best: f1:45.905, p:58.038,r:37.968, Curr: f1:45.9052, p:58.038,r:37.968 
11/24 18:39:19:  do not save, best f1: 45.9052
11/24 18:39:19:  Step:110000, Best: f1:45.905, p:58.038,r:37.968, Curr: f1:45.5819, p:57.629,r:37.701 
11/24 18:39:28:  do not save, best f1: 45.9052
11/24 18:39:28:  Step:110000, Best: f1:45.905, p:58.038,r:37.968, Curr: f1:45.5819, p:57.629,r:37.701 
11/24 19:33:53:  do not save, best f1: 45.9052
11/24 19:33:53:  Step:120000, Best: f1:45.905, p:58.038,r:37.968, Curr: f1:45.2830, p:57.299,r:37.433 
11/24 19:33:55:  do not save, best f1: 45.9052
11/24 19:33:55:  Step:120000, Best: f1:45.905, p:58.038,r:37.968, Curr: f1:45.2830, p:57.299,r:37.433 
11/24 20:28:20:  New best model, new f1 46.0129 % >= previous f1 45.9052 %
11/24 20:28:20:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 20:28:20:  Step:130000, Best: f1:46.013, p:58.174,r:38.057, Curr: f1:46.0129, p:58.174,r:38.057 
11/24 20:28:31:  New best model, new f1 46.0129 % >= previous f1 45.9052 %
11/24 20:28:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 20:28:31:  Step:130000, Best: f1:46.013, p:58.174,r:38.057, Curr: f1:46.0129, p:58.174,r:38.057 
11/24 21:22:51:  New best model, new f1 46.2863 % >= previous f1 46.0129 %
11/24 21:22:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 21:22:51:  Step:140000, Best: f1:46.286, p:58.424,r:38.324, Curr: f1:46.2863, p:58.424,r:38.324 
11/24 21:22:58:  New best model, new f1 46.2863 % >= previous f1 46.0129 %
11/24 21:22:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 21:22:58:  Step:140000, Best: f1:46.286, p:58.424,r:38.324, Curr: f1:46.2863, p:58.424,r:38.324 
11/24 22:17:21:  New best model, new f1 46.4190 % >= previous f1 46.2863 %
11/24 22:17:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 22:17:21:  Step:150000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:46.4190, p:58.639,r:38.414 
11/24 22:17:34:  New best model, new f1 46.4190 % >= previous f1 46.2863 %
11/24 22:17:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/24 22:17:34:  Step:150000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:46.4190, p:58.639,r:38.414 
11/24 23:11:53:  do not save, best f1: 46.4190
11/24 23:11:53:  Step:160000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:46.2036, p:58.367,r:38.235 
11/24 23:12:00:  do not save, best f1: 46.4190
11/24 23:12:00:  Step:160000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:46.2036, p:58.367,r:38.235 
11/25 00:06:21:  do not save, best f1: 46.4190
11/25 00:06:21:  Step:170000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:45.1265, p:57.007,r:37.344 
11/25 00:06:31:  do not save, best f1: 46.4190
11/25 00:06:31:  Step:170000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:45.1265, p:57.007,r:37.344 
11/25 01:00:53:  do not save, best f1: 46.4190
11/25 01:00:53:  Step:180000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:45.4252, p:57.337,r:37.611 
11/25 01:01:05:  do not save, best f1: 46.4190
11/25 01:01:05:  Step:180000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:45.4252, p:57.337,r:37.611 
11/25 01:55:21:  do not save, best f1: 46.4190
11/25 01:55:21:  Step:190000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:45.1752, p:57.162,r:37.344 
11/25 01:55:33:  do not save, best f1: 46.4190
11/25 01:55:33:  Step:190000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:45.1752, p:57.162,r:37.344 
11/25 02:49:53:  do not save, best f1: 46.4190
11/25 02:49:53:  Step:200000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:45.1752, p:57.162,r:37.344 
11/25 02:50:02:  do not save, best f1: 46.4190
11/25 02:50:02:  Step:200000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:45.1752, p:57.162,r:37.344 
11/25 03:44:19:  do not save, best f1: 46.4190
11/25 03:44:19:  Step:210000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:43.9892, p:55.662,r:36.364 
11/25 03:44:29:  do not save, best f1: 46.4190
11/25 03:44:29:  Step:210000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:43.9892, p:55.662,r:36.364 
11/25 03:56:38:  do not save, best f1: 46.4190
11/25 03:56:38:  Step:210000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:43.9892, p:55.662,r:36.364 
11/25 03:56:57:  do not save, best f1: 46.4190
11/25 03:56:57:  Step:210000, Best: f1:46.419, p:58.639,r:38.414, Curr: f1:43.9892, p:55.662,r:36.364 
11/29 08:32:28:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 118, in _main
    train_ds = SADataset(args.data_file['train'], aspect=train_aspect, tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 23, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 98, in _get_data
    assert len(sentence_l) == len(self.aspect)
TypeError: object of type 'NoneType' has no len()
11/29 08:32:28:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 118, in _main
    train_ds = SADataset(args.data_file['train'], aspect=train_aspect, tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 23, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 98, in _get_data
    assert len(sentence_l) == len(self.aspect)
TypeError: object of type 'NoneType' has no len()
11/29 08:34:49:  train data num: 2100  dev data num: 727
11/29 08:34:49:  train data num: 2100  dev data num: 727
11/29 08:42:28:  train data num: 2100  dev data num: 727
11/29 08:42:28:  train data num: 2100  dev data num: 727
11/29 08:46:24:  train data num: 2100  dev data num: 727
11/29 08:46:24:  train data num: 2100  dev data num: 727
11/29 09:37:43:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/29 09:37:43:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 09:37:43:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/29 09:37:55:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/29 09:37:55:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 09:37:55:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/29 10:27:55:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/29 10:27:55:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 10:27:55:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/29 10:28:01:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/29 10:28:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 10:28:01:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/29 11:17:58:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/29 11:17:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 11:17:58:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/29 11:18:12:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/29 11:18:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 11:18:13:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/29 12:08:18:  New best model, new f1 35.0295 % >= previous f1 0.0000 %
11/29 12:08:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 12:08:18:  Step:40000, Best: f1:35.029, p:43.893,r:29.144, Curr: f1:35.0295, p:43.893,r:29.144 
11/29 12:08:22:  New best model, new f1 35.0295 % >= previous f1 0.0000 %
11/29 12:08:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 12:08:22:  Step:40000, Best: f1:35.029, p:43.893,r:29.144, Curr: f1:35.0295, p:43.893,r:29.144 
11/29 12:58:19:  New best model, new f1 41.8554 % >= previous f1 35.0295 %
11/29 12:58:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 12:58:19:  Step:50000, Best: f1:41.855, p:53.005,r:34.581, Curr: f1:41.8554, p:53.005,r:34.581 
11/29 12:58:30:  New best model, new f1 41.8554 % >= previous f1 35.0295 %
11/29 12:58:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 12:58:30:  Step:50000, Best: f1:41.855, p:53.005,r:34.581, Curr: f1:41.8554, p:53.005,r:34.581 
11/29 13:48:24:  New best model, new f1 42.6106 % >= previous f1 41.8554 %
11/29 13:48:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 13:48:24:  Step:60000, Best: f1:42.611, p:53.962,r:35.205, Curr: f1:42.6106, p:53.962,r:35.205 
11/29 13:48:31:  New best model, new f1 42.6106 % >= previous f1 41.8554 %
11/29 13:48:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 13:48:31:  Step:60000, Best: f1:42.611, p:53.962,r:35.205, Curr: f1:42.6106, p:53.962,r:35.205 
11/29 14:38:31:  New best model, new f1 44.0129 % >= previous f1 42.6106 %
11/29 14:38:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 14:38:31:  Step:70000, Best: f1:44.013, p:55.738,r:36.364, Curr: f1:44.0129, p:55.738,r:36.364 
11/29 14:38:44:  New best model, new f1 44.0129 % >= previous f1 42.6106 %
11/29 14:38:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 14:38:45:  Step:70000, Best: f1:44.013, p:55.738,r:36.364, Curr: f1:44.0129, p:55.738,r:36.364 
11/29 15:28:44:  do not save, best f1: 44.0129
11/29 15:28:44:  Step:80000, Best: f1:44.013, p:55.738,r:36.364, Curr: f1:43.2956, p:54.694,r:35.829 
11/29 15:28:50:  do not save, best f1: 44.0129
11/29 15:28:50:  Step:80000, Best: f1:44.013, p:55.738,r:36.364, Curr: f1:43.2956, p:54.694,r:35.829 
11/29 16:18:53:  New best model, new f1 44.2649 % >= previous f1 44.0129 %
11/29 16:18:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 16:18:53:  Step:90000, Best: f1:44.265, p:55.918,r:36.631, Curr: f1:44.2649, p:55.918,r:36.631 
11/29 16:18:59:  New best model, new f1 44.2649 % >= previous f1 44.0129 %
11/29 16:18:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 16:18:59:  Step:90000, Best: f1:44.265, p:55.918,r:36.631, Curr: f1:44.2649, p:55.918,r:36.631 
11/29 17:08:50:  New best model, new f1 44.7312 % >= previous f1 44.2649 %
11/29 17:08:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 17:08:50:  Step:100000, Best: f1:44.731, p:56.369,r:37.077, Curr: f1:44.7312, p:56.369,r:37.077 
11/29 17:09:05:  New best model, new f1 44.7312 % >= previous f1 44.2649 %
11/29 17:09:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 17:09:05:  Step:100000, Best: f1:44.731, p:56.369,r:37.077, Curr: f1:44.7312, p:56.369,r:37.077 
11/29 17:58:58:  New best model, new f1 46.3441 % >= previous f1 44.7312 %
11/29 17:58:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 17:58:58:  Step:110000, Best: f1:46.344, p:58.401,r:38.414, Curr: f1:46.3441, p:58.401,r:38.414 
11/29 17:59:10:  New best model, new f1 46.3441 % >= previous f1 44.7312 %
11/29 17:59:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 17:59:10:  Step:110000, Best: f1:46.344, p:58.401,r:38.414, Curr: f1:46.3441, p:58.401,r:38.414 
11/29 18:49:09:  New best model, new f1 46.9322 % >= previous f1 46.3441 %
11/29 18:49:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 18:49:09:  Step:120000, Best: f1:46.932, p:59.239,r:38.859, Curr: f1:46.9322, p:59.239,r:38.859 
11/29 18:49:14:  New best model, new f1 46.9322 % >= previous f1 46.3441 %
11/29 18:49:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 18:49:14:  Step:120000, Best: f1:46.932, p:59.239,r:38.859, Curr: f1:46.9322, p:59.239,r:38.859 
11/29 19:39:09:  New best model, new f1 47.3118 % >= previous f1 46.9322 %
11/29 19:39:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 19:39:09:  Step:130000, Best: f1:47.312, p:59.621,r:39.216, Curr: f1:47.3118, p:59.621,r:39.216 
11/29 19:39:15:  New best model, new f1 47.3118 % >= previous f1 46.9322 %
11/29 19:39:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 19:39:15:  Step:130000, Best: f1:47.312, p:59.621,r:39.216, Curr: f1:47.3118, p:59.621,r:39.216 
11/29 20:29:08:  New best model, new f1 48.1980 % >= previous f1 47.3118 %
11/29 20:29:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 20:29:08:  Step:140000, Best: f1:48.198, p:60.787,r:39.929, Curr: f1:48.1980, p:60.787,r:39.929 
11/29 20:29:14:  New best model, new f1 48.1980 % >= previous f1 47.3118 %
11/29 20:29:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 20:29:14:  Step:140000, Best: f1:48.198, p:60.787,r:39.929, Curr: f1:48.1980, p:60.787,r:39.929 
11/29 21:19:05:  New best model, new f1 48.6022 % >= previous f1 48.1980 %
11/29 21:19:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 21:19:05:  Step:150000, Best: f1:48.602, p:61.247,r:40.285, Curr: f1:48.6022, p:61.247,r:40.285 
11/29 21:19:20:  New best model, new f1 48.6022 % >= previous f1 48.1980 %
11/29 21:19:20:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 21:19:20:  Step:150000, Best: f1:48.602, p:61.247,r:40.285, Curr: f1:48.6022, p:61.247,r:40.285 
11/29 22:09:11:  New best model, new f1 48.7884 % >= previous f1 48.6022 %
11/29 22:09:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 22:09:11:  Step:160000, Best: f1:48.788, p:61.633,r:40.374, Curr: f1:48.7884, p:61.633,r:40.374 
11/29 22:09:21:  New best model, new f1 48.7884 % >= previous f1 48.6022 %
11/29 22:09:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 22:09:21:  Step:160000, Best: f1:48.788, p:61.633,r:40.374, Curr: f1:48.7884, p:61.633,r:40.374 
11/29 22:59:14:  New best model, new f1 50.1078 % >= previous f1 48.7884 %
11/29 22:59:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 22:59:14:  Step:170000, Best: f1:50.108, p:63.351,r:41.444, Curr: f1:50.1078, p:63.351,r:41.444 
11/29 22:59:23:  New best model, new f1 50.1078 % >= previous f1 48.7884 %
11/29 22:59:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 22:59:23:  Step:170000, Best: f1:50.108, p:63.351,r:41.444, Curr: f1:50.1078, p:63.351,r:41.444 
11/29 23:49:11:  New best model, new f1 50.4310 % >= previous f1 50.1078 %
11/29 23:49:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 23:49:11:  Step:180000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:50.4310, p:63.760,r:41.711 
11/29 23:49:24:  New best model, new f1 50.4310 % >= previous f1 50.1078 %
11/29 23:49:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/29 23:49:24:  Step:180000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:50.4310, p:63.760,r:41.711 
11/30 00:39:11:  do not save, best f1: 50.4310
11/30 00:39:11:  Step:190000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:49.5146, p:62.705,r:40.909 
11/30 00:39:26:  do not save, best f1: 50.4310
11/30 00:39:26:  Step:190000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:49.5146, p:62.705,r:40.909 
11/30 01:29:22:  do not save, best f1: 50.4310
11/30 01:29:22:  Step:200000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:47.8191, p:60.408,r:39.572 
11/30 01:29:37:  do not save, best f1: 50.4310
11/30 01:29:37:  Step:200000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:47.8191, p:60.408,r:39.572 
11/30 02:19:45:  do not save, best f1: 50.4310
11/30 02:19:45:  Step:210000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:48.8147, p:61.717,r:40.374 
11/30 02:19:49:  do not save, best f1: 50.4310
11/30 02:19:49:  Step:210000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:48.8147, p:61.717,r:40.374 
11/30 02:31:55:  do not save, best f1: 50.4310
11/30 02:31:55:  Step:210000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:48.8147, p:61.717,r:40.374 
11/30 02:32:07:  do not save, best f1: 50.4310
11/30 02:32:07:  Step:210000, Best: f1:50.431, p:63.760,r:41.711, Curr: f1:48.8147, p:61.717,r:40.374 
11/30 03:20:34:  train data num: 2100  dev data num: 727
11/30 03:20:34:  train data num: 2100  dev data num: 727
11/30 03:26:30:  train data num: 2100  dev data num: 727
11/30 03:26:30:  train data num: 2100  dev data num: 727
11/30 03:30:39:  train data num: 2100  dev data num: 727
11/30 03:30:39:  train data num: 2100  dev data num: 727
11/30 04:19:14:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 04:19:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 04:19:15:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 04:19:27:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 04:19:27:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 04:19:27:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 05:06:48:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 05:06:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 05:06:48:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 05:06:55:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 05:06:55:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 05:06:55:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 05:54:18:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 05:54:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 05:54:18:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 05:54:30:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 05:54:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 05:54:30:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 06:41:47:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 06:41:47:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 06:41:47:  Step:40000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 06:41:57:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 06:41:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 06:41:57:  Step:40000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 07:29:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 07:29:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 07:29:21:  Step:50000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 07:29:29:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 07:29:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 07:29:29:  Step:50000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 08:16:45:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 08:16:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 08:16:45:  Step:60000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 08:16:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 08:16:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 08:16:51:  Step:60000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 09:04:18:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 09:04:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 09:04:18:  Step:70000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 09:04:24:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 09:04:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 09:04:24:  Step:70000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 09:51:42:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 09:51:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 09:51:42:  Step:80000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 09:51:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 09:51:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 09:51:54:  Step:80000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 10:39:18:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 10:39:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 10:39:18:  Step:90000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 10:39:30:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 10:39:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 10:39:30:  Step:90000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 11:26:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 11:26:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 11:26:53:  Step:100000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 11:27:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 11:27:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 11:27:03:  Step:100000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 12:14:25:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 12:14:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 12:14:25:  Step:110000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 12:14:38:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 12:14:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 12:14:38:  Step:110000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 13:02:02:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 13:02:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 13:02:02:  Step:120000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 13:02:09:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 13:02:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 13:02:09:  Step:120000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 13:49:31:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 13:49:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 13:49:31:  Step:130000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 13:49:41:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 13:49:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 13:49:41:  Step:130000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 14:36:58:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 14:36:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 14:36:58:  Step:140000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 14:37:10:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 14:37:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 14:37:10:  Step:140000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 15:24:28:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 15:24:28:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 15:24:28:  Step:150000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 15:24:37:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 15:24:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 15:24:37:  Step:150000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 16:11:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 16:11:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 16:11:53:  Step:160000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 16:12:00:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 16:12:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 16:12:00:  Step:160000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 16:59:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 16:59:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 16:59:17:  Step:170000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 16:59:25:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 16:59:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 16:59:25:  Step:170000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 17:46:39:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 17:46:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 17:46:39:  Step:180000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 17:46:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 17:46:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 17:46:54:  Step:180000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 18:34:11:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 18:34:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 18:34:11:  Step:190000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 18:34:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 18:34:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 18:34:17:  Step:190000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 19:21:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 19:21:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 19:21:40:  Step:200000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 19:21:47:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 19:21:47:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 19:21:47:  Step:200000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 20:09:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 20:09:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 20:09:04:  Step:210000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 20:09:12:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 20:09:12:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 20:09:12:  Step:210000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 20:21:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 20:21:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 20:21:07:  Step:210000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
11/30 20:21:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
11/30 20:21:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
11/30 20:21:21:  Step:210000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 07:55:34:  train data num: 2100  dev data num: 727
12/01 07:55:34:  train data num: 2100  dev data num: 727
12/01 07:59:30:  train data num: 2100  dev data num: 727
12/01 07:59:30:  train data num: 2100  dev data num: 727
12/01 08:00:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:50:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:50:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:52:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:52:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:54:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:54:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:57:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:57:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:57:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:57:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:59:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:59:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:00:59:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:00:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:00:59:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:01:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:01:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:01:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:01:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:03:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:03:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:06:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:06:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:06:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:06:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:08:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:08:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:10:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:10:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:10:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:10:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:13:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:13:  Step:11, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:13:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:13:  Step:11, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:15:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:15:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:15:  Step:12, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:15:  Step:12, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:17:  Step:13, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:01:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:01:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:01:17:  Step:13, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:05:24:  train data num: 2100  dev data num: 727
12/01 08:05:24:  train data num: 2100  dev data num: 727
12/01 08:06:44:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:44:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:44:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:44:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:44:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:44:  Step:1, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:46:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:46:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:46:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:46:  Step:2, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:48:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:48:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:48:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:48:  Step:3, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:51:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:51:  Step:4, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:53:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:53:  Step:5, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:55:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:55:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:55:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:55:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:55:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:55:  Step:6, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:58:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:58:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:06:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:06:58:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:06:58:  Step:7, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:07:00:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:07:00:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:07:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:07:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:07:00:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:07:00:  Step:8, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:07:02:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:07:02:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 08:07:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:07:02:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:07:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 08:07:02:  Step:9, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 08:12:33:  train data num: 2100  dev data num: 727
12/01 08:12:33:  train data num: 2100  dev data num: 727
12/01 09:04:20:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 09:04:20:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 09:04:20:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 09:04:30:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 09:04:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 09:04:30:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 09:55:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 09:55:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 09:55:08:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 09:55:09:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 09:55:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 09:55:09:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:09:12:  train data num: 2100  dev data num: 727
12/01 10:09:12:  train data num: 2100  dev data num: 727
12/01 10:10:46:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:10:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:10:46:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:10:46:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:10:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:10:46:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:00:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:00:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:01:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:01:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:15:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:15:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:15:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:15:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:29:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:29:  Step:40, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:30:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:30:  Step:40, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:44:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:44:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:44:  Step:50, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:45:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:45:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:45:  Step:50, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:58:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:58:  Step:60, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:11:59:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:11:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:11:59:  Step:60, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:12:13:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:12:13:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:12:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:12:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:12:13:  Step:70, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:12:13:  Step:70, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:12:27:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:12:27:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:12:27:  Step:80, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:12:28:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:12:28:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:12:28:  Step:80, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:12:41:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:12:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:12:41:  Step:90, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:12:42:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:12:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:12:42:  Step:90, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:12:56:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:12:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:12:56:  Step:100, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:12:57:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:12:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:12:57:  Step:100, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:13:10:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:13:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:13:10:  Step:110, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:13:11:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:13:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:13:11:  Step:110, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:13:25:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:13:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:13:25:  Step:120, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:13:26:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:13:26:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:13:26:  Step:120, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:13:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:13:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:13:40:  Step:130, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:13:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:13:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:13:40:  Step:130, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:13:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:13:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:13:54:  Step:140, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:13:55:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:13:55:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:13:55:  Step:140, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:14:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:14:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:14:08:  Step:150, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:14:09:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:14:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:14:09:  Step:150, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:14:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:14:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:14:23:  Step:160, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:14:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:14:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:14:23:  Step:160, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:14:37:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:14:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:14:37:  Step:170, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:14:38:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:14:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:14:38:  Step:170, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:14:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:14:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:14:52:  Step:180, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:14:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:14:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:14:52:  Step:180, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:15:06:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:15:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:15:06:  Step:190, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:15:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:15:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:15:07:  Step:190, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:15:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:15:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:15:21:  Step:200, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:15:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:15:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:15:21:  Step:200, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:15:35:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:15:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:15:35:  Step:210, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:15:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:15:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:15:36:  Step:210, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:15:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:15:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:15:50:  Step:220, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:15:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:15:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:15:51:  Step:220, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:16:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:16:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:16:05:  Step:230, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:16:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:16:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:16:05:  Step:230, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:16:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:16:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:16:19:  Step:240, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:16:20:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:16:20:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:16:20:  Step:240, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:16:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:16:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:16:34:  Step:250, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:16:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:16:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:16:34:  Step:250, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:16:48:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:16:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:16:48:  Step:260, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:16:49:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:16:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:16:49:  Step:260, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:17:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:17:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:17:03:  Step:270, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:17:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:17:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:17:04:  Step:270, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:20:08:  train data num: 2100  dev data num: 727
12/01 10:20:08:  train data num: 2100  dev data num: 727
12/01 10:21:41:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:21:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:21:42:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:21:42:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:21:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:21:42:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:21:56:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:21:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:21:56:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:21:56:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:21:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:21:56:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:22:10:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:22:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:22:10:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:22:11:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 10:22:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 10:22:11:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 10:24:22:  train data num: 2100  dev data num: 727
12/01 10:24:22:  train data num: 2100  dev data num: 727
12/01 11:15:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 11:15:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 11:15:36:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 11:15:38:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 11:15:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 11:15:38:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:05:31:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:05:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:05:31:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:05:46:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:05:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:05:46:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:13:46:  train data num: 2100  dev data num: 727
12/01 12:13:46:  train data num: 2100  dev data num: 727
12/01 12:15:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:15:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:15:19:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:15:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:15:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:15:19:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:15:33:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:15:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:15:33:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:15:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:15:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:15:34:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:54:21:  train data num: 2100  dev data num: 727
12/01 12:54:21:  train data num: 2100  dev data num: 727
12/01 12:55:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:55:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:55:54:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:55:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:55:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:55:54:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:56:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:56:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:56:08:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:56:09:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:56:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:56:09:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:56:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:56:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:56:23:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:56:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 12:56:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 12:56:23:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 12:59:42:  train data num: 2100  dev data num: 727
12/01 12:59:42:  train data num: 2100  dev data num: 727
12/01 13:01:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:01:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:01:17:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:01:17:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:01:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:01:17:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:01:31:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:01:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:01:31:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:01:31:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:01:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:01:31:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:18:20:  train data num: 2100  dev data num: 727
12/01 13:18:20:  train data num: 2100  dev data num: 727
12/01 13:19:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:19:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:19:54:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:19:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:19:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:19:54:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:20:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:20:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:20:08:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:20:09:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:20:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:20:09:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:20:24:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:20:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:20:24:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:20:24:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:20:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:20:24:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:20:38:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:20:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:20:38:  Step:40, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:20:39:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:20:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:20:39:  Step:40, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:20:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:20:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:20:53:  Step:50, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:20:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:20:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:20:54:  Step:50, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:21:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:21:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:21:07:  Step:60, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:21:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:21:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:21:08:  Step:60, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:21:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:21:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:21:23:  Step:70, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:21:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:21:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:21:23:  Step:70, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:21:37:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:21:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:21:37:  Step:80, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:21:38:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:21:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:21:38:  Step:80, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:21:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:21:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:21:52:  Step:90, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:21:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:21:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:21:52:  Step:90, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:22:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:22:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:22:07:  Step:100, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:22:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:22:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:22:07:  Step:100, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:22:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:22:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:22:21:  Step:110, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:22:22:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:22:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:22:22:  Step:110, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:22:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:22:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:22:36:  Step:120, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:22:37:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:22:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:22:37:  Step:120, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:22:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:22:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:22:51:  Step:130, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:22:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:22:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:22:52:  Step:130, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:23:06:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:23:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:23:06:  Step:140, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:23:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:23:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:23:07:  Step:140, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:23:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:23:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:23:21:  Step:150, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:23:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:23:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:23:21:  Step:150, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:23:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:23:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:23:36:  Step:160, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:23:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:23:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:23:36:  Step:160, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:23:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:23:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:23:51:  Step:170, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:23:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:23:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:23:51:  Step:170, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:24:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:24:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:24:05:  Step:180, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:24:06:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:24:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:24:06:  Step:180, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:24:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:24:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:24:21:  Step:190, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:24:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:24:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:24:21:  Step:190, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:24:35:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:24:35:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:24:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:24:36:  Step:200, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:24:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:24:36:  Step:200, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:24:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:24:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:24:50:  Step:210, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:24:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:24:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:24:51:  Step:210, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:25:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:25:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:25:05:  Step:220, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:25:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:25:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:25:05:  Step:220, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:25:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:25:20:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:25:20:  Step:230, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:25:20:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:25:20:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:25:20:  Step:230, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:25:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:25:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:25:34:  Step:240, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:25:35:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:25:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:25:35:  Step:240, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:25:49:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:25:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:25:49:  Step:250, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:25:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:25:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:25:50:  Step:250, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:26:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:26:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:26:05:  Step:260, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:26:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:26:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:26:05:  Step:260, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:26:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:26:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:26:19:  Step:270, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:26:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:26:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:26:19:  Step:270, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:26:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:26:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:26:34:  Step:280, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:26:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:26:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:26:34:  Step:280, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:26:48:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:26:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:26:48:  Step:290, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:26:49:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:26:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:26:49:  Step:290, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:35:05:  train data num: 2100  dev data num: 727
12/01 13:35:05:  train data num: 2100  dev data num: 727
12/01 13:36:39:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:36:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:36:39:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:36:39:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:36:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:36:39:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:36:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:36:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:36:53:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:36:54:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:36:54:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:36:54:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:37:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:37:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:37:08:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:37:09:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:37:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:37:09:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:37:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:37:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:37:23:  Step:40, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:37:24:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:37:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:37:24:  Step:40, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:37:38:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:37:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:37:38:  Step:50, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:37:39:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:37:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:37:39:  Step:50, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:37:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:37:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:37:53:  Step:60, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:37:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:37:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:37:53:  Step:60, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:38:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:38:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:38:08:  Step:70, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:38:08:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:38:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:38:08:  Step:70, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:38:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:38:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:38:23:  Step:80, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:38:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:38:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:38:23:  Step:80, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:38:37:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:38:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:38:37:  Step:90, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:38:37:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:38:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:38:37:  Step:90, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:38:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:38:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:38:51:  Step:100, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:38:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:38:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:38:52:  Step:100, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:39:06:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:39:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:39:06:  Step:110, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:39:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:39:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:39:07:  Step:110, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:39:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:39:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:39:21:  Step:120, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:39:22:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:39:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:39:22:  Step:120, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:39:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:39:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:39:36:  Step:130, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:39:37:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:39:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:39:37:  Step:130, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:39:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:39:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:39:51:  Step:140, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:39:52:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:39:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:39:52:  Step:140, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:40:06:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:40:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:40:06:  Step:150, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:40:07:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:40:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:40:07:  Step:150, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:40:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:40:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:40:21:  Step:160, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:40:22:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:40:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:40:22:  Step:160, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:40:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:40:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:40:36:  Step:170, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:40:37:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:40:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:40:37:  Step:170, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:40:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:40:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:40:51:  Step:180, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:40:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:40:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:40:51:  Step:180, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:41:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:41:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:41:05:  Step:190, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:41:06:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:41:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:41:06:  Step:190, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:41:20:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:41:20:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:41:20:  Step:200, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:41:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:41:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:41:21:  Step:200, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:41:35:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:41:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:41:35:  Step:210, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:41:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:41:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:41:36:  Step:210, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:41:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:41:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:41:50:  Step:220, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:41:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:41:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:41:50:  Step:220, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:42:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:42:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:42:05:  Step:230, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:42:05:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:42:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:42:05:  Step:230, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:42:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:42:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:42:19:  Step:240, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:42:20:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:42:20:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:42:20:  Step:240, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:42:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:42:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:42:34:  Step:250, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:42:35:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:42:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:42:35:  Step:250, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:42:49:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:42:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:42:49:  Step:260, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:42:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:42:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:42:50:  Step:260, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:43:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:43:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:43:04:  Step:270, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:43:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:43:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:43:04:  Step:270, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:43:18:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:43:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:43:18:  Step:280, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:43:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:43:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:43:19:  Step:280, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:43:33:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:43:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:43:33:  Step:290, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:43:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:43:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:43:34:  Step:290, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:43:48:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:43:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:43:48:  Step:300, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:43:49:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:43:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:43:49:  Step:300, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:44:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:44:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:44:04:  Step:310, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:44:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:44:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:44:04:  Step:310, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:44:18:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:44:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:44:18:  Step:320, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:44:19:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 13:44:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 13:44:19:  Step:320, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 13:49:35:  train data num: 2100  dev data num: 727
12/01 13:49:35:  train data num: 2100  dev data num: 727
12/01 14:42:15:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 14:42:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 14:42:15:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 14:42:24:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 14:42:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 14:42:24:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 15:32:58:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 15:32:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 15:32:58:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 15:33:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 15:33:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 15:33:04:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 16:23:34:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 16:23:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 16:23:34:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 16:23:40:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/01 16:23:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 16:23:40:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/01 17:14:12:  New best model, new f1 30.7460 % >= previous f1 0.0000 %
12/01 17:14:12:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 17:14:12:  Step:40000, Best: f1:30.746, p:35.383,r:27.184, Curr: f1:30.7460, p:35.383,r:27.184 
12/01 17:14:23:  New best model, new f1 30.7460 % >= previous f1 0.0000 %
12/01 17:14:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 17:14:23:  Step:40000, Best: f1:30.746, p:35.383,r:27.184, Curr: f1:30.7460, p:35.383,r:27.184 
12/01 18:04:58:  New best model, new f1 35.9474 % >= previous f1 30.7460 %
12/01 18:04:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 18:04:59:  Step:50000, Best: f1:35.947, p:39.635,r:32.888, Curr: f1:35.9474, p:39.635,r:32.888 
12/01 18:05:00:  New best model, new f1 35.9474 % >= previous f1 30.7460 %
12/01 18:05:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 18:05:00:  Step:50000, Best: f1:35.947, p:39.635,r:32.888, Curr: f1:35.9474, p:39.635,r:32.888 
12/01 18:55:22:  New best model, new f1 37.9796 % >= previous f1 35.9474 %
12/01 18:55:22:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 18:55:22:  Step:60000, Best: f1:37.980, p:41.729,r:34.848, Curr: f1:37.9796, p:41.729,r:34.848 
12/01 18:55:33:  New best model, new f1 37.9796 % >= previous f1 35.9474 %
12/01 18:55:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 18:55:33:  Step:60000, Best: f1:37.980, p:41.729,r:34.848, Curr: f1:37.9796, p:41.729,r:34.848 
12/01 19:46:03:  New best model, new f1 39.6702 % >= previous f1 37.9796 %
12/01 19:46:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 19:46:03:  Step:70000, Best: f1:39.670, p:43.511,r:36.453, Curr: f1:39.6702, p:43.511,r:36.453 
12/01 19:46:15:  New best model, new f1 39.6702 % >= previous f1 37.9796 %
12/01 19:46:15:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 19:46:15:  Step:70000, Best: f1:39.670, p:43.511,r:36.453, Curr: f1:39.6702, p:43.511,r:36.453 
12/01 20:36:49:  New best model, new f1 40.4843 % >= previous f1 39.6702 %
12/01 20:36:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 20:36:49:  Step:80000, Best: f1:40.484, p:44.327,r:37.255, Curr: f1:40.4843, p:44.327,r:37.255 
12/01 20:36:57:  New best model, new f1 40.4843 % >= previous f1 39.6702 %
12/01 20:36:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 20:36:57:  Step:80000, Best: f1:40.484, p:44.327,r:37.255, Curr: f1:40.4843, p:44.327,r:37.255 
12/01 21:27:31:  New best model, new f1 40.8321 % >= previous f1 40.4843 %
12/01 21:27:31:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 21:27:31:  Step:90000, Best: f1:40.832, p:44.656,r:37.611, Curr: f1:40.8321, p:44.656,r:37.611 
12/01 21:27:41:  New best model, new f1 40.8321 % >= previous f1 40.4843 %
12/01 21:27:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 21:27:41:  Step:90000, Best: f1:40.832, p:44.656,r:37.611, Curr: f1:40.8321, p:44.656,r:37.611 
12/01 22:18:07:  New best model, new f1 41.6465 % >= previous f1 40.8321 %
12/01 22:18:07:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 22:18:07:  Step:100000, Best: f1:41.646, p:45.599,r:38.324, Curr: f1:41.6465, p:45.599,r:38.324 
12/01 22:18:18:  New best model, new f1 41.6465 % >= previous f1 40.8321 %
12/01 22:18:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 22:18:18:  Step:100000, Best: f1:41.646, p:45.599,r:38.324, Curr: f1:41.6465, p:45.599,r:38.324 
12/01 23:08:48:  New best model, new f1 41.8762 % >= previous f1 41.6465 %
12/01 23:08:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 23:08:48:  Step:110000, Best: f1:41.876, p:45.772,r:38.592, Curr: f1:41.8762, p:45.772,r:38.592 
12/01 23:08:57:  New best model, new f1 41.8762 % >= previous f1 41.6465 %
12/01 23:08:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 23:08:57:  Step:110000, Best: f1:41.876, p:45.772,r:38.592, Curr: f1:41.8762, p:45.772,r:38.592 
12/01 23:59:28:  New best model, new f1 42.7260 % >= previous f1 41.8762 %
12/01 23:59:28:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 23:59:28:  Step:120000, Best: f1:42.726, p:46.674,r:39.394, Curr: f1:42.7260, p:46.674,r:39.394 
12/01 23:59:39:  New best model, new f1 42.7260 % >= previous f1 41.8762 %
12/01 23:59:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/01 23:59:39:  Step:120000, Best: f1:42.726, p:46.674,r:39.394, Curr: f1:42.7260, p:46.674,r:39.394 
12/02 00:50:11:  do not save, best f1: 42.7260
12/02 00:50:11:  Step:130000, Best: f1:42.726, p:46.674,r:39.394, Curr: f1:42.2018, p:46.048,r:38.948 
12/02 00:50:21:  do not save, best f1: 42.7260
12/02 00:50:21:  Step:130000, Best: f1:42.726, p:46.674,r:39.394, Curr: f1:42.2018, p:46.048,r:38.948 
12/02 01:40:48:  do not save, best f1: 42.7260
12/02 01:40:48:  Step:140000, Best: f1:42.726, p:46.674,r:39.394, Curr: f1:42.6641, p:46.526,r:39.394 
12/02 01:40:58:  do not save, best f1: 42.7260
12/02 01:40:58:  Step:140000, Best: f1:42.726, p:46.674,r:39.394, Curr: f1:42.6641, p:46.526,r:39.394 
12/02 02:31:29:  do not save, best f1: 42.7260
12/02 02:31:29:  Step:150000, Best: f1:42.726, p:46.674,r:39.394, Curr: f1:42.7053, p:46.624,r:39.394 
12/02 02:31:40:  do not save, best f1: 42.7260
12/02 02:31:40:  Step:150000, Best: f1:42.726, p:46.674,r:39.394, Curr: f1:42.7053, p:46.624,r:39.394 
12/02 03:21:59:  New best model, new f1 43.3478 % >= previous f1 42.7260 %
12/02 03:21:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 03:21:59:  Step:160000, Best: f1:43.348, p:47.407,r:39.929, Curr: f1:43.3478, p:47.407,r:39.929 
12/02 03:22:09:  New best model, new f1 43.3478 % >= previous f1 42.7260 %
12/02 03:22:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 03:22:09:  Step:160000, Best: f1:43.348, p:47.407,r:39.929, Curr: f1:43.3478, p:47.407,r:39.929 
12/02 04:12:30:  New best model, new f1 43.4109 % >= previous f1 43.3478 %
12/02 04:12:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 04:12:30:  Step:170000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:43.4109, p:47.558,r:39.929 
12/02 04:12:42:  New best model, new f1 43.4109 % >= previous f1 43.3478 %
12/02 04:12:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 04:12:42:  Step:170000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:43.4109, p:47.558,r:39.929 
12/02 05:03:10:  do not save, best f1: 43.4109
12/02 05:03:10:  Step:180000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:43.2171, p:47.346,r:39.750 
12/02 05:03:20:  do not save, best f1: 43.4109
12/02 05:03:20:  Step:180000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:43.2171, p:47.346,r:39.750 
12/02 05:53:52:  do not save, best f1: 43.4109
12/02 05:53:52:  Step:190000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:41.7636, p:45.754,r:38.414 
12/02 05:54:04:  do not save, best f1: 43.4109
12/02 05:54:04:  Step:190000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:41.7636, p:45.754,r:38.414 
12/02 06:44:43:  do not save, best f1: 43.4109
12/02 06:44:43:  Step:200000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:43.3349, p:47.503,r:39.840 
12/02 06:44:51:  do not save, best f1: 43.4109
12/02 06:44:51:  Step:200000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:43.3349, p:47.503,r:39.840 
12/02 07:35:24:  do not save, best f1: 43.4109
12/02 07:35:24:  Step:210000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:42.6007, p:46.752,r:39.127 
12/02 07:35:32:  do not save, best f1: 43.4109
12/02 07:35:32:  Step:210000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:42.6007, p:46.752,r:39.127 
12/02 07:47:37:  do not save, best f1: 43.4109
12/02 07:47:37:  Step:210000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:42.6007, p:46.752,r:39.127 
12/02 07:47:54:  do not save, best f1: 43.4109
12/02 07:47:54:  Step:210000, Best: f1:43.411, p:47.558,r:39.929, Curr: f1:42.6007, p:46.752,r:39.127 
12/02 13:19:56:  train data num: 2100  dev data num: 727
12/02 13:19:56:  train data num: 2100  dev data num: 727
12/02 14:11:42:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/02 14:11:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 14:11:42:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/02 14:11:42:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/02 14:11:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 14:11:42:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/02 15:01:59:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/02 15:01:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 15:01:59:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/02 15:02:21:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/02 15:02:21:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 15:02:21:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/02 15:52:39:  New best model, new f1 0.1125 % >= previous f1 0.0000 %
12/02 15:52:39:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 15:52:39:  Step:30000, Best: f1:0.113, p:0.153,r:0.089, Curr: f1:0.1125, p:0.153,r:0.089 
12/02 15:52:59:  New best model, new f1 0.1125 % >= previous f1 0.0000 %
12/02 15:52:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 15:52:59:  Step:30000, Best: f1:0.113, p:0.153,r:0.089, Curr: f1:0.1125, p:0.153,r:0.089 
12/02 16:43:13:  New best model, new f1 31.7347 % >= previous f1 0.1125 %
12/02 16:43:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 16:43:13:  Step:40000, Best: f1:31.735, p:37.112,r:27.718, Curr: f1:31.7347, p:37.112,r:27.718 
12/02 16:43:36:  New best model, new f1 31.7347 % >= previous f1 0.1125 %
12/02 16:43:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 16:43:37:  Step:40000, Best: f1:31.735, p:37.112,r:27.718, Curr: f1:31.7347, p:37.112,r:27.718 
12/02 17:33:48:  New best model, new f1 39.8524 % >= previous f1 31.7347 %
12/02 17:33:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 17:33:48:  Step:50000, Best: f1:39.852, p:48.774,r:33.690, Curr: f1:39.8524, p:48.774,r:33.690 
12/02 17:34:11:  New best model, new f1 39.8524 % >= previous f1 31.7347 %
12/02 17:34:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 17:34:11:  Step:50000, Best: f1:39.852, p:48.774,r:33.690, Curr: f1:39.8524, p:48.774,r:33.690 
12/02 18:24:24:  New best model, new f1 42.4339 % >= previous f1 39.8524 %
12/02 18:24:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 18:24:24:  Step:60000, Best: f1:42.434, p:52.214,r:35.740, Curr: f1:42.4339, p:52.214,r:35.740 
12/02 18:24:27:  New best model, new f1 42.4339 % >= previous f1 39.8524 %
12/02 18:24:27:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 18:24:27:  Step:60000, Best: f1:42.434, p:52.214,r:35.740, Curr: f1:42.4339, p:52.214,r:35.740 
12/02 19:14:48:  New best model, new f1 44.3152 % >= previous f1 42.4339 %
12/02 19:14:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 19:14:48:  Step:70000, Best: f1:44.315, p:54.486,r:37.344, Curr: f1:44.3152, p:54.486,r:37.344 
12/02 19:14:53:  New best model, new f1 44.3152 % >= previous f1 42.4339 %
12/02 19:14:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 19:14:53:  Step:70000, Best: f1:44.315, p:54.486,r:37.344, Curr: f1:44.3152, p:54.486,r:37.344 
12/02 20:05:19:  New best model, new f1 45.0555 % >= previous f1 44.3152 %
12/02 20:05:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 20:05:19:  Step:80000, Best: f1:45.056, p:55.397,r:37.968, Curr: f1:45.0555, p:55.397,r:37.968 
12/02 20:05:23:  New best model, new f1 45.0555 % >= previous f1 44.3152 %
12/02 20:05:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 20:05:23:  Step:80000, Best: f1:45.056, p:55.397,r:37.968, Curr: f1:45.0555, p:55.397,r:37.968 
12/02 20:55:37:  New best model, new f1 45.8774 % >= previous f1 45.0555 %
12/02 20:55:37:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 20:55:37:  Step:90000, Best: f1:45.877, p:56.364,r:38.681, Curr: f1:45.8774, p:56.364,r:38.681 
12/02 20:55:58:  New best model, new f1 45.8774 % >= previous f1 45.0555 %
12/02 20:55:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 20:55:58:  Step:90000, Best: f1:45.877, p:56.364,r:38.681, Curr: f1:45.8774, p:56.364,r:38.681 
12/02 21:46:18:  do not save, best f1: 45.8774
12/02 21:46:18:  Step:100000, Best: f1:45.877, p:56.364,r:38.681, Curr: f1:45.3728, p:55.787,r:38.235 
12/02 21:46:22:  do not save, best f1: 45.8774
12/02 21:46:22:  Step:100000, Best: f1:45.877, p:56.364,r:38.681, Curr: f1:45.3728, p:55.787,r:38.235 
12/02 22:36:43:  do not save, best f1: 45.8774
12/02 22:36:43:  Step:110000, Best: f1:45.877, p:56.364,r:38.681, Curr: f1:45.5362, p:55.901,r:38.414 
12/02 22:36:48:  do not save, best f1: 45.8774
12/02 22:36:48:  Step:110000, Best: f1:45.877, p:56.364,r:38.681, Curr: f1:45.5362, p:55.901,r:38.414 
12/02 23:27:02:  New best model, new f1 46.1701 % >= previous f1 45.8774 %
12/02 23:27:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 23:27:02:  Step:120000, Best: f1:46.170, p:56.680,r:38.948, Curr: f1:46.1701, p:56.680,r:38.948 
12/02 23:27:25:  New best model, new f1 46.1701 % >= previous f1 45.8774 %
12/02 23:27:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/02 23:27:25:  Step:120000, Best: f1:46.170, p:56.680,r:38.948, Curr: f1:46.1701, p:56.680,r:38.948 
12/03 00:17:33:  New best model, new f1 46.3890 % >= previous f1 46.1701 %
12/03 00:17:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 00:17:33:  Step:130000, Best: f1:46.389, p:56.774,r:39.216, Curr: f1:46.3890, p:56.774,r:39.216 
12/03 00:17:57:  New best model, new f1 46.3890 % >= previous f1 46.1701 %
12/03 00:17:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 00:17:58:  Step:130000, Best: f1:46.389, p:56.774,r:39.216, Curr: f1:46.3890, p:56.774,r:39.216 
12/03 01:08:19:  do not save, best f1: 46.3890
12/03 01:08:19:  Step:140000, Best: f1:46.389, p:56.774,r:39.216, Curr: f1:46.3814, p:56.939,r:39.127 
12/03 01:08:25:  do not save, best f1: 46.3890
12/03 01:08:25:  Step:140000, Best: f1:46.389, p:56.774,r:39.216, Curr: f1:46.3814, p:56.939,r:39.127 
12/03 01:58:48:  New best model, new f1 47.0712 % >= previous f1 46.3890 %
12/03 01:58:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 01:58:48:  Step:150000, Best: f1:47.071, p:57.697,r:39.750, Curr: f1:47.0712, p:57.697,r:39.750 
12/03 01:58:50:  New best model, new f1 47.0712 % >= previous f1 46.3890 %
12/03 01:58:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 01:58:50:  Step:150000, Best: f1:47.071, p:57.697,r:39.750, Curr: f1:47.0712, p:57.697,r:39.750 
12/03 02:49:11:  do not save, best f1: 47.0712
12/03 02:49:11:  Step:160000, Best: f1:47.071, p:57.697,r:39.750, Curr: f1:46.9657, p:57.568,r:39.661 
12/03 02:49:14:  do not save, best f1: 47.0712
12/03 02:49:14:  Step:160000, Best: f1:47.071, p:57.697,r:39.750, Curr: f1:46.9657, p:57.568,r:39.661 
12/03 03:39:23:  do not save, best f1: 47.0712
12/03 03:39:23:  Step:170000, Best: f1:47.071, p:57.697,r:39.750, Curr: f1:46.5753, p:56.959,r:39.394 
12/03 03:39:46:  do not save, best f1: 47.0712
12/03 03:39:46:  Step:170000, Best: f1:47.071, p:57.697,r:39.750, Curr: f1:46.5753, p:56.959,r:39.394 
12/03 04:30:14:  do not save, best f1: 47.0712
12/03 04:30:14:  Step:180000, Best: f1:47.071, p:57.697,r:39.750, Curr: f1:47.0216, p:57.548,r:39.750 
12/03 04:30:15:  do not save, best f1: 47.0712
12/03 04:30:15:  Step:180000, Best: f1:47.071, p:57.697,r:39.750, Curr: f1:47.0216, p:57.548,r:39.750 
12/03 05:20:32:  New best model, new f1 47.1768 % >= previous f1 47.0712 %
12/03 05:20:32:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 05:20:32:  Step:190000, Best: f1:47.177, p:57.827,r:39.840, Curr: f1:47.1768, p:57.827,r:39.840 
12/03 05:20:35:  New best model, new f1 47.1768 % >= previous f1 47.0712 %
12/03 05:20:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 05:20:35:  Step:190000, Best: f1:47.177, p:57.827,r:39.840, Curr: f1:47.1768, p:57.827,r:39.840 
12/03 06:10:56:  do not save, best f1: 47.1768
12/03 06:10:56:  Step:200000, Best: f1:47.177, p:57.827,r:39.840, Curr: f1:46.4625, p:56.995,r:39.216 
12/03 06:11:19:  do not save, best f1: 47.1768
12/03 06:11:19:  Step:200000, Best: f1:47.177, p:57.827,r:39.840, Curr: f1:46.4625, p:56.995,r:39.216 
12/03 07:01:40:  do not save, best f1: 47.1768
12/03 07:01:40:  Step:210000, Best: f1:47.177, p:57.827,r:39.840, Curr: f1:45.5789, p:55.656,r:38.592 
12/03 07:01:44:  do not save, best f1: 47.1768
12/03 07:01:44:  Step:210000, Best: f1:47.177, p:57.827,r:39.840, Curr: f1:45.5789, p:55.656,r:38.592 
12/03 07:13:51:  do not save, best f1: 47.1768
12/03 07:13:51:  Step:210000, Best: f1:47.177, p:57.827,r:39.840, Curr: f1:45.5789, p:55.656,r:38.592 
12/03 07:13:59:  do not save, best f1: 47.1768
12/03 07:13:59:  Step:210000, Best: f1:47.177, p:57.827,r:39.840, Curr: f1:45.5789, p:55.656,r:38.592 
12/03 09:29:36:  train data num: 2100  dev data num: 727
12/03 09:29:36:  train data num: 2100  dev data num: 727
12/03 09:38:50:  train data num: 2100  dev data num: 727
12/03 09:38:50:  train data num: 2100  dev data num: 727
12/03 09:43:50:  train data num: 2100  dev data num: 727
12/03 09:43:50:  train data num: 2100  dev data num: 727
12/03 09:55:33:  train data num: 2100  dev data num: 727
12/03 09:55:33:  train data num: 2100  dev data num: 727
12/03 09:58:36:  train data num: 2100  dev data num: 727
12/03 09:58:36:  train data num: 2100  dev data num: 727
12/03 11:05:33:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/03 11:05:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 11:05:33:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/03 11:05:43:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/03 11:05:43:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 11:05:43:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/03 12:11:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/03 12:11:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 12:11:03:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/03 12:11:13:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/03 12:11:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 12:11:13:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/03 13:16:33:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/03 13:16:33:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 13:16:33:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/03 13:16:42:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/03 13:16:42:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 13:16:42:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/03 14:22:06:  New best model, new f1 36.6420 % >= previous f1 0.0000 %
12/03 14:22:06:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 14:22:06:  Step:40000, Best: f1:36.642, p:44.948,r:30.927, Curr: f1:36.6420, p:44.948,r:30.927 
12/03 14:22:13:  New best model, new f1 36.6420 % >= previous f1 0.0000 %
12/03 14:22:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 14:22:13:  Step:40000, Best: f1:36.642, p:44.948,r:30.927, Curr: f1:36.6420, p:44.948,r:30.927 
12/03 15:27:29:  New best model, new f1 38.5798 % >= previous f1 36.6420 %
12/03 15:27:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 15:27:29:  Step:50000, Best: f1:38.580, p:47.582,r:32.442, Curr: f1:38.5798, p:47.582,r:32.442 
12/03 15:27:35:  New best model, new f1 38.5798 % >= previous f1 36.6420 %
12/03 15:27:35:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 15:27:35:  Step:50000, Best: f1:38.580, p:47.582,r:32.442, Curr: f1:38.5798, p:47.582,r:32.442 
12/03 16:32:38:  New best model, new f1 41.5695 % >= previous f1 38.5798 %
12/03 16:32:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 16:32:38:  Step:60000, Best: f1:41.569, p:51.309,r:34.938, Curr: f1:41.5695, p:51.309,r:34.938 
12/03 16:32:52:  New best model, new f1 41.5695 % >= previous f1 38.5798 %
12/03 16:32:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 16:32:52:  Step:60000, Best: f1:41.569, p:51.309,r:34.938, Curr: f1:41.5695, p:51.309,r:34.938 
12/03 17:38:05:  New best model, new f1 42.2669 % >= previous f1 41.5695 %
12/03 17:38:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 17:38:05:  Step:70000, Best: f1:42.267, p:52.089,r:35.561, Curr: f1:42.2669, p:52.089,r:35.561 
12/03 17:38:10:  New best model, new f1 42.2669 % >= previous f1 41.5695 %
12/03 17:38:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 17:38:10:  Step:70000, Best: f1:42.267, p:52.089,r:35.561, Curr: f1:42.2669, p:52.089,r:35.561 
12/03 18:43:29:  do not save, best f1: 42.2669
12/03 18:43:29:  Step:80000, Best: f1:42.267, p:52.089,r:35.561, Curr: f1:42.0941, p:51.756,r:35.472 
12/03 18:43:36:  do not save, best f1: 42.2669
12/03 18:43:36:  Step:80000, Best: f1:42.267, p:52.089,r:35.561, Curr: f1:42.0941, p:51.756,r:35.472 
12/03 19:48:46:  New best model, new f1 44.1036 % >= previous f1 42.2669 %
12/03 19:48:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 19:48:46:  Step:90000, Best: f1:44.104, p:54.226,r:37.166, Curr: f1:44.1036, p:54.226,r:37.166 
12/03 19:48:57:  New best model, new f1 44.1036 % >= previous f1 42.2669 %
12/03 19:48:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 19:48:57:  Step:90000, Best: f1:44.104, p:54.226,r:37.166, Curr: f1:44.1036, p:54.226,r:37.166 
12/03 20:54:10:  do not save, best f1: 44.1036
12/03 20:54:10:  Step:100000, Best: f1:44.104, p:54.226,r:37.166, Curr: f1:43.9386, p:54.107,r:36.988 
12/03 20:54:23:  do not save, best f1: 44.1036
12/03 20:54:23:  Step:100000, Best: f1:44.104, p:54.226,r:37.166, Curr: f1:43.9386, p:54.107,r:36.988 
12/03 21:59:34:  New best model, new f1 45.4786 % >= previous f1 44.1036 %
12/03 21:59:34:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 21:59:34:  Step:110000, Best: f1:45.479, p:55.917,r:38.324, Curr: f1:45.4786, p:55.917,r:38.324 
12/03 21:59:48:  New best model, new f1 45.4786 % >= previous f1 44.1036 %
12/03 21:59:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/03 21:59:48:  Step:110000, Best: f1:45.479, p:55.917,r:38.324, Curr: f1:45.4786, p:55.917,r:38.324 
12/03 23:05:02:  do not save, best f1: 45.4786
12/03 23:05:02:  Step:120000, Best: f1:45.479, p:55.917,r:38.324, Curr: f1:45.4305, p:55.772,r:38.324 
12/03 23:05:09:  do not save, best f1: 45.4786
12/03 23:05:09:  Step:120000, Best: f1:45.479, p:55.917,r:38.324, Curr: f1:45.4305, p:55.772,r:38.324 
12/04 00:10:17:  New best model, new f1 46.9905 % >= previous f1 45.4786 %
12/04 00:10:17:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/04 00:10:17:  Step:130000, Best: f1:46.990, p:57.642,r:39.661, Curr: f1:46.9905, p:57.642,r:39.661 
12/04 00:10:30:  New best model, new f1 46.9905 % >= previous f1 45.4786 %
12/04 00:10:30:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/04 00:10:30:  Step:130000, Best: f1:46.990, p:57.642,r:39.661, Curr: f1:46.9905, p:57.642,r:39.661 
12/04 01:15:43:  New best model, new f1 48.0973 % >= previous f1 46.9905 %
12/04 01:15:43:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/04 01:15:43:  Step:140000, Best: f1:48.097, p:59.091,r:40.553, Curr: f1:48.0973, p:59.091,r:40.553 
12/04 01:15:51:  New best model, new f1 48.0973 % >= previous f1 46.9905 %
12/04 01:15:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/04 01:15:51:  Step:140000, Best: f1:48.097, p:59.091,r:40.553, Curr: f1:48.0973, p:59.091,r:40.553 
12/04 02:21:02:  New best model, new f1 48.3888 % >= previous f1 48.0973 %
12/04 02:21:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/04 02:21:02:  Step:150000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:48.3888, p:59.403,r:40.820 
12/04 02:21:11:  New best model, new f1 48.3888 % >= previous f1 48.0973 %
12/04 02:21:11:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/04 02:21:11:  Step:150000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:48.3888, p:59.403,r:40.820 
12/04 03:26:27:  do not save, best f1: 48.3888
12/04 03:26:27:  Step:160000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:47.0712, p:57.697,r:39.750 
12/04 03:26:34:  do not save, best f1: 48.3888
12/04 03:26:34:  Step:160000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:47.0712, p:57.697,r:39.750 
12/04 04:31:46:  do not save, best f1: 48.3888
12/04 04:31:46:  Step:170000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:47.7596, p:58.452,r:40.374 
12/04 04:31:56:  do not save, best f1: 48.3888
12/04 04:31:56:  Step:170000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:47.7596, p:58.452,r:40.374 
12/04 05:37:13:  do not save, best f1: 48.3888
12/04 05:37:13:  Step:180000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:48.1013, p:58.915,r:40.642 
12/04 05:37:22:  do not save, best f1: 48.3888
12/04 05:37:22:  Step:180000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:48.1013, p:58.915,r:40.642 
12/04 06:42:33:  do not save, best f1: 48.3888
12/04 06:42:33:  Step:190000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:47.2880, p:57.786,r:40.018 
12/04 06:42:40:  do not save, best f1: 48.3888
12/04 06:42:40:  Step:190000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:47.2880, p:57.786,r:40.018 
12/04 07:48:00:  do not save, best f1: 48.3888
12/04 07:48:00:  Step:200000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:45.8706, p:55.969,r:38.859 
12/04 07:48:06:  do not save, best f1: 48.3888
12/04 07:48:06:  Step:200000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:45.8706, p:55.969,r:38.859 
12/04 08:53:22:  do not save, best f1: 48.3888
12/04 08:53:22:  Step:210000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:46.2836, p:56.645,r:39.127 
12/04 08:53:28:  do not save, best f1: 48.3888
12/04 08:53:28:  Step:210000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:46.2836, p:56.645,r:39.127 
12/04 09:06:07:  do not save, best f1: 48.3888
12/04 09:06:07:  Step:210000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:46.2836, p:56.645,r:39.127 
12/04 09:06:22:  do not save, best f1: 48.3888
12/04 09:06:22:  Step:210000, Best: f1:48.389, p:59.403,r:40.820, Curr: f1:46.2836, p:56.645,r:39.127 
12/05 02:07:08:  train data num: 2100  dev data num: 727
12/05 02:07:08:  train data num: 2100  dev data num: 727
12/05 02:07:08:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 131, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/utils.py", line 132, in wrap_with_peft
    args.tokenizer = LlamaTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 1838, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for '../../_llm_weight/minigpt4'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '../../_llm_weight/minigpt4' is the correct path to a directory containing all relevant files for a LlamaTokenizer tokenizer.
12/05 02:07:08:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 162, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 131, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/utils.py", line 132, in wrap_with_peft
    args.tokenizer = LlamaTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 1838, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for '../../_llm_weight/minigpt4'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '../../_llm_weight/minigpt4' is the correct path to a directory containing all relevant files for a LlamaTokenizer tokenizer.
12/05 03:16:42:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 197, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 153, in _main
    train_ds = SADataset(args.data_file['train'], aspect=train_aspect, tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 48, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 136, in _get_data
    "predict_aspect": self.aspect[index]
TypeError: 'NoneType' object is not subscriptable
12/05 03:16:43:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 197, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 153, in _main
    train_ds = SADataset(args.data_file['train'], aspect=train_aspect, tokenizer=True, args=args, train_flag=True, **args.kwargs_ds)  # train_flag: for exclude same training example
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 48, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 136, in _get_data
    "predict_aspect": self.aspect[index]
TypeError: 'NoneType' object is not subscriptable
12/05 03:20:53:  train data num: 2100  dev data num: 727
12/05 03:20:53:  train data num: 2100  dev data num: 727
12/05 03:22:12:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 194, in <module>
    args.logger.error("Error", exc_info=True)
  File "/workspace/GEMEL/twitter/code/main.py", line 178, in _main
    # 6.inference test
  File "/workspace/GEMEL/twitter/code/main.py", line 79, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 173, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 196, in _get_query
    prefix_list = self._incontext_prefix(item)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 230, in _incontext_prefix
    at_q = compose_question(index, aspect, sentiment=self.opinion[sentiment])
TypeError: compose_question() missing 1 required positional argument: 'at'
12/05 03:22:12:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 194, in <module>
    args.logger.error("Error", exc_info=True)
  File "/workspace/GEMEL/twitter/code/main.py", line 178, in _main
    # 6.inference test
  File "/workspace/GEMEL/twitter/code/main.py", line 79, in _train
    for batch_idx, batch_data in enumerate(args.train_dl):
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py", line 677, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py", line 54, in fetch
    return self.collate_fn(data)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 173, in collate_fn
    batch_querys.append(self._get_query(item))
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 196, in _get_query
    prefix_list = self._incontext_prefix(item)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 230, in _incontext_prefix
    at_q = compose_question(index, aspect, sentiment=self.opinion[sentiment])
TypeError: compose_question() missing 1 required positional argument: 'at'
12/05 03:25:53:  train data num: 2100  dev data num: 727
12/05 03:25:53:  train data num: 2100  dev data num: 727
12/05 03:32:50:  train data num: 2100  dev data num: 727
12/05 03:32:50:  train data num: 2100  dev data num: 727
12/05 04:27:24:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/05 04:27:24:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 04:27:24:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/05 04:27:25:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/05 04:27:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 04:27:25:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/05 05:20:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/05 05:20:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 05:20:04:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/05 05:20:14:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/05 05:20:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 05:20:14:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/05 06:12:53:  New best model, new f1 0.4402 % >= previous f1 0.0000 %
12/05 06:12:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 06:12:53:  Step:30000, Best: f1:0.440, p:1.245,r:0.267, Curr: f1:0.4402, p:1.245,r:0.267 
12/05 06:13:13:  New best model, new f1 0.4402 % >= previous f1 0.0000 %
12/05 06:13:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 06:13:13:  Step:30000, Best: f1:0.440, p:1.245,r:0.267, Curr: f1:0.4402, p:1.245,r:0.267 
12/05 07:06:00:  New best model, new f1 21.6567 % >= previous f1 0.4402 %
12/05 07:06:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 07:06:00:  Step:40000, Best: f1:21.657, p:27.586,r:17.825, Curr: f1:21.6567, p:27.586,r:17.825 
12/05 07:06:18:  New best model, new f1 21.6567 % >= previous f1 0.4402 %
12/05 07:06:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 07:06:18:  Step:40000, Best: f1:21.657, p:27.586,r:17.825, Curr: f1:21.6567, p:27.586,r:17.825 
12/05 07:59:08:  New best model, new f1 30.4509 % >= previous f1 21.6567 %
12/05 07:59:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 07:59:08:  Step:50000, Best: f1:30.451, p:37.615,r:25.579, Curr: f1:30.4509, p:37.615,r:25.579 
12/05 07:59:10:  New best model, new f1 30.4509 % >= previous f1 21.6567 %
12/05 07:59:10:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 07:59:10:  Step:50000, Best: f1:30.451, p:37.615,r:25.579, Curr: f1:30.4509, p:37.615,r:25.579 
12/05 08:51:48:  New best model, new f1 36.1038 % >= previous f1 30.4509 %
12/05 08:51:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 08:51:48:  Step:60000, Best: f1:36.104, p:44.459,r:30.392, Curr: f1:36.1038, p:44.459,r:30.392 
12/05 08:52:09:  New best model, new f1 36.1038 % >= previous f1 30.4509 %
12/05 08:52:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 08:52:09:  Step:60000, Best: f1:36.104, p:44.459,r:30.392, Curr: f1:36.1038, p:44.459,r:30.392 
12/05 09:45:00:  New best model, new f1 39.7253 % >= previous f1 36.1038 %
12/05 09:45:00:  New best model, new f1 39.7253 % >= previous f1 36.1038 %
12/05 09:45:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 09:45:00:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 09:45:00:  Step:70000, Best: f1:39.725, p:48.768,r:33.512, Curr: f1:39.7253, p:48.768,r:33.512 
12/05 09:45:00:  Step:70000, Best: f1:39.725, p:48.768,r:33.512, Curr: f1:39.7253, p:48.768,r:33.512 
12/05 10:37:40:  New best model, new f1 42.4658 % >= previous f1 39.7253 %
12/05 10:37:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 10:37:40:  Step:80000, Best: f1:42.466, p:51.933,r:35.918, Curr: f1:42.4658, p:51.933,r:35.918 
12/05 10:37:59:  New best model, new f1 42.4658 % >= previous f1 39.7253 %
12/05 10:37:59:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 10:37:59:  Step:80000, Best: f1:42.466, p:51.933,r:35.918, Curr: f1:42.4658, p:51.933,r:35.918 
12/05 11:30:41:  New best model, new f1 45.0422 % >= previous f1 42.4658 %
12/05 11:30:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 11:30:41:  Step:90000, Best: f1:45.042, p:55.168,r:38.057, Curr: f1:45.0422, p:55.168,r:38.057 
12/05 11:31:02:  New best model, new f1 45.0422 % >= previous f1 42.4658 %
12/05 11:31:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 11:31:02:  Step:90000, Best: f1:45.042, p:55.168,r:38.057, Curr: f1:45.0422, p:55.168,r:38.057 
12/05 12:23:46:  do not save, best f1: 45.0422
12/05 12:23:46:  Step:100000, Best: f1:45.042, p:55.168,r:38.057, Curr: f1:44.7966, p:54.994,r:37.790 
12/05 12:23:46:  do not save, best f1: 45.0422
12/05 12:23:46:  Step:100000, Best: f1:45.042, p:55.168,r:38.057, Curr: f1:44.7966, p:54.994,r:37.790 
12/05 13:16:41:  New best model, new f1 45.2532 % >= previous f1 45.0422 %
12/05 13:16:41:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 13:16:41:  Step:110000, Best: f1:45.253, p:55.426,r:38.235, Curr: f1:45.2532, p:55.426,r:38.235 
12/05 13:16:58:  New best model, new f1 45.2532 % >= previous f1 45.0422 %
12/05 13:16:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 13:16:58:  Step:110000, Best: f1:45.253, p:55.426,r:38.235, Curr: f1:45.2532, p:55.426,r:38.235 
12/05 14:09:56:  New best model, new f1 46.6737 % >= previous f1 45.2532 %
12/05 14:09:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 14:09:56:  Step:120000, Best: f1:46.674, p:57.254,r:39.394, Curr: f1:46.6737, p:57.254,r:39.394 
12/05 14:09:57:  New best model, new f1 46.6737 % >= previous f1 45.2532 %
12/05 14:09:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 14:09:57:  Step:120000, Best: f1:46.674, p:57.254,r:39.394, Curr: f1:46.6737, p:57.254,r:39.394 
12/05 15:02:43:  New best model, new f1 47.3934 % >= previous f1 46.6737 %
12/05 15:02:43:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 15:02:43:  Step:130000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.3934, p:57.915,r:40.107 
12/05 15:03:02:  New best model, new f1 47.3934 % >= previous f1 46.6737 %
12/05 15:03:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 15:03:02:  Step:130000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.3934, p:57.915,r:40.107 
12/05 15:55:41:  do not save, best f1: 47.3934
12/05 15:55:41:  Step:140000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.1270, p:57.677,r:39.840 
12/05 15:56:02:  do not save, best f1: 47.3934
12/05 15:56:02:  Step:140000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.1270, p:57.677,r:39.840 
12/05 16:48:53:  do not save, best f1: 47.3934
12/05 16:48:53:  Step:150000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:46.9968, p:57.474,r:39.750 
12/05 16:48:54:  do not save, best f1: 47.3934
12/05 16:48:54:  Step:150000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:46.9968, p:57.474,r:39.750 
12/05 17:41:30:  do not save, best f1: 47.3934
12/05 17:41:30:  Step:160000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.2076, p:57.732,r:39.929 
12/05 17:41:49:  do not save, best f1: 47.3934
12/05 17:41:49:  Step:160000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.2076, p:57.732,r:39.929 
12/05 18:34:37:  do not save, best f1: 47.3934
12/05 18:34:37:  Step:170000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.2135, p:57.564,r:40.018 
12/05 18:34:38:  do not save, best f1: 47.3934
12/05 18:34:38:  Step:170000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.2135, p:57.564,r:40.018 
12/05 19:27:29:  do not save, best f1: 47.3934
12/05 19:27:29:  Step:180000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.0836, p:57.362,r:39.929 
12/05 19:27:29:  do not save, best f1: 47.3934
12/05 19:27:29:  Step:180000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.0836, p:57.362,r:39.929 
12/05 20:20:09:  do not save, best f1: 47.3934
12/05 20:20:09:  Step:190000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.1639, p:57.417,r:40.018 
12/05 20:20:09:  do not save, best f1: 47.3934
12/05 20:20:09:  Step:190000, Best: f1:47.393, p:57.915,r:40.107, Curr: f1:47.1639, p:57.417,r:40.018 
12/05 21:13:01:  New best model, new f1 47.5289 % >= previous f1 47.3934 %
12/05 21:13:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 21:13:01:  Step:200000, Best: f1:47.529, p:57.949,r:40.285, Curr: f1:47.5289, p:57.949,r:40.285 
12/05 21:13:02:  New best model, new f1 47.5289 % >= previous f1 47.3934 %
12/05 21:13:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/05 21:13:02:  Step:200000, Best: f1:47.529, p:57.949,r:40.285, Curr: f1:47.5289, p:57.949,r:40.285 
12/05 22:05:37:  do not save, best f1: 47.5289
12/05 22:05:37:  Step:210000, Best: f1:47.529, p:57.949,r:40.285, Curr: f1:46.7683, p:56.978,r:39.661 
12/05 22:05:58:  do not save, best f1: 47.5289
12/05 22:05:58:  Step:210000, Best: f1:47.529, p:57.949,r:40.285, Curr: f1:46.7683, p:56.978,r:39.661 
12/05 22:17:42:  do not save, best f1: 47.5289
12/05 22:17:42:  Step:210000, Best: f1:47.529, p:57.949,r:40.285, Curr: f1:46.7683, p:56.978,r:39.661 
12/05 22:18:22:  do not save, best f1: 47.5289
12/05 22:18:22:  Step:210000, Best: f1:47.529, p:57.949,r:40.285, Curr: f1:46.7683, p:56.978,r:39.661 
12/06 03:12:01:  train data num: 2100  dev data num: 727
12/06 03:12:01:  train data num: 2100  dev data num: 727
12/06 03:17:31:  train data num: 2100  dev data num: 727
12/06 03:17:31:  train data num: 2100  dev data num: 727
12/06 03:28:23:  train data num: 2100  dev data num: 727
12/06 03:28:23:  train data num: 2100  dev data num: 727
12/06 04:36:51:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/06 04:36:51:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 04:36:51:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/06 04:37:01:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/06 04:37:01:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 04:37:01:  Step:10000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/06 05:42:57:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/06 05:42:57:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 05:42:57:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/06 05:43:03:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/06 05:43:03:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 05:43:03:  Step:20000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/06 06:49:04:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/06 06:49:04:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 06:49:04:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/06 06:49:09:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/06 06:49:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 06:49:09:  Step:30000, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/06 07:54:49:  New best model, new f1 38.6096 % >= previous f1 0.0000 %
12/06 07:54:49:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 07:54:49:  Step:40000, Best: f1:38.610, p:48.262,r:32.175, Curr: f1:38.6096, p:48.262,r:32.175 
12/06 07:54:53:  New best model, new f1 38.6096 % >= previous f1 0.0000 %
12/06 07:54:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 07:54:53:  Step:40000, Best: f1:38.610, p:48.262,r:32.175, Curr: f1:38.6096, p:48.262,r:32.175 
12/06 09:02:14:  New best model, new f1 40.8875 % >= previous f1 38.6096 %
12/06 09:02:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 09:02:14:  Step:50000, Best: f1:40.887, p:50.195,r:34.492, Curr: f1:40.8875, p:50.195,r:34.492 
12/06 09:02:19:  New best model, new f1 40.8875 % >= previous f1 38.6096 %
12/06 09:02:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 09:02:19:  Step:50000, Best: f1:40.887, p:50.195,r:34.492, Curr: f1:40.8875, p:50.195,r:34.492 
12/06 10:08:58:  New best model, new f1 42.6455 % >= previous f1 40.8875 %
12/06 10:08:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 10:08:58:  Step:60000, Best: f1:42.646, p:52.474,r:35.918, Curr: f1:42.6455, p:52.474,r:35.918 
12/06 10:09:08:  New best model, new f1 42.6455 % >= previous f1 40.8875 %
12/06 10:09:08:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 10:09:08:  Step:60000, Best: f1:42.646, p:52.474,r:35.918, Curr: f1:42.6455, p:52.474,r:35.918 
12/06 11:14:40:  New best model, new f1 43.1746 % >= previous f1 42.6455 %
12/06 11:14:40:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 11:14:40:  Step:70000, Best: f1:43.175, p:53.125,r:36.364, Curr: f1:43.1746, p:53.125,r:36.364 
12/06 11:14:49:  New best model, new f1 43.1746 % >= previous f1 42.6455 %
12/06 11:14:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 11:14:50:  Step:70000, Best: f1:43.175, p:53.125,r:36.364, Curr: f1:43.1746, p:53.125,r:36.364 
12/06 12:20:25:  New best model, new f1 44.0445 % >= previous f1 43.1746 %
12/06 12:20:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 12:20:25:  Step:80000, Best: f1:44.044, p:54.237,r:37.077, Curr: f1:44.0445, p:54.237,r:37.077 
12/06 12:20:36:  New best model, new f1 44.0445 % >= previous f1 43.1746 %
12/06 12:20:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 12:20:36:  Step:80000, Best: f1:44.044, p:54.237,r:37.077, Curr: f1:44.0445, p:54.237,r:37.077 
12/06 13:26:05:  New best model, new f1 45.7143 % >= previous f1 44.0445 %
12/06 13:26:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 13:26:05:  Step:90000, Best: f1:45.714, p:56.250,r:38.503, Curr: f1:45.7143, p:56.250,r:38.503 
12/06 13:26:18:  New best model, new f1 45.7143 % >= previous f1 44.0445 %
12/06 13:26:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 13:26:18:  Step:90000, Best: f1:45.714, p:56.250,r:38.503, Curr: f1:45.7143, p:56.250,r:38.503 
12/06 14:31:38:  New best model, new f1 46.4796 % >= previous f1 45.7143 %
12/06 14:31:38:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 14:31:38:  Step:100000, Best: f1:46.480, p:57.236,r:39.127, Curr: f1:46.4796, p:57.236,r:39.127 
12/06 14:31:52:  New best model, new f1 46.4796 % >= previous f1 45.7143 %
12/06 14:31:52:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 14:31:52:  Step:100000, Best: f1:46.480, p:57.236,r:39.127, Curr: f1:46.4796, p:57.236,r:39.127 
12/06 15:37:19:  New best model, new f1 47.7801 % >= previous f1 46.4796 %
12/06 15:37:19:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 15:37:19:  Step:110000, Best: f1:47.780, p:58.701,r:40.285, Curr: f1:47.7801, p:58.701,r:40.285 
12/06 15:37:29:  New best model, new f1 47.7801 % >= previous f1 46.4796 %
12/06 15:37:29:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 15:37:29:  Step:110000, Best: f1:47.780, p:58.701,r:40.285, Curr: f1:47.7801, p:58.701,r:40.285 
12/06 16:42:43:  do not save, best f1: 47.7801
12/06 16:42:43:  Step:120000, Best: f1:47.780, p:58.701,r:40.285, Curr: f1:46.9593, p:57.737,r:39.572 
12/06 16:42:58:  do not save, best f1: 47.7801
12/06 16:42:58:  Step:120000, Best: f1:47.780, p:58.701,r:40.285, Curr: f1:46.9593, p:57.737,r:39.572 
12/06 17:48:19:  do not save, best f1: 47.7801
12/06 17:48:19:  Step:130000, Best: f1:47.780, p:58.701,r:40.285, Curr: f1:47.7045, p:58.473,r:40.285 
12/06 17:48:30:  do not save, best f1: 47.7801
12/06 17:48:30:  Step:130000, Best: f1:47.780, p:58.701,r:40.285, Curr: f1:47.7045, p:58.473,r:40.285 
12/06 18:53:47:  New best model, new f1 48.2868 % >= previous f1 47.7801 %
12/06 18:53:47:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 18:53:47:  Step:140000, Best: f1:48.287, p:59.097,r:40.820, Curr: f1:48.2868, p:59.097,r:40.820 
12/06 18:53:58:  New best model, new f1 48.2868 % >= previous f1 47.7801 %
12/06 18:53:58:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 18:53:58:  Step:140000, Best: f1:48.287, p:59.097,r:40.820, Curr: f1:48.2868, p:59.097,r:40.820 
12/06 19:59:14:  New best model, new f1 48.5774 % >= previous f1 48.2868 %
12/06 19:59:14:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 19:59:14:  Step:150000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:48.5774, p:59.407,r:41.087 
12/06 19:59:25:  New best model, new f1 48.5774 % >= previous f1 48.2868 %
12/06 19:59:25:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/06 19:59:25:  Step:150000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:48.5774, p:59.407,r:41.087 
12/06 21:04:45:  do not save, best f1: 48.5774
12/06 21:04:45:  Step:160000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:48.4945, p:59.533,r:40.909 
12/06 21:04:57:  do not save, best f1: 48.5774
12/06 21:04:57:  Step:160000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:48.4945, p:59.533,r:40.909 
12/06 22:10:14:  do not save, best f1: 48.5774
12/06 22:10:14:  Step:170000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:47.5539, p:58.023,r:40.285 
12/06 22:10:22:  do not save, best f1: 48.5774
12/06 22:10:22:  Step:170000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:47.5539, p:58.023,r:40.285 
12/06 23:15:41:  do not save, best f1: 48.5774
12/06 23:15:41:  Step:180000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:47.2135, p:57.564,r:40.018 
12/06 23:15:54:  do not save, best f1: 48.5774
12/06 23:15:54:  Step:180000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:47.2135, p:57.564,r:40.018 
12/07 00:21:06:  do not save, best f1: 48.5774
12/07 00:21:06:  Step:190000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:47.9200, p:58.559,r:40.553 
12/07 00:21:13:  do not save, best f1: 48.5774
12/07 00:21:13:  Step:190000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:47.9200, p:58.559,r:40.553 
12/07 01:26:38:  do not save, best f1: 48.5774
12/07 01:26:38:  Step:200000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:47.6040, p:58.172,r:40.285 
12/07 01:26:40:  do not save, best f1: 48.5774
12/07 01:26:40:  Step:200000, Best: f1:48.577, p:59.407,r:41.087, Curr: f1:47.6040, p:58.172,r:40.285 
12/07 01:48:22:  train data num: 2100  dev data num: 727
12/07 01:48:22:  train data num: 2100  dev data num: 727
12/07 01:49:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 195, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 176, in _main
    test(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 16, in test
    test_ds = SADataset(args.data_file['test'], args.tokenizer, args, **args.kwargs_ds)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 57, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in _get_data
    "predict_aspect": self.predict_aspect[index]
TypeError: 'NoneType' object is not subscriptable
12/07 01:49:41:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 195, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 176, in _main
    test(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 16, in test
    test_ds = SADataset(args.data_file['test'], args.tokenizer, args, **args.kwargs_ds)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 57, in __init__
    self.data = self._get_data(file)
  File "/workspace/GEMEL/twitter/code/dataset_sa.py", line 146, in _get_data
    "predict_aspect": self.predict_aspect[index]
TypeError: 'NoneType' object is not subscriptable
12/07 01:54:37:  train data num: 2100  dev data num: 727
12/07 01:54:37:  train data num: 2100  dev data num: 727
12/07 01:56:03:  load linear
12/07 01:56:03:  load linear
12/07 01:56:03:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 195, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 176, in _main
    test(args, dev_ds)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 26, in test
    precision, recall, f1 = _eval4sa(args, dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 120, in _eval4sa
    batch_pairs, batch_targets = batch_data
ValueError: too many values to unpack (expected 2)
12/07 01:56:07:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 195, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 176, in _main
    test(args, dev_ds)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 26, in test
    precision, recall, f1 = _eval4sa(args, dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 120, in _eval4sa
    batch_pairs, batch_targets = batch_data
ValueError: too many values to unpack (expected 2)
12/07 02:02:09:  train data num: 2100  dev data num: 727
12/07 02:02:09:  train data num: 2100  dev data num: 727
12/07 02:03:49:  load linear
12/07 02:03:49:  load linear
12/07 02:03:49:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 195, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 176, in _main
    test(args, dev_ds)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 26, in test
    precision, recall, f1 = _eval2save(args, dl)
TypeError: _eval2save() takes 1 positional argument but 2 were given
12/07 02:03:53:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 195, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 176, in _main
    test(args, dev_ds)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 26, in test
    precision, recall, f1 = _eval2save(args, dl)
TypeError: _eval2save() takes 1 positional argument but 2 were given
12/07 02:07:01:  train data num: 2100  dev data num: 727
12/07 02:07:01:  train data num: 2100  dev data num: 727
12/07 02:08:19:  load linear
12/07 02:08:19:  load linear
12/07 02:29:20:  train data num: 2100  dev data num: 727
12/07 02:29:20:  train data num: 2100  dev data num: 727
12/07 02:31:02:  load linear
12/07 02:31:02:  load linear
12/07 02:33:47:  train data num: 2100  dev data num: 727
12/07 02:33:47:  train data num: 2100  dev data num: 727
12/07 02:35:09:  load linear
12/07 02:35:09:  load linear
12/07 02:39:28:  train data num: 2100  dev data num: 727
12/07 02:39:28:  train data num: 2100  dev data num: 727
12/07 05:30:19:  train data num: 2100  dev data num: 727
12/07 05:30:19:  train data num: 2100  dev data num: 727
12/07 09:39:24:  train data num: 2100  dev data num: 727
12/07 09:39:24:  train data num: 2100  dev data num: 727
12/07 10:33:52:  train data num: 2100  dev data num: 727
12/07 10:33:53:  train data num: 2100  dev data num: 727
12/07 10:33:53:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 184, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/main.py", line 50, in wrap_with_peft
    args.tokenizer = LlamaTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 1841, in from_pretrained
    return cls._from_pretrained(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 2004, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/tokenization_llama.py", line 144, in __init__
    self.sp_model.Load(vocab_file)
  File "/usr/local/lib/python3.10/dist-packages/sentencepiece/__init__.py", line 905, in Load
    return self.LoadFromFile(model_file)
  File "/usr/local/lib/python3.10/dist-packages/sentencepiece/__init__.py", line 310, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
TypeError: not a string
12/07 10:33:53:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 184, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/main.py", line 50, in wrap_with_peft
    args.tokenizer = LlamaTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 1841, in from_pretrained
    return cls._from_pretrained(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 2004, in _from_pretrained
    tokenizer = cls(*init_inputs, **init_kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/llama/tokenization_llama.py", line 144, in __init__
    self.sp_model.Load(vocab_file)
  File "/usr/local/lib/python3.10/dist-packages/sentencepiece/__init__.py", line 905, in Load
    return self.LoadFromFile(model_file)
  File "/usr/local/lib/python3.10/dist-packages/sentencepiece/__init__.py", line 310, in LoadFromFile
    return _sentencepiece.SentencePieceProcessor_LoadFromFile(self, arg)
TypeError: not a string
12/07 10:36:30:  train data num: 2100  dev data num: 727
12/07 10:36:33:  train data num: 2100  dev data num: 727
12/07 10:36:40:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 184, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/main.py", line 58, in wrap_with_peft
    model = AutoModelForCausalLM.from_pretrained(args.model_path, device_map=device_map)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py", line 461, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py", line 986, in from_pretrained
    trust_remote_code = resolve_trust_remote_code(
  File "/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py", line 553, in resolve_trust_remote_code
    raise ValueError(
ValueError: Loading ../../_llm_weight/qwen_chat requires you to execute the configuration file in that repo on your local machine. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.
12/07 10:36:48:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 184, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/main.py", line 58, in wrap_with_peft
    model = AutoModelForCausalLM.from_pretrained(args.model_path, device_map=device_map)
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py", line 461, in from_pretrained
    config, kwargs = AutoConfig.from_pretrained(
  File "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py", line 986, in from_pretrained
    trust_remote_code = resolve_trust_remote_code(
  File "/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py", line 538, in resolve_trust_remote_code
    answer = input(
  File "/usr/local/lib/python3.10/dist-packages/transformers/dynamic_module_utils.py", line 520, in _raise_timeout_error
    raise ValueError(
ValueError: Loading this model requires you to execute the configuration file in that repo on your local machine. We asked if it was okay but did not get an answer. Make sure you have read the code there to avoid malicious use, then set the option `trust_remote_code=True` to remove this error.
12/07 10:38:03:  train data num: 2100  dev data num: 727
12/07 10:38:05:  train data num: 2100  dev data num: 727
12/07 10:44:09:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 184, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/main.py", line 69, in wrap_with_peft
    model = get_peft_model(model, peft_config)
  File "/usr/local/lib/python3.10/dist-packages/peft/mapping.py", line 98, in get_peft_model
    return MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config.task_type](model, peft_config, adapter_name=adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 893, in __init__
    super().__init__(model, peft_config, adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 112, in __init__
    self.base_model = PEFT_TYPE_TO_MODEL_MAPPING[peft_config.peft_type](
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 180, in __init__
    self.add_adapter(adapter_name, self.peft_config[adapter_name])
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 192, in add_adapter
    config = self._prepare_lora_config(config, model_config)
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 434, in _prepare_lora_config
    raise ValueError("Please specify `target_modules` in `peft_config`")
ValueError: Please specify `target_modules` in `peft_config`
12/07 10:44:09:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 184, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/main.py", line 69, in wrap_with_peft
    model = get_peft_model(model, peft_config)
  File "/usr/local/lib/python3.10/dist-packages/peft/mapping.py", line 98, in get_peft_model
    return MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config.task_type](model, peft_config, adapter_name=adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 893, in __init__
    super().__init__(model, peft_config, adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 112, in __init__
    self.base_model = PEFT_TYPE_TO_MODEL_MAPPING[peft_config.peft_type](
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 180, in __init__
    self.add_adapter(adapter_name, self.peft_config[adapter_name])
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 192, in add_adapter
    config = self._prepare_lora_config(config, model_config)
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 434, in _prepare_lora_config
    raise ValueError("Please specify `target_modules` in `peft_config`")
ValueError: Please specify `target_modules` in `peft_config`
12/07 12:10:45:  train data num: 2100  dev data num: 727
12/07 12:10:45:  train data num: 2100  dev data num: 727
12/07 12:17:16:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 189, in _main
    args.model = Generator(lm=lm, tokenizer=args.tokenizer, inference=False, **kwargs_model).to(args.device)
  File "/workspace/GEMEL/twitter/code/model_.py", line 16, in __init__
    self.text_embedder = lm.module.base_model.model.model.embed_tokens  # for opt  TRAIN llama
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'QWenLMHeadModel' object has no attribute 'model'
12/07 12:17:16:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 189, in _main
    args.model = Generator(lm=lm, tokenizer=args.tokenizer, inference=False, **kwargs_model).to(args.device)
  File "/workspace/GEMEL/twitter/code/model_.py", line 16, in __init__
    self.text_embedder = lm.module.base_model.model.model.embed_tokens  # for opt  TRAIN llama
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'QWenLMHeadModel' object has no attribute 'model'
12/07 12:20:53:  train data num: 2100  dev data num: 727
12/07 12:20:53:  train data num: 2100  dev data num: 727
12/07 13:15:33:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 201, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 115, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 36, in generate
    genenrated = self.lm.module.generate(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 977, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_chat/modeling_qwen.py", line 1318, in generate
    return super().generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 1305, in generate
    inputs_tensor, model_input_name, model_kwargs = self._prepare_model_inputs(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 552, in _prepare_model_inputs
    model_kwargs["input_ids"] = self._maybe_initialize_input_ids_for_generation(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 587, in _maybe_initialize_input_ids_for_generation
    raise ValueError("`bos_token_id` has to be defined when no `input_ids` are provided.")
ValueError: `bos_token_id` has to be defined when no `input_ids` are provided.
12/07 13:15:33:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 201, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 115, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 36, in generate
    genenrated = self.lm.module.generate(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 977, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_chat/modeling_qwen.py", line 1318, in generate
    return super().generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 1305, in generate
    inputs_tensor, model_input_name, model_kwargs = self._prepare_model_inputs(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 552, in _prepare_model_inputs
    model_kwargs["input_ids"] = self._maybe_initialize_input_ids_for_generation(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 587, in _maybe_initialize_input_ids_for_generation
    raise ValueError("`bos_token_id` has to be defined when no `input_ids` are provided.")
ValueError: `bos_token_id` has to be defined when no `input_ids` are provided.
12/07 13:24:27:  train data num: 2100  dev data num: 727
12/07 13:24:27:  train data num: 2100  dev data num: 727
12/07 13:31:05:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 201, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 115, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 119, in _eval4sa
    batch_preds = args.tokenizer.batch_decode(generated, skip_special_tokens=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3485, in batch_decode
    return [
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3486, in <listcomp>
    self.decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3525, in decode
    return self._decode(
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_chat/tokenization_qwen.py", line 245, in _decode
    token_ids = [i for i in token_ids if i < self.eod_id]
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_chat/tokenization_qwen.py", line 245, in <listcomp>
    token_ids = [i for i in token_ids if i < self.eod_id]
TypeError: '<' not supported between instances of 'str' and 'int'
12/07 13:31:05:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 201, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 115, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 119, in _eval4sa
    batch_preds = args.tokenizer.batch_decode(generated, skip_special_tokens=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3485, in batch_decode
    return [
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3486, in <listcomp>
    self.decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3525, in decode
    return self._decode(
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_chat/tokenization_qwen.py", line 245, in _decode
    token_ids = [i for i in token_ids if i < self.eod_id]
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_chat/tokenization_qwen.py", line 245, in <listcomp>
    token_ids = [i for i in token_ids if i < self.eod_id]
TypeError: '<' not supported between instances of 'str' and 'int'
12/07 13:42:57:  train data num: 2100  dev data num: 727
12/07 13:42:57:  train data num: 2100  dev data num: 727
12/07 13:49:38:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 201, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 115, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 36, in generate
    genenrated = self.lm.module.generate(input_ids=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 977, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_chat/modeling_qwen.py", line 1318, in generate
    return super().generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 1665, in generate
    return self.beam_sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3223, in beam_sample
    batch_beam_size, cur_len = input_ids.shape
ValueError: too many values to unpack (expected 2)
12/07 13:49:38:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 201, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 115, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 36, in generate
    genenrated = self.lm.module.generate(input_ids=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 977, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_chat/modeling_qwen.py", line 1318, in generate
    return super().generate(
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 1665, in generate
    return self.beam_sample(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 3223, in beam_sample
    batch_beam_size, cur_len = input_ids.shape
ValueError: too many values to unpack (expected 2)
12/22 02:57:41:  train data num: 2100  dev data num: 727
12/22 02:57:41:  train data num: 2100  dev data num: 727
12/22 03:01:31:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 201, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 90, in _train
    gen_ls = args.model(batch_pairs, batch_targets).loss  #  HERE
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/GEMEL/twitter/code/model_.py", line 26, in forward
    outputs = self.lm(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, labels=labels)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 922, in forward
    return self.base_model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 856, in forward
    transformer_outputs = self.transformer(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 554, in forward
    if past_key_values is None and torch.any(input_ids == self.config.visual['image_start_id']):
TypeError: any(): argument 'input' (position 1) must be Tensor, not bool
12/22 03:01:32:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 201, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 90, in _train
    gen_ls = args.model(batch_pairs, batch_targets).loss  #  HERE
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/GEMEL/twitter/code/model_.py", line 26, in forward
    outputs = self.lm(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, labels=labels)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 922, in forward
    return self.base_model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 856, in forward
    transformer_outputs = self.transformer(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 554, in forward
    if past_key_values is None and torch.any(input_ids == self.config.visual['image_start_id']):
TypeError: any(): argument 'input' (position 1) must be Tensor, not bool
12/22 03:04:41:  train data num: 2100  dev data num: 727
12/22 03:04:41:  train data num: 2100  dev data num: 727
12/22 03:05:52:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 184, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/main.py", line 69, in wrap_with_peft
    model = get_peft_model(model, peft_config)
  File "/usr/local/lib/python3.10/dist-packages/peft/mapping.py", line 98, in get_peft_model
    return MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config.task_type](model, peft_config, adapter_name=adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 893, in __init__
    super().__init__(model, peft_config, adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 112, in __init__
    self.base_model = PEFT_TYPE_TO_MODEL_MAPPING[peft_config.peft_type](
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 180, in __init__
    self.add_adapter(adapter_name, self.peft_config[adapter_name])
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 194, in add_adapter
    self._find_and_replace(adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 356, in _find_and_replace
    raise ValueError(
ValueError: Target modules ['c_proj'] not found in the base model. Please check the target modules and try again.
12/22 03:05:52:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 218, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 184, in _main
    lm = wrap_with_peft(args, inference=False)
  File "/workspace/GEMEL/twitter/code/main.py", line 69, in wrap_with_peft
    model = get_peft_model(model, peft_config)
  File "/usr/local/lib/python3.10/dist-packages/peft/mapping.py", line 98, in get_peft_model
    return MODEL_TYPE_TO_PEFT_MODEL_MAPPING[peft_config.task_type](model, peft_config, adapter_name=adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 893, in __init__
    super().__init__(model, peft_config, adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 112, in __init__
    self.base_model = PEFT_TYPE_TO_MODEL_MAPPING[peft_config.peft_type](
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 180, in __init__
    self.add_adapter(adapter_name, self.peft_config[adapter_name])
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 194, in add_adapter
    self._find_and_replace(adapter_name)
  File "/usr/local/lib/python3.10/dist-packages/peft/tuners/lora.py", line 356, in _find_and_replace
    raise ValueError(
ValueError: Target modules ['c_proj'] not found in the base model. Please check the target modules and try again.
12/22 03:26:04:  train data num: 2100  dev data num: 727
12/22 03:26:04:  train data num: 2100  dev data num: 727
12/22 03:27:31:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 191, in _main
    args.model = Generator(lm=lm, tokenizer=args.tokenizer, inference=False, **kwargs_model).to(args.device)
  File "/workspace/GEMEL/twitter/code/model_.py", line 15, in __init__
    self.text_embedder = lm.module.base_model.model.transformer.wte  # for opt  TRAIN  qwen
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'LlamaForCausalLM' object has no attribute 'transformer'
12/22 03:27:32:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 191, in _main
    args.model = Generator(lm=lm, tokenizer=args.tokenizer, inference=False, **kwargs_model).to(args.device)
  File "/workspace/GEMEL/twitter/code/model_.py", line 15, in __init__
    self.text_embedder = lm.module.base_model.model.transformer.wte  # for opt  TRAIN  qwen
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'LlamaForCausalLM' object has no attribute 'transformer'
12/22 03:30:44:  train data num: 2100  dev data num: 727
12/22 03:30:44:  train data num: 2100  dev data num: 727
12/22 03:32:18:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 38, in generate
    genenrated = self.lm.module.generate(input_ids=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 977, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 1627, in generate
    return self.beam_search(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2889, in beam_search
    batch_beam_size, cur_len = input_ids.shape
ValueError: too many values to unpack (expected 2)
12/22 03:32:18:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 38, in generate
    genenrated = self.lm.module.generate(input_ids=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 977, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 1627, in generate
    return self.beam_search(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2889, in beam_search
    batch_beam_size, cur_len = input_ids.shape
ValueError: too many values to unpack (expected 2)
12/22 10:25:37:  train data num: 2100  dev data num: 727
12/22 10:25:37:  train data num: 2100  dev data num: 727
12/22 10:27:10:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 38, in generate
    genenrated = self.lm.module.generate(input_ids=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 977, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 1627, in generate
    return self.beam_search(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2889, in beam_search
    batch_beam_size, cur_len = input_ids.shape
ValueError: too many values to unpack (expected 2)
12/22 10:27:10:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 38, in generate
    genenrated = self.lm.module.generate(input_ids=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 977, in generate
    outputs = self.base_model.generate(**kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 1627, in generate
    return self.beam_search(
  File "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py", line 2889, in beam_search
    batch_beam_size, cur_len = input_ids.shape
ValueError: too many values to unpack (expected 2)
12/22 10:30:17:  train data num: 2100  dev data num: 727
12/22 10:30:17:  train data num: 2100  dev data num: 727
12/22 10:31:50:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 119, in _eval4sa
    batch_preds = args.tokenizer.batch_decode(generated, skip_special_tokens=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3485, in batch_decode
    return [
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3486, in <listcomp>
    self.decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3525, in decode
    return self._decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py", line 931, in _decode
    filtered_tokens = self.convert_ids_to_tokens(token_ids, skip_special_tokens=skip_special_tokens)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py", line 906, in convert_ids_to_tokens
    index = int(index)
ValueError: invalid literal for int() with base 10: 'l'
12/22 10:31:50:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 119, in _eval4sa
    batch_preds = args.tokenizer.batch_decode(generated, skip_special_tokens=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3485, in batch_decode
    return [
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3486, in <listcomp>
    self.decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3525, in decode
    return self._decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py", line 931, in _decode
    filtered_tokens = self.convert_ids_to_tokens(token_ids, skip_special_tokens=skip_special_tokens)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py", line 906, in convert_ids_to_tokens
    index = int(index)
ValueError: invalid literal for int() with base 10: 'l'
12/22 10:38:35:  train data num: 2100  dev data num: 727
12/22 10:38:35:  train data num: 2100  dev data num: 727
12/22 10:40:09:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 119, in _eval4sa
    batch_preds = args.tokenizer.batch_decode(generated, skip_special_tokens=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3485, in batch_decode
    return [
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3486, in <listcomp>
    self.decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3525, in decode
    return self._decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py", line 931, in _decode
    filtered_tokens = self.convert_ids_to_tokens(token_ids, skip_special_tokens=skip_special_tokens)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py", line 906, in convert_ids_to_tokens
    index = int(index)
ValueError: invalid literal for int() with base 10: 'l'
12/22 10:40:09:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 119, in _eval4sa
    batch_preds = args.tokenizer.batch_decode(generated, skip_special_tokens=True)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3485, in batch_decode
    return [
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3486, in <listcomp>
    self.decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 3525, in decode
    return self._decode(
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py", line 931, in _decode
    filtered_tokens = self.convert_ids_to_tokens(token_ids, skip_special_tokens=skip_special_tokens)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py", line 906, in convert_ids_to_tokens
    index = int(index)
ValueError: invalid literal for int() with base 10: 'l'
12/22 10:42:40:  train data num: 2100  dev data num: 727
12/22 10:42:40:  train data num: 2100  dev data num: 727
12/22 10:44:13:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 40, in generate
    genenrated = self.lm.generate(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'DistributedDataParallel' object has no attribute 'generate'
12/22 10:44:13:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 40, in generate
    genenrated = self.lm.generate(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'DistributedDataParallel' object has no attribute 'generate'
12/22 10:47:52:  train data num: 2100  dev data num: 727
12/22 10:47:52:  train data num: 2100  dev data num: 727
12/22 10:49:26:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 41, in generate
    genenrated = self.lm.generate(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'DistributedDataParallel' object has no attribute 'generate'
12/22 10:49:26:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 117, in _train
    _eval2save(args)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/workspace/GEMEL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/workspace/GEMEL/twitter/code/model_.py", line 41, in generate
    genenrated = self.lm.generate(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'DistributedDataParallel' object has no attribute 'generate'
12/22 10:52:47:  train data num: 2100  dev data num: 727
12/22 10:52:47:  train data num: 2100  dev data num: 727
12/22 11:06:48:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:06:48:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:06:48:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:06:53:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:06:53:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:06:53:  Step:10, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:19:18:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:19:18:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:19:18:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:19:32:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:19:32:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:19:32:  Step:20, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:31:56:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:31:56:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:31:56:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:32:09:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:32:09:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:32:09:  Step:30, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:44:36:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:44:36:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:44:36:  Step:40, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:44:46:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:44:46:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:44:46:  Step:40, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:57:13:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:57:13:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:57:13:  Step:50, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 11:57:23:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 11:57:23:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 11:57:23:  Step:50, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 12:09:50:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 12:09:50:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 12:09:50:  Step:60, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 12:10:02:  New best model, new f1 0.0000 % >= previous f1 0.0000 %
12/22 12:10:02:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
12/22 12:10:02:  Step:60, Best: f1:0.000, p:0.000,r:0.000, Curr: f1:0.0000, p:0.000,r:0.000 
12/22 12:22:27:  train data num: 2100  dev data num: 727
12/22 12:22:27:  train data num: 2100  dev data num: 727
12/22 12:26:07:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _train
    gen_ls = args.model(batch_pairs, batch_targets).loss  #  HERE
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/GEMEL/twitter/code/model_.py", line 29, in forward
    outputs = self.lm(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, labels=labels)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 922, in forward
    return self.base_model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 856, in forward
    transformer_outputs = self.transformer(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 554, in forward
    if past_key_values is None and torch.any(input_ids == self.config.visual['image_start_id']):
TypeError: any(): argument 'input' (position 1) must be Tensor, not bool
12/22 12:26:08:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _train
    gen_ls = args.model(batch_pairs, batch_targets).loss  #  HERE
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/GEMEL/twitter/code/model_.py", line 29, in forward
    outputs = self.lm(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, labels=labels)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 922, in forward
    return self.base_model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 856, in forward
    transformer_outputs = self.transformer(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 554, in forward
    if past_key_values is None and torch.any(input_ids == self.config.visual['image_start_id']):
TypeError: any(): argument 'input' (position 1) must be Tensor, not bool
12/24 12:03:53:  train data num: 2100  dev data num: 727
12/24 12:03:53:  train data num: 2100  dev data num: 727
12/24 12:07:37:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _train
    gen_ls = args.model(batch_pairs, batch_targets).loss  #  HERE
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/GEMEL/twitter/code/model_.py", line 29, in forward
    outputs = self.lm(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, labels=labels)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 922, in forward
    return self.base_model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 856, in forward
    transformer_outputs = self.transformer(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 554, in forward
    if past_key_values is None and torch.any(input_ids == self.config.visual['image_start_id']):
TypeError: any(): argument 'input' (position 1) must be Tensor, not bool
12/24 12:07:37:  Error
Traceback (most recent call last):
  File "/workspace/GEMEL/twitter/code/main.py", line 220, in <module>
    _main(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 203, in _main
    _train(args)
  File "/workspace/GEMEL/twitter/code/main.py", line 92, in _train
    gen_ls = args.model(batch_pairs, batch_targets).loss  #  HERE
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/workspace/GEMEL/twitter/code/model_.py", line 29, in forward
    outputs = self.lm(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, labels=labels)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/peft/peft_model.py", line 922, in forward
    return self.base_model(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 856, in forward
    transformer_outputs = self.transformer(
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/.cache/huggingface/modules/transformers_modules/qwen_VL_Chat/modeling_qwen.py", line 554, in forward
    if past_key_values is None and torch.any(input_ids == self.config.visual['image_start_id']):
TypeError: any(): argument 'input' (position 1) must be Tensor, not bool
03/28 18:38:08:  Error
Traceback (most recent call last):
  File "code/main.py", line 220, in <module>
    _main(args)
  File "code/main.py", line 139, in _main
    check_dirs(dirs=[args.dataset_dir, args.log_dir, args.ckpt_dir])
  File "/data/ssz/EL/twitter/code/utils.py", line 41, in check_dirs
    os.mkdir(dir)
FileNotFoundError: [Errno 2] No such file or directory: '../../_SAdata/twitter2015/'
03/28 18:38:37:  Error
Traceback (most recent call last):
  File "code/main.py", line 220, in <module>
    _main(args)
  File "code/main.py", line 139, in _main
    check_dirs(dirs=[args.dataset_dir, args.log_dir, args.ckpt_dir])
  File "/data/ssz/EL/twitter/code/utils.py", line 41, in check_dirs
    os.mkdir(dir)
FileNotFoundError: [Errno 2] No such file or directory: '../../data/twitter2015/'
03/28 18:39:24:  Error
Traceback (most recent call last):
  File "code/main.py", line 220, in <module>
    _main(args)
  File "code/main.py", line 148, in _main
    args.train_embed = get_embed(args.ment_embed_file, mention_data = args.data_file['train'], args=args)
  File "/data/ssz/EL/twitter/code/utils.py", line 61, in get_embed
    raw_data = [json.loads(line) for line in f]
  File "/data/ssz/EL/twitter/code/utils.py", line 61, in <listcomp>
    raw_data = [json.loads(line) for line in f]
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
03/28 19:27:45:  Error
Traceback (most recent call last):
  File "code/main.py", line 220, in <module>
    _main(args)
  File "code/main.py", line 148, in _main
    args.train_embed = get_embed(args.ment_embed_file, mention_data = args.data_file['train'], args=args)
  File "/data/ssz/EL/twitter/code/utils.py", line 60, in get_embed
    raw_data = [json.loads(line) for line in f]
  File "/data/ssz/EL/twitter/code/utils.py", line 60, in <listcomp>
    raw_data = [json.loads(line) for line in f]
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/json/__init__.py", line 357, in loads
    return _default_decoder.decode(s)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)
03/28 19:28:21:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 148, in _main
    args.roberta_tokenizer = AutoTokenizer.from_pretrained(args.simcse_model)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../../_ELdata/sup-simcse-roberta-large/'. Use `repo_type` argument if needed.
03/28 20:39:39:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 148, in _main
    args.roberta_tokenizer = AutoTokenizer.from_pretrained(args.simcse_model)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../../_ELdata/sup-simcse-roberta-large/'. Use `repo_type` argument if needed.
03/28 20:39:59:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 152, in _main
    aspect_predictor = aspect_method(args=args)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 316, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(os.path.join(self.pretrain_path, "deberta"), add_prefix_space=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../../_llm_weight/pretrain/deberta'. Use `repo_type` argument if needed.
03/28 21:45:15:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 148, in _main
    args.roberta_tokenizer = AutoTokenizer.from_pretrained(args.simcse_model)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../data/sup-simcse-roberta-large/'. Use `repo_type` argument if needed.
03/28 21:45:31:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 148, in _main
    args.roberta_tokenizer = AutoTokenizer.from_pretrained(args.simcse_model)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../data/sup-simcse-roberta-large/'. Use `repo_type` argument if needed.
03/28 21:46:08:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 152, in _main
    aspect_predictor = aspect_method(args=args)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 316, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained(os.path.join(self.pretrain_path, "deberta"), add_prefix_space=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../data/pretrain/pretrain/deberta'. Use `repo_type` argument if needed.
03/28 21:47:32:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 152, in _main
    aspect_predictor = aspect_method(args=args)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 319, in __init__
    self.train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 160, in __init__
    self.raw_data, self.pairs = self.process_data(refresh_data=args.refresh_aspect_data)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 294, in process_data
    tokenized_inputs = self.tokenize_data(sentence_l, image_l, label_l, pair_l, senti_l, allabel_l)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 232, in tokenize_data
    image = Image.open(img_path)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/PIL/Image.py", line 3247, in open
    fp = builtins.open(filename, "rb")
FileNotFoundError: [Errno 2] No such file or directory: '../data/ImgData/twitter2015/1860693.jpg'
03/28 21:49:35:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 152, in _main
    aspect_predictor = aspect_method(args=args)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 319, in __init__
    self.train_data = aspect_dataset(self.args.data_file['train'], self.args)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 160, in __init__
    self.raw_data, self.pairs = self.process_data(refresh_data=args.refresh_aspect_data)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 294, in process_data
    tokenized_inputs = self.tokenize_data(sentence_l, image_l, label_l, pair_l, senti_l, allabel_l)
  File "/data/ssz/EL/twitter/code/aspect/aspect_method.py", line 236, in tokenize_data
    processor = AutoProcessor.from_pretrained(self.image_model_path)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/processing_auto.py", line 212, in from_pretrained
    preprocessor_config_file = get_file_from_repo(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 545, in get_file_from_repo
    return cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../data/pretrain/vit-base-patch16-224-in21k'. Use `repo_type` argument if needed.
03/30 16:54:25:  train data num: 2100  dev data num: 727
03/30 16:54:25:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 185, in _main
    lm = wrap_with_peft(args, inference=False)
  File "code/main.py", line 58, in wrap_with_peft
    args.tokenizer = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../../_llm_weight/qwen_VL_Chat'. Use `repo_type` argument if needed.
03/30 16:55:21:  train data num: 2100  dev data num: 727
03/30 16:55:21:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 185, in _main
    lm = wrap_with_peft(args, inference=False)
  File "code/main.py", line 50, in wrap_with_peft
    args.tokenizer = LlamaTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/import_utils.py", line 1039, in __getattribute__
    requires_backends(cls, cls._backends)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/import_utils.py", line 1027, in requires_backends
    raise ImportError("".join(failed))
ImportError: 
LlamaTokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the
installation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones
that match your environment. Please note that you may need to restart your runtime after installation.

03/30 16:56:57:  train data num: 2100  dev data num: 727
03/30 16:56:57:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 185, in _main
    lm = wrap_with_peft(args, inference=False)
  File "code/main.py", line 50, in wrap_with_peft
    args.tokenizer = LlamaTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 1800, in from_pretrained
    resolved_vocab_files[file_id] = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../../_llm_weight/llama7bhf'. Use `repo_type` argument if needed.
04/02 22:38:59:  train data num: 2100  dev data num: 727
04/02 22:38:59:  Error
Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 111, in _inner_fn
    validate_repo_id(arg_value)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 159, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '../../_llm_weight/llama7bhf'. Use `repo_type` argument if needed.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 185, in _main
    lm = wrap_with_peft(args, inference=False)
  File "code/main.py", line 50, in wrap_with_peft
    args.tokenizer = LlamaTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2007, in from_pretrained
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 462, in cached_file
    raise EnvironmentError(
OSError: Incorrect path_or_model_id: '../../_llm_weight/llama7bhf'. Please provide either the path to a local folder or the repo_id of a model on the Hub.
04/02 22:40:51:  train data num: 2100  dev data num: 727
04/02 22:40:51:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 185, in _main
    lm = wrap_with_peft(args, inference=False)
  File "code/main.py", line 50, in wrap_with_peft
    args.tokenizer = LlamaTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/tokenization_utils_base.py", line 2070, in from_pretrained
    raise EnvironmentError(
OSError: Can't load tokenizer for '../data/pretrain/llama7bhf'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure '../data/pretrain/llama7bhf' is the correct path to a directory containing all relevant files for a LlamaTokenizer tokenizer.
04/02 22:43:30:  train data num: 2100  dev data num: 727
04/02 22:43:51:  Error
Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/peft_model.py", line 540, in __getattr__
    return super().__getattr__(name)  # defer to nn.Module's logic
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1269, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'PeftModelForCausalLM' object has no attribute 'module'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/tuners/lora/model.py", line 311, in __getattr__
    return super().__getattr__(name)  # defer to nn.Module's logic
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1269, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'LoraModel' object has no attribute 'module'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 190, in _main
    args.model = Generator(args=args, lm=lm, tokenizer=args.tokenizer, inference=False, **kwargs_model).to(args.device)
  File "/data/ssz/EL/twitter/code/model_.py", line 17, in __init__
    self.text_embedder = lm.module.base_model.model.model.embed_tokens  # for opt  TRAIN llama
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/peft_model.py", line 542, in __getattr__
    return getattr(self.base_model, name)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/tuners/lora/model.py", line 313, in __getattr__
    return getattr(self.model, name)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1269, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'LlamaForCausalLM' object has no attribute 'module'
04/03 18:55:50:  train data num: 2100  dev data num: 727
04/03 18:56:29:  Error
Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/peft_model.py", line 540, in __getattr__
    return super().__getattr__(name)  # defer to nn.Module's logic
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1269, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'PeftModelForCausalLM' object has no attribute 'module'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/tuners/lora/model.py", line 311, in __getattr__
    return super().__getattr__(name)  # defer to nn.Module's logic
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1269, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'LoraModel' object has no attribute 'module'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 202, in _main
    _train(args)
  File "code/main.py", line 117, in _train
    _eval2save(args)
  File "/data/ssz/EL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/data/ssz/EL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/data/ssz/EL/twitter/code/model_.py", line 40, in generate
    genenrated = self.lm.module.generate(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/peft_model.py", line 542, in __getattr__
    return getattr(self.base_model, name)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/tuners/lora/model.py", line 313, in __getattr__
    return getattr(self.model, name)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1269, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'LlamaForCausalLM' object has no attribute 'module'
04/03 19:02:34:  train data num: 2100  dev data num: 727
04/03 19:02:55:  Error
Traceback (most recent call last):
  File "code/main.py", line 219, in <module>
    _main(args)
  File "code/main.py", line 202, in _main
    _train(args)
  File "code/main.py", line 117, in _train
    _eval2save(args)
  File "/data/ssz/EL/twitter/code/evaluate.py", line 138, in _eval2save
    precision, recall, f1 = _eval4sa(args, args.eval_dl)
  File "/data/ssz/EL/twitter/code/evaluate.py", line 118, in _eval4sa
    generated = args.model.generate(**features)
  File "/data/ssz/EL/twitter/code/model_.py", line 40, in generate
    genenrated = self.lm.generate(input_ids=None, inputs_embeds=inputs_embeds, attention_mask=attention_mask, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/peft/peft_model.py", line 1190, in generate
    outputs = self.base_model.generate(*args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/generation/utils.py", line 1609, in generate
    result = self._beam_search(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/generation/utils.py", line 3062, in _beam_search
    outputs = self(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1196, in forward
    outputs = self.model(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 990, in forward
    causal_mask = self._update_causal_mask(attention_mask, inputs_embeds, cache_position)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/llama/modeling_llama.py", line 1077, in _update_causal_mask
    causal_mask *= torch.arange(target_length, device=device) > cache_position.reshape(-1, 1)
RuntimeError: The size of tensor a (205) must match the size of tensor b (0) at non-singleton dimension 0
04/03 19:04:37:  train data num: 2100  dev data num: 727
04/03 19:07:28:  train data num: 2100  dev data num: 727
04/03 20:37:32:  New best model, new f1 47.2880 % >= previous f1 0.0000 %
04/03 20:37:32:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
04/03 20:37:32:  Step:20000, Best: f1:47.288, p:57.786,r:40.018, Curr: f1:47.2880, p:57.786,r:40.018 
04/03 21:49:05:  New best model, new f1 50.7384 % >= previous f1 47.2880 %
04/03 21:49:05:  Save to ./checkpoint/llama_linear_1token_1examples.pkl
04/03 21:49:05:  Step:40000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:50.7384, p:62.145,r:42.870 
04/03 23:05:07:  do not save, best f1: 50.7384
04/03 23:05:07:  Step:60000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:49.9473, p:61.082,r:42.246 
04/04 00:12:12:  do not save, best f1: 50.7384
04/04 00:12:12:  Step:80000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:47.8740, p:58.238,r:40.642 
04/04 01:19:05:  do not save, best f1: 50.7384
04/04 01:19:05:  Step:100000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:48.8421, p:59.640,r:41.355 
04/04 02:26:05:  do not save, best f1: 50.7384
04/04 02:26:05:  Step:120000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:48.7933, p:59.311,r:41.444 
04/04 03:33:03:  do not save, best f1: 50.7384
04/04 03:33:03:  Step:140000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:49.7899, p:60.614,r:42.246 
04/04 04:40:02:  do not save, best f1: 50.7384
04/04 04:40:02:  Step:160000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:47.0279, p:57.381,r:39.840 
04/04 05:47:00:  do not save, best f1: 50.7384
04/04 05:47:00:  Step:180000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:48.7625, p:59.588,r:41.266 
04/04 06:53:59:  do not save, best f1: 50.7384
04/04 06:53:59:  Step:200000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:50.2365, p:61.204,r:42.602 
04/04 07:35:05:  do not save, best f1: 50.7384
04/04 07:35:05:  Step:210000, Best: f1:50.738, p:62.145,r:42.870, Curr: f1:50.7102, p:61.874,r:42.959 
04/06 20:42:29:  train data num: 2100  dev data num: 727
04/06 20:43:09:  Error
Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connection.py", line 203, in _new_conn
    sock = connection.create_connection(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/connection.py", line 85, in create_connection
    raise err
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/connection.py", line 73, in create_connection
    sock.connect(sa)
socket.timeout: timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 790, in urlopen
    response = self._make_request(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 491, in _make_request
    raise new_e
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    self._validate_conn(conn)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1096, in _validate_conn
    conn.connect()
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connection.py", line 611, in connect
    self.sock = sock = self._new_conn()
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connection.py", line 212, in _new_conn
    raise ConnectTimeoutError(
urllib3.exceptions.ConnectTimeoutError: (<urllib3.connection.HTTPSConnection object at 0x7f48741a88b0>, 'Connection to huggingface.co timed out. (connect timeout=10)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 844, in urlopen
    retries = retries.increment(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/retry.py", line 515, in increment
    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /llava-hf/llava-1.5-7b-hf/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f48741a88b0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1261, in hf_hub_download
    metadata = get_hf_file_metadata(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 119, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1674, in get_hf_file_metadata
    r = _request_wrapper(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 369, in _request_wrapper
    response = _request_wrapper(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 392, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_http.py", line 68, in send
    return super().send(request, *args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/adapters.py", line 507, in send
    raise ConnectTimeout(e, request=request)
requests.exceptions.ConnectTimeout: (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /llava-hf/llava-1.5-7b-hf/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7f48741a88b0>, 'Connection to huggingface.co timed out. (connect timeout=10)'))"), '(Request ID: 684cd5c1-dd3a-42bf-a6d0-661df613bc5f)')

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 119, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1406, in hf_hub_download
    raise LocalEntryNotFoundError(
huggingface_hub.utils._errors.LocalEntryNotFoundError: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "code/main.py", line 228, in <module>
    _main(args)
  File "code/main.py", line 194, in _main
    lm = wrap_with_peft(args, inference=False)
  File "code/main.py", line 58, in wrap_with_peft
    args.tokenizer = AutoTokenizer.from_pretrained(args.model_path, trust_remote_code=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/tokenization_auto.py", line 782, in from_pretrained
    config = AutoConfig.from_pretrained(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py", line 1111, in from_pretrained
    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/configuration_utils.py", line 633, in get_config_dict
    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/configuration_utils.py", line 688, in _get_config_dict
    resolved_config_file = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 441, in cached_file
    raise EnvironmentError(
OSError: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like llava-hf/llava-1.5-7b-hf is not the path to a directory containing a file named config.json.
Checkout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.
04/06 20:43:59:  train data num: 2100  dev data num: 727
04/06 20:47:35:  Error
Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/response.py", line 712, in _error_catcher
    yield
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/response.py", line 812, in _raw_read
    data = self._fp_read(amt) if not fp_closed else b""
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/response.py", line 789, in _fp_read
    data = self._fp.read(chunk_amt)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/http/client.py", line 459, in read
    n = self.readinto(b)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/http/client.py", line 503, in readinto
    n = self.fp.readinto(b)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/socket.py", line 669, in readinto
    return self._sock.recv_into(b)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/ssl.py", line 1274, in recv_into
    return self.read(nbytes, buffer)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/ssl.py", line 1132, in read
    return self._sslobj.read(len, buffer)
socket.timeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/models.py", line 816, in generate
    yield from self.raw.stream(chunk_size, decode_content=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/response.py", line 934, in stream
    data = self.read(amt=amt, decode_content=decode_content)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/response.py", line 877, in read
    data = self._raw_read(amt)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/response.py", line 833, in _raw_read
    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/contextlib.py", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/response.py", line 717, in _error_catcher
    raise ReadTimeoutError(self._pool, None, "Read timed out.") from e  # type: ignore[arg-type]
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 535, in http_get
    for chunk in r.iter_content(chunk_size=DOWNLOAD_CHUNK_SIZE):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/models.py", line 822, in generate
    raise ConnectionError(e)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    self._validate_conn(conn)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1096, in _validate_conn
    conn.connect()
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connection.py", line 782, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 470, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 514, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/ssl.py", line 1073, in _create
    self.do_handshake()
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/ssl.py", line 1342, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1114: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 844, in urlopen
    retries = retries.increment(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 790, in urlopen
    response = self._make_request(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 491, in _make_request
    raise new_e
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 469, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 370, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "code/main.py", line 228, in <module>
    _main(args)
  File "code/main.py", line 194, in _main
    lm = wrap_with_peft(args, inference=False)
  File "code/main.py", line 59, in wrap_with_peft
    model = LlavaForConditionalGeneration.from_pretrained(args.model_path, device_map=device_map, trust_remote_code=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3264, in from_pretrained
    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 1038, in get_checkpoint_shard_files
    cached_filename = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 119, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1492, in hf_hub_download
    http_get(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 552, in http_get
    return http_get(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 456, in http_get
    r = _request_wrapper(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 392, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_http.py", line 68, in send
    return super().send(request, *args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/adapters.py", line 532, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: (ReadTimeoutError("HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out. (read timeout=10)"), '(Request ID: abe61935-3c6c-4d10-882f-0c0e9ae0e8ca)')
04/06 20:56:47:  train data num: 2100  dev data num: 727
04/06 20:57:10:  Error
Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 467, in _make_request
    self._validate_conn(conn)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 1096, in _validate_conn
    conn.connect()
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connection.py", line 642, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connection.py", line 782, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 470, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/ssl_.py", line 514, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/ssl.py", line 500, in wrap_socket
    return self.sslsocket_class._create(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/ssl.py", line 1073, in _create
    self.do_handshake()
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/ssl.py", line 1342, in do_handshake
    self._sslobj.do_handshake()
socket.timeout: _ssl.c:1114: The handshake operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/adapters.py", line 486, in send
    resp = conn.urlopen(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 844, in urlopen
    retries = retries.increment(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/retry.py", line 470, in increment
    raise reraise(type(error), error, _stacktrace)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/util/util.py", line 39, in reraise
    raise value
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 790, in urlopen
    response = self._make_request(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 491, in _make_request
    raise new_e
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 469, in _make_request
    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/urllib3/connectionpool.py", line 370, in _raise_timeout
    raise ReadTimeoutError(
urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out. (read timeout=10)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "code/main.py", line 228, in <module>
    _main(args)
  File "code/main.py", line 194, in _main
    lm = wrap_with_peft(args, inference=False)
  File "code/main.py", line 59, in wrap_with_peft
    model = LlavaForConditionalGeneration.from_pretrained(args.model_path, device_map=device_map, trust_remote_code=True)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3264, in from_pretrained
    resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 1038, in get_checkpoint_shard_files
    cached_filename = cached_file(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/transformers/utils/hub.py", line 398, in cached_file
    resolved_file = hf_hub_download(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py", line 119, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 1492, in hf_hub_download
    http_get(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 456, in http_get
    r = _request_wrapper(
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/file_download.py", line 392, in _request_wrapper
    response = get_session().request(method=method, url=url, **params)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/huggingface_hub/utils/_http.py", line 68, in send
    return super().send(request, *args, **kwargs)
  File "/home/hello/miniconda3/envs/cpm-9g/lib/python3.8/site-packages/requests/adapters.py", line 532, in send
    raise ReadTimeout(e, request=request)
requests.exceptions.ReadTimeout: (ReadTimeoutError("HTTPSConnectionPool(host='cdn-lfs-us-1.hf-mirror.com', port=443): Read timed out. (read timeout=10)"), '(Request ID: 53b577a1-ecf5-40e6-947f-0201c0329b09)')
